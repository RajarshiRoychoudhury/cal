,Description,forum
0,"Per author response, I've revised my review from 4 to 6 contingent on authors including the additional evaluation & clarifications they've described in the thread below",NXJ18rwo-t7
1,Vapur is a tool for finding related protein-chemical pairs,NXJ18rwo-t7
2,"The idea is to (i) extract & normalize entities using BERN, (ii) identify relations using a ChemProt-supervised model, (iii) index papers based on related entity pairs",NXJ18rwo-t7
3, Search results organized by relationships with other potential drug targets and entities of interest,NXJ18rwo-t7
4, The authors evaluate the system's predictions in a small manual study.,NXJ18rwo-t7
5,"Since the methods used to build the system are applications of existing methods, and the key innovation is in the interface, I recommend restructuring this paper like a demo paper",NXJ18rwo-t7
6,1) Make Figure 3 --> Figure 1.,NXJ18rwo-t7
7,2) Spend more time walking through how a user should use Vapur for search/exploration/discovery,NXJ18rwo-t7
8, Taking us through a compelling example from the perspective of a real biomedical researcher user would be nice  (the current example in Figure 3 caption is a bit lacking in motivation),NXJ18rwo-t7
9,3) Add to Related Work a review of other similar relation-oriented COVID19 systems,NXJ18rwo-t7
10,"  Some examples include KDCovid (http://kdcovid.nl/about.html), EVIDENCEMINER (https://www.aclweb.org/anthology/2020.acl-demos.8/), and SemViz (https://www.semviz.org/), which all surface relational information between bio-entities for COVID-19",NXJ18rwo-t7
11," I believe Vapur is sufficiently different from theirs because of the use of a relation-based inverted index, but I recommend the authors try to articulate this clearly earlier in their paper to help distinguish their work.",NXJ18rwo-t7
12,4) Move the details about the Methods (sec 3) to after the reader has familiarized with the system,NXJ18rwo-t7
13,- Table 6 is not discussed in the text.,NXJ18rwo-t7
14,- Please include the Appendix from the GitHub containing domain-expert-checked instances in the final version of this paper,NXJ18rwo-t7
15, Don't make us go look for it.,NXJ18rwo-t7
16,- Why did you decide to use 1/0 binary classification of relation instead of predicting the class labels?  Were the relation class labels not useful for your particular user interface? This would be very interesting to discuss,NXJ18rwo-t7
17,- It's good you performed an evaluation for the relation extraction module,NXJ18rwo-t7
18," When checking the Appendix, I realized the evaluation was on the binary level (i.e",NXJ18rwo-t7
19,does this express a relation or not?),NXJ18rwo-t7
20," While this is fine to identify that errors are coming from entity normalization, I think your system could benefit from an error analysis on the sentences itself (i.e",NXJ18rwo-t7
21,what types of sentences does the system tend to fail on?  maybe split this out by the existing relation types in ChemProt?),NXJ18rwo-t7
22,- I'm disappointed to not see a human evaluation of the system in front of (at least one) real user,NXJ18rwo-t7
23," When we build such tools, it's important to get feedback from real biomedical researchers (e.g",NXJ18rwo-t7
24,"given they issue K queries, do they find the results sensible/helpful?)  It doesn't have to be extensive (given this is a workshop submission), but some indication of having verified that this tool is actually something biomedical researchers would find helpful would give readers more confidence that system designs like Vapur are a good idea.",NXJ18rwo-t7
25,This paper is about the development of a search engine for Proteins-compounds extracted from CORD-19 dataset,NXJ18rwo-t7
26,The pipeline of the work consists in extracting the entities from the abstracts using BERN and normalizing these entities,NXJ18rwo-t7
27,"Then the system uses the BioBERT, previously tuned using the ChemProt dataset, for relation extraction between the entities (e1 for chemicals and e2 for proteins)",NXJ18rwo-t7
28,"Finally, they create an inverted index",NXJ18rwo-t7
29,"I think this is a valuable work, well written, however a little confused in its structure",NXJ18rwo-t7
30,"The introduction provides a good insight of the work, but I was expecting more information here",NXJ18rwo-t7
31,The related work section needs more work,NXJ18rwo-t7
32,"This section talks about NER, BERN, but it does not present RW related to search engines, thus, when the authors state that this is the first search engine that “uses relation extraction to construct an inverted index of related biochemical entities”, I thought that I need more info about search engines provided in the RW",NXJ18rwo-t7
33,"In Methods, the paper presents very well the datasets used, I have just some issues:",NXJ18rwo-t7
34,- Why do you consider CPR:0 as 1? Is there a certain relation there but ChemProt doesn't know what is it?,NXJ18rwo-t7
35,"- Here the authors introduce new concepts, such as GENIA, and finally say what is BERN (a neural NER architecture with an integrated normalizer), but I think this should be said previously in the paper",NXJ18rwo-t7
36,- I didn’t quite understand what was used for the normalization,NXJ18rwo-t7
37,"About Vapur, it seems a useful search engine, but there is no evaluation here",NXJ18rwo-t7
38,Are you planning some online evaluation? ,NXJ18rwo-t7
39,"In Results and Discussion the authors only evaluate BERT vs BioBERT performance, which seems a bit limiting and expected that BioBERT performs better in a Biomedical related dataset",NXJ18rwo-t7
40,"- In vapur there is the display of similar entities, for example, similar genes as in Figure 3",NXJ18rwo-t7
41,I didn’t understand how the similarity is calculated here,NXJ18rwo-t7
42,- Are you considering the use of the full text? Some precious entities may be enclosured there,NXJ18rwo-t7
43,"Introduction: The last paragraph staring with “in order to”, contains technical detail of the work",NXJ18rwo-t7
44,It would have been better to highlight the contribution and importance of the work and leave the technical description to the next sections,NXJ18rwo-t7
45,Figure 1 show the overall architecture of the work but the main component which is CORD-19 is not explicitly included,NXJ18rwo-t7
46,"For this sentence “Vapur indexes only these abstracts, but it is able to return the linked full-paper,",NXJ18rwo-t7
47,"as well.” What does it mean? As a reviewer I had to decipher it to mean this “ Vapur indexes into these abstracts, and is also able to return the linked full-paper.” Is that correct? (Only and as well do not go together).",NXJ18rwo-t7
48, Section 3.3 there seem to be no need to reference BioBERT again,NXJ18rwo-t7
49,Where Chemprot dataset is introduced include the number of records (publications).,NXJ18rwo-t7
50,Table 1 would benefit from having a total row.,NXJ18rwo-t7
51,As a reader I found myself going back and forth between sections to try to find how the components are introduced and what the contributions are,NXJ18rwo-t7
52,Both Results and Discussion and Conclusion sections have Vapur explained in them,NXJ18rwo-t7
53,I would suggest describing Vapur only in the Conclusion section,NXJ18rwo-t7
54,"Final update:  Per continued dialogue with the authors (see thread below), I've modified my rating of this work from 4 to 6, leaning toward acceptance under the belief that the authors will make the changes to their manuscript as they've described below",eeYSJJGAkg1
55, I stand by my initial review as other reviewers also pointed out much of the same concerns; but I thank the authors for engaging & working toward what I believe will be a more clarified contribution.,eeYSJJGAkg1
56,"The authors latest response addressed many of my concerns, and I'd be happy to push for acceptance *contingent* on author commitment to make certain changes in the manuscript.",eeYSJJGAkg1
57,I've increased my rating of this work from 3 to 4 based on the author response below,eeYSJJGAkg1
58, Many more questions still remain (see my follow-up to author response).,eeYSJJGAkg1
59,The authors provide a detailed documentation of their participation in the TREC-COVID challenge (Rounds 1-3),eeYSJJGAkg1
60," Their system: (i) concatenates BioBERT sentence embeddings (Reimers and Gurevych 2019) with a standard inverted index over documents, and (ii) ranking documents using an averaging of BM25 scores and cosine similarities over the neural embeddings",eeYSJJGAkg1
61, The system achieves moderate performance among automatic runs on the official TREC-COVID results,eeYSJJGAkg1
62,"Regarding the method, there is not sufficient Related Work provided to understand how this method fits within the broader literature  (has this been tried before -- if so, citation? is this similar to something else w/ some modification?  -- if so, citation & explanation/motivation of differences?  is this entirely novel?)",eeYSJJGAkg1
63,"Regarding the relevance feedback (RF) baseline, why is this a sensible choice over (a) BioBERT sentence embeddings & cosine similarities without BM25, and (b) BM25 without the BioBERT sentence embeddings?  Comparing against the latter baselines would be able to help explain how/where the described system is performing well/not",eeYSJJGAkg1
64,"Regarding the evaluation, Table 1, while it is an accurate reporting of the official performance by this team, because the nature of the submissions differs between Rounds, it's hard to understand what learnings we can gain from this",eeYSJJGAkg1
65," For example, RF appears for Round 1, but RF-RR for Round 2, and no baseline for Round 3",eeYSJJGAkg1
66," Fusion appears for Round 3, but not Round 1 or Round 2",eeYSJJGAkg1
67," NIRR appears for Round 2 and Round 3, but not Round 1",eeYSJJGAkg1
68, It's really hard to see any meaningful patterns with results reported in this manner,eeYSJJGAkg1
69," I believe the authors should've conducted separate controlled experiments to demonstrate efficacy of their method in a controlled setting, and supplement those results with the results from TREC-COVID, not base the entire paper on the TREC-COVID results.",eeYSJJGAkg1
70,"Regarding the analysis in ""Where does the model succeed or fail"", the point about bias in TREC judgments is very interesting -- that is, their system returned a document at a high rank but was un-judged because no other system returned that document",eeYSJJGAkg1
71, This could've been very interesting if the authors did a more thorough analysis -- how often does this happen? how big of an impact does this have on the performance scores (e.g,eeYSJJGAkg1
72,"if these documents were judged, what would the scores look like?)   why might this model be behaving in this manner that's different from other systems?",eeYSJJGAkg1
73,"Overall, this submission, while a perfectly fine detailed report about a team's submissions to a competition, does not propose a particularly powerful system or novel method (either of which would be great)",eeYSJJGAkg1
74, Nor does it perform enough careful experimentation/detailed analysis to glean any generalizable learnings from their experiences (which would also be great).,eeYSJJGAkg1
75,This paper describes an approach to the TREC COVID Search challenge,eeYSJJGAkg1
76,The proposed method combines an inverted index score using BM25 and a cosine similarity score based on neural representations derived from BioBERT-NLI,eeYSJJGAkg1
77,The paper's main contribution is the proposal of a hybrid system that can perform document retrieval without separate search and re-ranking steps using a pre-trained neural indexer.,eeYSJJGAkg1
78,A large concern about the paper is its incoherency in supporting its main contribution,eeYSJJGAkg1
79,"The paper denotes NIR_{AVG} as its proposed method, but the model is neither the official submitted model (NIR_{[CLS]}) nor the best performing model in the additional run (ClinicalCovid-NLI)",eeYSJJGAkg1
80,What's the rationale behind this choice?,eeYSJJGAkg1
81,"It would have been nice to see quantitative analysis of models' performance regarding ""Where does the model succeed or fail?""  The authors provide a qualitative description of a case where the model had lost points due to unjudged documents, but the explanation's qualitative nature leaves many questions open",eeYSJJGAkg1
82,Is it always the case that the model's low NDCG@10 scores in different topics due to this phenomenon? How does it improve as the base model changes to a stronger model?,eeYSJJGAkg1
83,- The paper does not describe why certain documents were unjudged,eeYSJJGAkg1
84,"One can guess that it's related to other teams' submissions, but it would be better to have the exact criteria described in the document.",eeYSJJGAkg1
85,- Why doesn't Table 2 have the numbers for Round 3?,eeYSJJGAkg1
86,This paper proposes a simple and effective model for the COVID-19 challenge that combines similarity scores computed from neural representations and traditional inverted index scores (BM25),eeYSJJGAkg1
87,"The details are extensively provided however the organization can be improved, as it's unclear what are the motivations for technical choices and baseline choices.",eeYSJJGAkg1
88,My biggest concern is that the contribution of this paper is not clear,eeYSJJGAkg1
89,It seems the biggest discovery is that BM25 score is very important for the model (and potentially for other models that participate in this challenge),eeYSJJGAkg1
90,"While this can be a contribution, but the argument sounds weak to me",eeYSJJGAkg1
91,"Isn't this a widely used tool even outside of this challenge? Furthermore, in the ablation study, when taking out BM25 components, the performance dropped to a point of unusable",eeYSJJGAkg1
92,This questions whether the neural part of this model is effective,eeYSJJGAkg1
93,It looks like the BM25 is doing heavy-lifting there.,eeYSJJGAkg1
94,What does the NIRR model add to this paper? It seems it performed worse than NIR but the paper does not offer any analysis.,eeYSJJGAkg1
95,"It seems another contribution buried in the technical details is that ""the NIR model...performs on par with the RF run with neural reranking, without the need for tasks specific training data."" So the proposed method is actually unsupervised?  I am confused",eeYSJJGAkg1
96,Did it use round 1 judgement during round 2? and in round 3?,eeYSJJGAkg1
97,This article describes IR methods and their evaluation on the context of the TREC-COVID challenge,eeYSJJGAkg1
98,"The article is well written and structured, and the authors do a good job in providing the full context of the challenge, together with their own contributions",eeYSJJGAkg1
99,"Given the space constraints, I believe the information is very well summarised.",eeYSJJGAkg1
100,"With regards to the technical contributions, the methodology they applied to build and evaluate their models is sound, and the error analysis is insightful, providing useful ideas for future work",eeYSJJGAkg1
101,Maybe it would have been interesting to provide more details about the systems in Table 2,eeYSJJGAkg1
102,"For instance, the different NLI and BioBERT versions should be explained, and also the difference between NIR_avg and NIR_cls (not just in the table caption)",eeYSJJGAkg1
103,"I think it would be more relevant to have a paragraph covering the Table2 variations than keeping Figure 2 (the example is interesting, but the figure takes too much space in my opinion).",eeYSJJGAkg1
104,- NIR_avg has slightly different numbers for Round 1 NDCG@10 in Table 2 (0.614) and Table 3 (0.615),eeYSJJGAkg1
105,"- P1: ""gains achieved with neural reranking are debated until recently"": a bit of elaboration would help provide more context.",eeYSJJGAkg1
106,"- P1: ""large neural models pre-trained on language modeling—specifically BERT which uses bi-directional transformer architecture— achieves"": should be ""achieve""",eeYSJJGAkg1
107,"- P4: ""the document at rank 3 for shared no keywords"": remove ""for""",eeYSJJGAkg1
108,"We might say, neither NMF nor HNMF is a novel idea in topic inference, regardless the known LDA in history and powerful Transformers variances (If one use BERT or SciBERT to augment semantics in the research) in current days",toVkbxrY0V5
109,"However, this work is fairly well designed, and I believe it reaches sufficient quality level published in EMNLP workshop.",toVkbxrY0V5
110,The overall scientific design is reasonable,toVkbxrY0V5
111,"In the implementation section, algorithm 2 is carefully designed and it assures the reasonability of topic amount selection",toVkbxrY0V5
112,"It seems very doable for this work to provide ""raw data/codes"" reproducibility, but authors did not mention it",toVkbxrY0V5
113,"---This is just a humble suggestion, though.",toVkbxrY0V5
114,"Introducing Word2vec in WMD makes sense, that is true",toVkbxrY0V5
115,"However, in the meantime, currently there are quite a lot new focuses in semantics representation of phrase or sentence, instead of single lexicon",toVkbxrY0V5
116,Conventional method could be augmented with new idea so as to explore more in depth.,toVkbxrY0V5
117,"Somehow, some baseline methods could be introduced, implemented and tested",toVkbxrY0V5
118,"Before jumping into the analysis of the final 52 (sub-)topics, it is of utmost importance to make the HNMF algorithmic part convincing",toVkbxrY0V5
119,This paper presents a topic modelling system based on hierarchical nonnegative matrix factorisation,toVkbxrY0V5
120,"The paper itself is very well written and structured, there is a clear logical progression between sections and ideas",toVkbxrY0V5
121,"The accompanying website is easy to use, though can be improved in terms of visual representation.",toVkbxrY0V5
122,"Though the paper does not introduce a novel method, it makes several meaningful contributions including the following:",toVkbxrY0V5
123,"The authors augment Kaggle's COVID-19 dataset by additionally searching 4 databases, removing non-English publications and articles without abstract or full text, which helps to build more meaningful and relevant topic models",toVkbxrY0V5
124,The resulting model helps to avoid flat structure and discover meaningful subtopics on as many as three levels of nesting,toVkbxrY0V5
125,Some subtopics can belong to several major topics and the authors provide examples to justify this,toVkbxrY0V5
126,"Overall, such hierarchical structure can be useful for researchers to explore the topics of interest in more detail.",toVkbxrY0V5
127,"The topics are thoroughly analysed in terms of major issues discussed in COVID-19 literature, thus presenting a valid use-case scenario",toVkbxrY0V5
128,"However, there are some weak points in terms of reproducibility and implementation:",toVkbxrY0V5
129,"The corpus is not provided, and it is impossible to reproduce based on the information in the article.",toVkbxrY0V5
130,It is not clear how the texts were preprocessed,toVkbxrY0V5
131,"The authors state that ""words deem to be irrelevant such as “copyright” or “et al” are removes”, but they provide no criteria for this judgment, such as a publicly available stop-words list or, say, 50 most frequent words in the data set",toVkbxrY0V5
132,"Again, this makes the paper impossible to reproduce and can potentially affect the results of the topic model",toVkbxrY0V5
133,"For example, if the authors manually checked the texts for “irrelevant” words and then removed them, that would lead to much more relevant and coherent results and thus we’d overestimate what the model can do.",toVkbxrY0V5
134,"More of a suggestion - though the topics look coherent by “eyeballing”, you might consider using a more reliable coherence metric than Mimno et al",toVkbxrY0V5
135,"2011, which has the worst correlation with human evaluation (Röder, M., Both, A., & Hinneburg, A",toVkbxrY0V5
136,Exploring the space of topic coherence measures,toVkbxrY0V5
137,In Proceedings of the eighth ACM international conference on Web search and data mining (pp,toVkbxrY0V5
138,The paper describes the creation of a dataset with scientific papers about COVID-19 that have been divided in a three-layer structure based on the topics covered,toVkbxrY0V5
139,The authors have used hierarchical nonnegative matrix factorization to organize the topics,toVkbxrY0V5
140,A total of 52 major topics were found,toVkbxrY0V5
141,The authors evaluated the results trough different measurements,toVkbxrY0V5
142,"The work is of high interest given the ability of ""classify"" papers based on specific and concrete topics, allowing to filter the large amount of literature that has been produced in the last months with respect to COVID-19, being an useful tool",toVkbxrY0V5
143,"My only concern is that I cannot see where is possible to download the dataset used to create the topic structure, or if could be possible to use the tool for new articles classification that will appear in the future.",toVkbxrY0V5
144,"This paper proposes a dataset that is annotated via a standard active learning framework, aiming at providing supervision for models to filter COVID-19 articles that are out of expert interests",4nEHDnoLAmK
145,This paper is well-motivated and well-written,4nEHDnoLAmK
146,Some elaborations appear to be unnecessarily extensive.,4nEHDnoLAmK
147,"When the paper says ""...however, the precision of the aforementioned query is highly arguable"", there should be some statistics to justify this point",4nEHDnoLAmK
148,"Afterall, this point establishes the motivation of this paper",4nEHDnoLAmK
149,"In Algo1, line 5, ""i<= max"" should be ""i <= t_max""",4nEHDnoLAmK
150,"Further, it would be useful to present a curve of the acc(f_i) over time",4nEHDnoLAmK
151,This would illustrate the effectiveness of using active learning,4nEHDnoLAmK
152,It would be interesting to see if this is a log-like curve or some bumpy curve.,4nEHDnoLAmK
153,"In footnote 10, it seems the data is ONLY available during the review time? I want to make sure if this is the case",4nEHDnoLAmK
154,"For a closed dataset, even if it is available during the reviewing period, I would give it an immediate rejection, no matter how good the work is.",4nEHDnoLAmK
155,What is Fig 5? Not mentioned anywhere.,4nEHDnoLAmK
156,It would be perfect if this paper can even gently touch on this point: What is the impact of this dataset on other COVID challenges? This would highlight the usefulness of this data,4nEHDnoLAmK
157,There could be some domain issue that hinders its application elsewhere,4nEHDnoLAmK
158,"While my rating is leaning positive to acceptance, it depends on the authors' response on point 3 above.",4nEHDnoLAmK
159,This paper introduces a task of filtering scientific literature for relevant artciles,4nEHDnoLAmK
160,"The authors frame the task as a binary classification problem, and use both BioBERT based classifier and conventional classifiers to solve the task",4nEHDnoLAmK
161,The second contribution is that the authors release an expert-curated benchamark set for the task.,4nEHDnoLAmK
162,"Active learning is used to develop the training set, where BioBERT based classifier is used as the base classifier.",4nEHDnoLAmK
163,"- Although the proposed task focus on meeting the information needs from medicine, biology, chemistry and bioinformatics researchers, the task of filtering out scientific literature should have broader audiences",4nEHDnoLAmK
164,The proposed framework is generic and should be able to find use cases in other domains.,4nEHDnoLAmK
165,- The authors mention the dataset is available upon request,4nEHDnoLAmK
166,- The binary classification setting seems oversimplified,4nEHDnoLAmK
167,"The authors have defined several criteria which, in my opinion, can be used as targeted labels, because these criteria seem to target different groups of users",4nEHDnoLAmK
168,"For example, practitioners who focus on treating patients may feel articles beloing to criteria 3 is relevant but those to criteria 5 irrevant",4nEHDnoLAmK
169,"If the task is framed as a multi-class classification problem, it may further solve the overload issue.",4nEHDnoLAmK
170,- It would be interesting to see the performance of a simplest baseline that uses only query in Figure 3,4nEHDnoLAmK
171,"In other words, you can use only the IF part of your Algorithm 2 (line 4) and assign all others `relevant'.",4nEHDnoLAmK
172,- Page 3: 'keyword query is used on the metadata of the articles' vs,4nEHDnoLAmK
173,"Figure 1 caption 'Papers that match on these keywords in their title, abstract, or full text are included in the dataset.'",4nEHDnoLAmK
174,Are these two conflicting? Is full text used?,4nEHDnoLAmK
175,"- Page 4: Line 4 in Algorithm 1, measuare accuracy on which set?",4nEHDnoLAmK
176,"- Page 4: You didn't mention which classifier you use in Section 3, until in Section 5, you say the BioBERT based classifier is used as the base classifier",4nEHDnoLAmK
177,Maybe make it clear in Section 3.,4nEHDnoLAmK
178,- Page 4: is the seperate regression set randomly sampled?,4nEHDnoLAmK
179,- Page 5: The first part of Algorithm 1 is confusing,4nEHDnoLAmK
180,Should the training of BioBERT classifier not involve active learning? and the classifier is trained only once on the complete training set? The second part of Algorithm 2 (line 3-8) looks unnecessary.,4nEHDnoLAmK
181,"- Page 6: Table 2, not sure why the bottom line of the first column is missing",4nEHDnoLAmK
182,"Also, you may add \bottomline to Table 3.",4nEHDnoLAmK
183,"- Page 6: not sure what Figure 5 is for, since you didn't mention it at all in the text.",4nEHDnoLAmK
184,"- Table 2, 3: reporting only results on Relevant class should be enough, because it is a binary classification task and relevant class is what we really care.",4nEHDnoLAmK
185,- Page 7: suggest to simplify Section 6,4nEHDnoLAmK
186,"For example, delete the first paragraph, which seems no need to repeat.",4nEHDnoLAmK
187,"- Page 8: suggest to add citation after batch-aware methods, or explain what it is ",4nEHDnoLAmK
188,"- Page 8: 'By conducting novel keywords extraction from the recent scientific literature, the CORA keyword-based query can be enhanced automatically with new terminology.' this part sounds not about future work",4nEHDnoLAmK
189,- The section 4 may benefit from rewriting,4nEHDnoLAmK
190,It is a bit of confusing,4nEHDnoLAmK
191,"My understanding is at this stage you fine-tune BioBERT based classifier on the complete training set, and this process does not involve training the classifier several times (such as the while loop in Algorithm 1)",4nEHDnoLAmK
192,The authors generated a benchmark dataset of relevant scientific information to COVID,4nEHDnoLAmK
193,They used active learning to build the training set and classified literatures into COVID relevant and non-relevant with high precision and recall,4nEHDnoLAmK
194,The paper is well written and includes sufficient technical details,4nEHDnoLAmK
195,"The authors not only evaluated the performance the purposed method, but also evaluated the benchmark dataset using other classifiers",4nEHDnoLAmK
196, The classifier fine-tuned on BioBERT outperforms other classifiers,4nEHDnoLAmK
197,Please clarify the following information in the paper:,4nEHDnoLAmK
198,The purpose of using active learning for classification is to reduce the number of labeled samples,4nEHDnoLAmK
199,Please provide the number of samples labeled by experts in Algorithm 1 and show the performance of classifier with the increase of labeled samples,4nEHDnoLAmK
200,The performance of classifier on two relevant and non-relevant sets were reported,4nEHDnoLAmK
201,"In each of set, relevant and non-relevant literatures were included",4nEHDnoLAmK
202,What is the purpose of generating two sets?  ,4nEHDnoLAmK
203,Two datasets were used: training and regression set,4nEHDnoLAmK
204,Both datasets were annotated by expert,4nEHDnoLAmK
205,What is the purpose of using two datasets and why only the regression dataset was used to compare with other classifiers?,4nEHDnoLAmK
206,The work compares traditional topic models based on word tokens with topic models based on medical concepts and suggests several ways to improve topic coherence and specificity.,c-TkXmZC-Yk
207,Latent Dirichlet allocation is the most commonly used method for topic-based analysis of documents,c-TkXmZC-Yk
208,"The authors have pointed out that conventional LDA models work well for topically-diverse document collections but they are less informative in narrow, knowledge-rich domains like medicine and specifically when the corpus consists of documents related to one broad topic, such as coronavirus-related literature",c-TkXmZC-Yk
209,The experiments have been conducted on the CORD-19 dataset,c-TkXmZC-Yk
210,"Three different models have been considered based on three different input representations of the text: word tokens using NLTK tokenizer, concepts based on the Unified Medical Language Systems concepts and non-generic concepts with more general concepts filtered out.",c-TkXmZC-Yk
211,"Human evaluation was performed by two annotators to evaluate the quality of topics by labelling them as incoherent, specific or generic",c-TkXmZC-Yk
212,"Although the definitions of these labels are quite vague, the Cohen’s Kappa measure of inter-annotator agreement was 0.87",c-TkXmZC-Yk
213,The necessity of human evaluation has been well explained.,c-TkXmZC-Yk
214,"After the models are trained, the dataset is subdivided based on the most prevalent topic in each document and then an LDA model was trained on each subset",c-TkXmZC-Yk
215,Two approached have been proposed for further experimentation: first one based on non-generic concepts and the second one based on non-generic concepts re-weighted based on the log-likelihood.,c-TkXmZC-Yk
216,It has been empirically shown that non-generic concepts based topic modelling makes the identified topics as more specific and less incoherent and less generic.,c-TkXmZC-Yk
217,In this work the authors present different approaches to improve the topic coherence and specificity of topic representations using LDA with an application to the CORD-19 dataset,c-TkXmZC-Yk
218,The authors do a great job in framing the problem and presenting their approach,c-TkXmZC-Yk
219,"Most of the details of their methodology are found in the presented text (document preparation, number of topics), but a few things could be expanded further as other reviewers have pointed out",c-TkXmZC-Yk
220,The evaluation part is very brief and key details about the annotation/evaluation instructions and specifics of how the topics were separated into generic and specific is definitely needed,c-TkXmZC-Yk
221,"Did the manual reviewers had access to only the abstract/first 2 paragraphs of paper? or did they had access to the full paper to make their decision on topic relevance? the agreement between reviewers is quite excellent, so a bit more in-depth discussion about this would have been nice to have",c-TkXmZC-Yk
222,The point of using humans instead of automatic metrics for the topic coherence evaluation is essential for this kind of work,c-TkXmZC-Yk
223, The experimental evaluation nicely characterizes the need of a certain 'guide' (while not being exactly guided-LDA) for the LDA models to be coherent by feeding them concepts of higher relevance in the clinical context,c-TkXmZC-Yk
224,Table 1 is an excellent result,c-TkXmZC-Yk
225,"The topic tables on page 4 are nice, but should have been reduced as this didn't leave much space to the authors for a longer discussion and conclusion sections This last section seems to be missing and replaced with an odd ""Related Work"" section at the end which is not really a satisfactory conclusion to this paper as some of the test should be featured earlier on the paper",c-TkXmZC-Yk
226," Overall, very solid start of the paper that seems to run out of space near the end, and leaves important details out.",c-TkXmZC-Yk
227,This paper describes how an LDA topic model was improved by using concepts,c-TkXmZC-Yk
228,"The evaluation - performed by humans - shows that the more refined topic models (using medical concepts) are indeed ""better"", meaning here more specific and less incoherent.",c-TkXmZC-Yk
229,The conclusion is not by itself surprising: LDA models are known to be very sensitive to pre-processing (including lemmatization and stop-word removal),c-TkXmZC-Yk
230,This is one of the reasons why embeddings became so powerful as they are less impacted by that,c-TkXmZC-Yk
231,"In this sense, comparison with a neural topic model would have been an interesting, and helpful to guide practitioners as well as to have a data-point of the usefulness of old-and-tested LDA vs more novel models.",c-TkXmZC-Yk
232,I found the paper an interesting experience nugget..,c-TkXmZC-Yk
233,something which we don't see so much and which practitioners might benefit,c-TkXmZC-Yk
234,"The substance however is very limited, as it basically consists of a report of a human evaluation campaign",c-TkXmZC-Yk
235,"In addition, I have doubts about the following:",c-TkXmZC-Yk
236," - what exactly are the documents that are provided as input to the concept-LDA? Are the words enriched with concepts, or are those documents just a sequence of concepts?",c-TkXmZC-Yk
237," - how is a topic represented to an evaluator? By its 5 most frequent words, or some other way?",c-TkXmZC-Yk
238," - so what? It is not clear to me why having more ""specific"" topics would be helpful in the end",c-TkXmZC-Yk
239,"Can you relate the 7 specific word-topics to some of the concept-tokens (eg, by comparing the probability distribution over words)? Do they subdivide the space further, or is it a totally different soft clustering? How will this help the final application?",c-TkXmZC-Yk
240,This paper proposes an improvement to LDA-based topic modelling by using only important concept words,c-TkXmZC-Yk
241,"It proposes to test whether limiting the vocabulary to UMLS concepts, and a smaller set of non-generic UMLS concepts improve the topics extracted by an LDA method on the CORD-19 dataset",c-TkXmZC-Yk
242,"It evaluates the quality of these topics through manual evaluation as incoherent, generic or specific",c-TkXmZC-Yk
243,The paper finds that non-generic UMLS concepts provides improved topics.,c-TkXmZC-Yk
244,This is an interesting and well-written paper that I found easy to understand,c-TkXmZC-Yk
245,"While I do find it believable that non-generic UMLS concepts improve over normal LDA methods, I think this paper could do more to evaluate this compared to other methods",c-TkXmZC-Yk
246,"Furthermore, it is not clear what this paper adds to the COVID-specific text mining area",c-TkXmZC-Yk
247,I would suggest that it could be fleshed out more and sent to a more general NLP venue,c-TkXmZC-Yk
248,The ideas proposed in Section 4.2,c-TkXmZC-Yk
249,seem intriguing but are too quickly explained and explored.,c-TkXmZC-Yk
250,- The core issue is that this paper cites multiple other extensions to LDA but doesn’t attempt to evaluate them as comparisons.,c-TkXmZC-Yk
251,"- Just a note, but why aren’t both evaluation annotators authors on the paper?",c-TkXmZC-Yk
252,- The annotation task didn’t sound pretty vaguely defined so I’m impressed by the high agreement between annotators,c-TkXmZC-Yk
253,"- Anti-HIV treatments for cancer seems like an odd topic, especially in a coronavirus corpus",c-TkXmZC-Yk
254,"- The Data section mentions concepts and non-generic terms before they are defined, which is confusing",c-TkXmZC-Yk
255,"- I know it was likely down to the page limit, but it’s weird to have the concluding remarks in the Related Work section.",c-TkXmZC-Yk
256,- I think a stronger case has to be made for fixing the number of topics across all methods (to 25),c-TkXmZC-Yk
257,"While it makes the methods comparable using raw counts, it isn’t clear that good methods won’t be unfairly penalised by this.",c-TkXmZC-Yk
258,This submission proposes a new Korean-English test set and multilingual neural machine translation model for contributing to the translation task of COVID-19 related texts,U5luH7UiQw6
259,The single model was heavily trained on 4 selected languages from Corona Crisis Corpora (TAUS 2020) and a Korean corpus via back-translation,U5luH7UiQw6
260,The authors implement the model with a standard toolkit with a few adaptations based on the recent work,U5luH7UiQw6
261,"Reasons to accept: The proposed model beats against the state-of-the-art (SOTA) models (results were from Berard et al., 2019; Ng et al., 2019, Bawden et al., 2019) on major test sets",U5luH7UiQw6
262,The model has a significant performance improvement than the publicly available OPUS-MT model on the handpicked Korean-English sentences,U5luH7UiQw6
263,"The Korean-English test set is valuable and supplementary to the existing multilingual translation corpora, Corona Crisis Corpora",U5luH7UiQw6
264,A significant contribution is the new test set,U5luH7UiQw6
265,"However, the data quality is a big concern",U5luH7UiQw6
266,"First, how the sentences were handpicked is not clear",U5luH7UiQw6
267,"For example, the KCDC document has many pages, but the selected number is only 258 sentences",U5luH7UiQw6
268,Does the sentence share similar format with the training set? Will the authors provide detailed guidelines that the confidence of data selection? Did the translators have a high agreement on the translation quality?,U5luH7UiQw6
269,"The TAUS 2020 provides 6 languages (checked at 09-28-2020), including the 4 languages in this paper and the other 2 languages (Russian and Chinese)",U5luH7UiQw6
270,I am not sure why the authors selected the 4 and left the other 2 languages,U5luH7UiQw6
271,"Is that because when the authors trained the model, those two languages were not available?",U5luH7UiQw6
272,"This work presents a pretrained multilingual neural machine translation (MNMT) model, baseline evaluations of this model on an existing COVID-19 MT dataset called Corona Crisis Corpora (TAUS 2020), and a new test set for Korean-English sentence pairs to make up for lack of this language pair in the TAUS 2020 dataset",U5luH7UiQw6
273,"- Not enough people are working in this space, and the authors should be commended for tackling a difficult but important problem (lack of access to foreign language papers can be harmful especially with so much important knowledge about the virus being generated in different countries)",U5luH7UiQw6
274,"- Large pretrained models are costly to train, but easy to use",U5luH7UiQw6
275, Releasing such models is a service to the community & makes it easy for others to get started in this area of research,U5luH7UiQw6
276,- Translation datasets are difficult to curate & valuable ,U5luH7UiQw6
277,"- How did you guarantee the quality/faithfulness of the Korean-English translations, given that these contained sentences from biomedical abstracts?  Did the recruited translators have relevant biomedical background?",U5luH7UiQw6
278,"- To help others gauge the cost/effort to produce such annotations, would it be possible to add more information about the total annotation hours spent & cost to hire these experts?  ",U5luH7UiQw6
279,"The paper describes a new multilingual multidomain machine translation model, and a new Korean-English test set",U5luH7UiQw6
280,"On a neural-network level , the model itself seems to be fairly standard, with a few tweaks based on recent suggestions from the literature",U5luH7UiQw6
281,"The training data is of more interest - they have included the recent Corona Crisis Corpora, biomedical data where available (oversampled by a factor of 2), back-translated data for Korean (the language with the least data available), and domain tags to indicate whether the data is biomedical or not.",U5luH7UiQw6
282,"Their Korean-English test corpus was developed to test performance in the Covid-19 domain, and because Korean-English was the only language pair not covered by the Corona Crisis Corpora",U5luH7UiQw6
283,"It consists partly of official guidelines and reports from relevant governmental bodies, and partly of abstracts from biomedical papers",U5luH7UiQw6
284,Their model was tested against state-of-the-art systems on three test sets,U5luH7UiQw6
285,"On ""generic"" test sets (News, IWSLT) it generally outperforms the state of the art, but does slightly worse in the biomedical domain",U5luH7UiQw6
286,"They have also evaluated their system using their Korean-English test set, where it outperforms publically-available models by a substantially wider margin than on the pre-existing test sets",U5luH7UiQw6
287,This may suggest that the model is particularly well-adapted to the Covid-19 domain.,U5luH7UiQw6
288,"Reasons to accept: The model they have developed looks like it performs well, and the evaluation on the Korean-English dataset suggests it should do particularly well in the Covid-19 domain",U5luH7UiQw6
289,The authors stress the multi-lingual nature of the system as an advantage,U5luH7UiQw6
290,"I wonder also whether the multi-domain nature of the system is an advantage - Covid-19 news is likely to have more in common with the biomedial domain than most news text does, and the literature relevant to the ""international impact that this crisis is causing, at asocietal, economical and healthcare level"" which they are studying is likely to have more in common with newswire text than most biomedical text does",U5luH7UiQw6
291,Both the model and the test set look like useful resources for the community.,U5luH7UiQw6
292,Reasons to reject: Two of the three results in the biomedical domain are behind the state of the art,U5luH7UiQw6
293,"The authors say ""Note the SOTA models were trained to maximize performance in the very specific Medline domain, for which training data is provided",U5luH7UiQw6
294,"While we included this data in our tagged biomedical data, we did not fine-tune aggressively over it."" This raises the question as to whether the systems optimised for biomedical text are better for the biomedical texts this model is intended for, and whether the other advantages of this model are compelling enough to overcome this.",U5luH7UiQw6
295,"In conclusion, this paper presents two useful resources to the NLP community, and as such is worthy of acceptance.",U5luH7UiQw6
296,"This paper proposes a real-time Twitter visualization tool which consists of three components: Twitter classification, geolocation extraction and interactive visualization",CyeMZ_gutEn
297,I agree that the proposed system can be of great value in practical use,CyeMZ_gutEn
298,"However, a lot of critical information is not included in this paper and without these information, it is hard to determine the contribution of this paper",CyeMZ_gutEn
299,"First, there exist a lot of twitter mapping/visualization works, e.g., real-time crisis mapping of natural disasters using social media and this one: https://blog.tensorflow.org/2019/09/disaster-watch-crisis-mapping-platform.html",CyeMZ_gutEn
300,"All these tools have similar structure as that of the proposed tool: extract location of the twitter, perform classification on the twitter content and visualize the classified twitters in a map",CyeMZ_gutEn
301,The only difference to me is that the target labels in the classification layer is different,CyeMZ_gutEn
302,The author should include a comprehensive review of these visualization tools and highlight the differences between this paper and previous tools,CyeMZ_gutEn
303,"Second, a claim in this paper is that using negative L2 distances in the output classification layer outperforms using traditional inner product similarity",CyeMZ_gutEn
304,"However, there is not enough experiments to support this claim",CyeMZ_gutEn
305,The marginal improvement in terms of validation accuracy (76.84 vs 76.35) is not convincing to me.,CyeMZ_gutEn
306,"Finally, as the proposed system works in an interative and real-time manner, there should be an evaluation on the latency of the system.",CyeMZ_gutEn
307,Even though the idea is interesting,CyeMZ_gutEn
308,But they are several issues that need to be addressed before considering it for publication,CyeMZ_gutEn
309, for example  “training data” is not well described,CyeMZ_gutEn
310,"The author mentioned that the annotated data is from Middle Eastern Respiratory Syndrome (MERS) outbreak but there is no clear connection with Covid-19 data, there are several Covid-19 datasets and the author did not mention why did not use them",CyeMZ_gutEn
311,Main point: author did not report any classifier’s performance or any kind of evaluation metrics,CyeMZ_gutEn
312, even though it is short paper but at least a table explaining the performance metrics and how the classifier performs,CyeMZ_gutEn
313,The classification is heart of this visualization and the performance metric s are must for any NLP or applied NLP research paper.,CyeMZ_gutEn
314,"This work presented an interactive visualization system for COVID information including the number of affected people, prevention, treatment, death reports, etc",CyeMZ_gutEn
315,The system was based on Tweet streaming data with 4 COVID related filtering keywords,CyeMZ_gutEn
316,To classify tweets into different information categories (eg,CyeMZ_gutEn
317,"number of affected people), the BERT-based pre-trained model was fined-tuned on the 2014 MERS dataset and the L2 layer was employed as an output layer",CyeMZ_gutEn
318,"To further generate the information distributions on the global map, geolocations were extracted with name entity recognition from the text contents of tweets.",CyeMZ_gutEn
319,"In this reviewer's view, this work is well written",CyeMZ_gutEn
320,This novel system provides a live information distribution that presents the changes in the pandemic situation,CyeMZ_gutEn
321,"To extract text-based geolocation, are tweets with misinformation filtered out? People may discuss things in other places, which may not true",CyeMZ_gutEn
322,"For the tweets that are not the first-person narrative, how do the maps of 'affected_people', 'deaths_reports' reflect the changes of the situation?",CyeMZ_gutEn
323,"The authors present an analysis of the prevalence of the 6 Ekman emotion classes in Portuguese tweets, over the month of March 2020",tRaHlwUKmLU
324,"The hypothesis they explore is that ""negative emotions would intensify as the pandemic progresses""",tRaHlwUKmLU
325,"This is subsequently made more precise: ""tweets would reflect more negative emotions throughout the pandemic, up to its peak""  In the conclusions, it is stated ""the evolution of the six basic emotions ..",tRaHlwUKmLU
326,"is correlated with the disease evolution"" and that ""more negative tweets posted in the beginning of the pandemic, up to its peak""",tRaHlwUKmLU
327,"However, the data don't really support the conclusions, first because no direct ""correlation"" is measured, and second because the negative emotions do not in fact seem to intensify at all up to the peak in late March, but rather much earlier in the month",tRaHlwUKmLU
328,"In addition, insufficient context is provided -- what is the level of relative emotion in March, as compared to February and April? You have data Feb-May, it could be used.",tRaHlwUKmLU
329,"If the data set is a primary contribution, then some analysis of the labelling is needed, including some assessment of the quality of the emotion classification using the identified method",tRaHlwUKmLU
330,"As other reviews have pointed out, the count-based approach to measuring is oversimplistic; while it may be okay for large-scale statistical studies on trends where some noise can be tolerated, if it is intended to be used as a labelled dataset it must be more rigorously validated",tRaHlwUKmLU
331,"If the collection of COVID-19 Tweets tied to Portugal is the contribution, some additional details are required",tRaHlwUKmLU
332,Are English-language tweets ignored? Is there some way to assess the effectiveness of the geolocation strategy?,tRaHlwUKmLU
333,"In all, it is an interesting direction, however, even for a short paper the 'preliminary' analysis should be approach in a more considered manner, or the contributions that the authors claim should be clarified",tRaHlwUKmLU
334,"- is ""decreted"" a word in English?",tRaHlwUKmLU
335,"- ""natural language processing and machine learning technologies offer exciting possibilities for the improvement of both population-level and individual-level mental health"" -- is it really improvement of mental health that is targeted with this work, or rather monitoring of mental health? (How that information is used to improve mental health seems to require more than NLP.)",tRaHlwUKmLU
336,- why does Figure 3 have a y axis that goes up to 12 (120%) and at least one point that appears to be above 10? Labels for the axes are needed,tRaHlwUKmLU
337,What is the normalization assumed to produce this Figure? ,tRaHlwUKmLU
338,Ofoghi et al (2016) Towards early discovery of salient health threats: A social media emotion classification technique,tRaHlwUKmLU
339,[Also see related/citing papers listed at https://pubmed.ncbi.nlm.nih.gov/26776213/ ],tRaHlwUKmLU
340,Also consider from the Part 1 of this workshop:,tRaHlwUKmLU
341,The paper aims to conduct emotion analysis on English and Portuguese Tweets related to COVID-19 and shows that the negative emotion trend corresponds to some of the events occurred during the pandemic.,tRaHlwUKmLU
342,"While the objective of the research - which is to monitor the mental health of the social network users - is interesting, I am not convinced that the preliminary experiment conducted in the paper can serve as a stepping stone for that.",tRaHlwUKmLU
343,My concerns about the paper are:,tRaHlwUKmLU
344,"Although the authors went to great lengths to gather and filter relevant Tweets, I am not sure if the size of the resulting Tweets is large enough to extract any meaningful insight.",tRaHlwUKmLU
345,"For example, while Table 2 shows the number of Tweets, it is unclear how many unique users were involved.",tRaHlwUKmLU
346,The authors should consult the recent related work and techniques in the field of sentiment/emotion analysis,tRaHlwUKmLU
347,Emotion analysis using keyword counting is very basic and cannot capture the overall emotion prevalent in the Tweet accurately.,tRaHlwUKmLU
348,The level of the analysis is limited,tRaHlwUKmLU
349,The authors present a single figure (Fig,tRaHlwUKmLU
350,3) as a result of the analysis where the normalized counts for the six emotions are shown within the period of March.,tRaHlwUKmLU
351,"In the figure, the only positive emotion, Joy is sometimes more prevalent than other individual negative emotions even though the Tweets are all about the pandemic",tRaHlwUKmLU
352,It would be interesting to see why this is so.,tRaHlwUKmLU
353,I am not sure what lessons can be learned from the current formulation of the experiment,tRaHlwUKmLU
354,"Of course, it is expected that you would see more negative emotions when you look at Tweets about an event as negative as COVID-19",tRaHlwUKmLU
355,The authors should reconsider the direction of the experiment as proposed by the AnnonReviewer2.,tRaHlwUKmLU
356,The authors provide a basic sentiment analysis of a set of tweets that have been generated in portugal for month March 2020,tRaHlwUKmLU
357,They claim that sentiment analysis of social media posts can be used as a  tool for locating individuals who suffer with psychological issues caused by the covid-19 pandemic.,tRaHlwUKmLU
358,- The authors original aim is very interesting,tRaHlwUKmLU
359,"Based on a psychology theoretic framework, they want to locate people that might have mental health issues.",tRaHlwUKmLU
360,- The authors indeed show a correlation between negative sentiment and the diffusion of covid-19 for March 2020,tRaHlwUKmLU
361,- The authors only compare time-series plot to support their claims,tRaHlwUKmLU
362,Even a simple correlation metric can provide additional insights,tRaHlwUKmLU
363,"For example, although the virus is diffused and reaches it peak in the end of march, negative emotion in tweets does not increase",tRaHlwUKmLU
364,- The authors analyze only tweets related to covid-19,tRaHlwUKmLU
365,"In my opinion, it is straightforward that negative emotions will be associated to tweets talking about a virus",tRaHlwUKmLU
366,"Authors should look at an individual's tweets in general, and see if COVID-19 waves are related to negative emotions overall",tRaHlwUKmLU
367,"Mental health issues are externalized in the totality of an individual's interactions, and not specifically when they decide to talk about a virus.",tRaHlwUKmLU
368,"- Moreover, even a healthy person can be afraid of a deadly virus",tRaHlwUKmLU
369,"The analysis bases it self in a very simple theoretic framework, and needs a more solid framework that can lead to the detection of individuals with mental issues.",tRaHlwUKmLU
370,"- Based on the last point, the authors do not address at all how they would proceed after they would detect a person who tweets very negatively",tRaHlwUKmLU
371,What does this information tell them? Would they contact the individual? Report authorities that specific regions might face serious issues?,tRaHlwUKmLU
372,"Although the idea is very interesting, it is not operationalized adequately",tRaHlwUKmLU
373,"I propose to create a more solid framework (better sample of tweets, a theory that connects the different feelings to psychological issues), analyze tweets during multiple waves of covid-19, and use more sophisticated statistical tools (e.g",tRaHlwUKmLU
374,"time-series econometric models, potentially panel data that allow to find associations at the city level)",tRaHlwUKmLU
375,"In this way, they can create a pipeline that provides insights about mental health and covid-19.",tRaHlwUKmLU
376,in the abstract it says twees instead of tweets;,tRaHlwUKmLU
377,in the preliminary results it is french instead of franch;,tRaHlwUKmLU
378,"plot visualizations are poor, they could be improved.",tRaHlwUKmLU
379,The paper describes an application of sentiment analysis for the dutch messages from three social platforms related to the COVID-19 measures,37zyB5yuPXi
380,"The paper is well written, the introduced analysis is definitely needful and interesting",37zyB5yuPXi
381,"However, the paper has the following issues:",37zyB5yuPXi
382, Authors do not describe the classification algorithm that was used for the stance analysis,37zyB5yuPXi
383,"I realize that the authors applied an external tool, but still a brief explanation is needed",37zyB5yuPXi
384,"According to my understanding, authors trained FastText word vectors on their data",37zyB5yuPXi
385,"However, authors do not explain why they do not use pre-trained vectors, despite the very well known fact that word embedding trained on a big data performs better than trained on a specific small data",37zyB5yuPXi
386," Also, the authors mix training word vectors with classification, which is confusing",37zyB5yuPXi
387,"If the used classification model contains an embedding layer, it also needs to be explained",37zyB5yuPXi
388," Due to a noisy content in social media, sarcasm, and other factors that might affect the annotation, I assume that the annotator encountered some ""difficult"" cases",37zyB5yuPXi
389,How these cases were handled? ,37zyB5yuPXi
390,"What is the accuracy level of the used sentiment analysis (polarity)? Despite the method that was used is unsupervised, its evaluation on some test dataset is needed (or, if it was evaluated by developers on a similar domain, the relevant paper must be cited and its performance must be reported).",37zyB5yuPXi
391,10-fold cross validation is used for evaluation and NOT for training,37zyB5yuPXi
392,Which model (trained on what?) was eventually used for automatic labeling of a new data? ,37zyB5yuPXi
393,"Which classes were ""difficult"" for your classifier (were misclassified)? Accuracy per class can answer this question",37zyB5yuPXi
394,"Also, I think that reporting validation accuracy is redundant",37zyB5yuPXi
395,"A small typo: ""the COVID-19 related tweets *is->are* generally.",37zyB5yuPXi
396,"This paper describes an analysis of COVID-19-related text messages in the Dutch language obtained from three online sources (Twitter, Reddit, Nu.nl; relevant messages were filtered using a selection of COVID-19 related keywords (Twitter) or based on specific topics (Reddit, Nu.nl)) from February to July 2020",37zyB5yuPXi
397,Sentiment polarity analysis (using a lexicon-based approach) as well as stance detection for the topics of social distancing and the use of face coverings (using a supervised learning approach based on fastText) were conducted on the retrieved messages,37zyB5yuPXi
398,"For the latter, subsets of the retrieved texts were sampled based on keyword search and manually annotated by a single human annotator",37zyB5yuPXi
399,The findings show some alignments between COVID-19-related events and the corresponding reception on such social media platforms,37zyB5yuPXi
400,"For example, the first introduction of lockdown measures in the Netherlands in March 2020 led to a decrease in polarity on the Twitter data, and the first release measures in May 2020 caused the polarity to peak on the observed dataset.",37zyB5yuPXi
401,The topic and approach presented in this paper can be very interesting to the community,37zyB5yuPXi
402,"However, it is unclear whether the collected online text data can be interpreted as representative for the “broader Dutch public” (as claimed in the paper) since only online data are used",37zyB5yuPXi
403,"For the stance detection, the used dataset is relatively small (especially for the face covering topic), and it would be interesting to see how a simpler approach (e.g., a linear model using bag-of-words features) compares to the neural network-based approach.",37zyB5yuPXi
404,"Furthermore, some statistics (e.g., average sequence length) on the text messages obtained from the different sources would be helpful, since the stance detection system is trained only on parts of the collected data",37zyB5yuPXi
405,"In Figure 2, for example, the stance detection system is trained only on the Twitter data and evaluated on all three datasets.",37zyB5yuPXi
406,"It would also be interesting to see the polarity results on the other datasets (e.g., in the Appendix), only Twitter data are shown in the paper.",37zyB5yuPXi
407,"Section 3.2: For the stance detection task, is there a reason for why only Twitter and Nu.nl data was used for the human annotation?",37zyB5yuPXi
408,Which topics and articles were considered for the analysis of Reddit and Nu.nl data?,37zyB5yuPXi
409,In Section 2 different tenses are mixed up when discussing related work.,37zyB5yuPXi
410,The axes in Figure 1 should be labelled and explained in more detail,37zyB5yuPXi
411,"Also, the letters A and B are hardly visible in the figure.",37zyB5yuPXi
412,Section 3.2: Footnote should come after punctuation.,37zyB5yuPXi
413,Section 4.1: Missing word “Some interesting links can [be] found…”,37zyB5yuPXi
414,This work described a series of public sentiment analysis regarding Dutch governmental policies,37zyB5yuPXi
415,"The study was based on the datasets from three types of social media: Twitter, Reddit, and Nu",37zyB5yuPXi
416,Datasets are collected and filtered using a set of COVID related keywords from late February 2020 to July 2020,37zyB5yuPXi
417,Sentiment analysis included two parts: 1) polarity analysis based on 3918 Dutch polarity words; 2) stance analysis--annotating and then classifying posts related to social distancing and face mask-wearing,37zyB5yuPXi
418,"For stance analysis, the trained classifier (with fastText) is applied to the entire dataset",37zyB5yuPXi
419,"The study showed the policy support value declined until June and then increased, which was consistent with the pandemic situation in the Netherlands",37zyB5yuPXi
420,"For the Reddit dataset in Table 2, is it the number of submissions(initiating posts)?",37zyB5yuPXi
421,"Reddit data is based on subreddits, can you please clarify the subreddits that you were using?",37zyB5yuPXi
422,Is it trustworthy to have only one annotator without any adjudication process?,37zyB5yuPXi
423,"This study aimed to identify public figures involved in the discussion of medical information on Twitter, examine the transformations of their initial tweet content, and trace the dynamics of attitudes within information cascades.",WsZ2gYorQ0u
424,The authors should provide more information on the motivations for retweeting (or why people propagate tweets),WsZ2gYorQ0u
425,What does the literature suggest? ,WsZ2gYorQ0u
426,I don’t quite believe that people are incompetent simply because they do not understand medical terminology,WsZ2gYorQ0u
427,The paragraph concluding the introduction section needs to be rewritten,WsZ2gYorQ0u
428,Why did the authors choose these terms and this time period? Please explain,WsZ2gYorQ0u
429,"The approach to detect information distortion lacked transparency, reliability, and validity",WsZ2gYorQ0u
430,Please fully explain this process and demonstrate how it was determined to be valid.,WsZ2gYorQ0u
431,“Take the red pill” is a reference to the Matrix (popular movie from the 1990s),WsZ2gYorQ0u
432,Do the authors think this tweet is appropriate to include in their study? Wouldn’t this tweet suggest the authors’ data is very noisy? Please explain,WsZ2gYorQ0u
433,"The authors suggest that people are misunderstanding the medical terminology, but it seems as if people simply don’t agree on what information is being presented",WsZ2gYorQ0u
434,I don’t doubt that members of the public struggle with medical terms but this study does not seem to show misunderstanding as much as the authors believe it does,WsZ2gYorQ0u
435,This paper investigates in how medical information is distorted during its propagation on Twitter,WsZ2gYorQ0u
436,"This is a rather interesting topic, and can potentially have social impact",WsZ2gYorQ0u
437,"But as the paper itself points out (“preliminary and qualitative study”), the study is still at a very early stage to me in several aspects",WsZ2gYorQ0u
438,"First, the concept of “information distortion” is replaced by  ""attitude/sentiment shifts""",WsZ2gYorQ0u
439,"Although the two concepts may overlap to some extent, but are not equal to me",WsZ2gYorQ0u
440,"Secondly, the experiment setting is simplified (only very influential figures are included) and only qualitative results are given.",WsZ2gYorQ0u
441,The quality of the paper can be greatly enhanced by improving its experiment section.,WsZ2gYorQ0u
442,The authors addressed an important phenomena: distorted medical information on Twitter,WsZ2gYorQ0u
443,They detected the major public figures spreading the information and also attitude shift within cascades,WsZ2gYorQ0u
444,The analysis in this paper offers deep understanding of distorted medical information on Twitter,WsZ2gYorQ0u
445,"However, only descriptive analysis is provided",WsZ2gYorQ0u
446,The paper will be improved if the authors adopt automatic approaches for detecting distorted medical information in large scale,WsZ2gYorQ0u
447,"For example, tools such as InfoPath (http://snap.stanford.edu/infopath/) can be used",WsZ2gYorQ0u
448,"Gomez Rodriguez, Manuel, Jure Leskovec, and Bernhard Schölkopf",WsZ2gYorQ0u
449,"""Structure and dynamics of information pathways in online media."" Proceedings of the sixth ACM international conference on Web search and data mining",WsZ2gYorQ0u
450,# [REVIEW]  Coronavirus:  Public Arabic Twitter Dataset,ZxjFAfD0pSy
451,EMNLP COVID-19 WORKSHOP — 26th Sep 2020,ZxjFAfD0pSy
452,This short paper/abstract describes the development of a corpus of Arabic COVID-19 related tweets from Saudi Arabia,ZxjFAfD0pSy
453,  Saudi has a relatively high proportion of Twitter users and produces around 40% of all Arabic tweets,ZxjFAfD0pSy
454," Data was collected between Jan 1st 2020 and Apr 10th 2020, and consisted of 3.8 million tweets selected based on Arabic COVID-related hashtags",ZxjFAfD0pSy
455,"The development of this corpus is a useful endeavour, but it is not clear to this reviewer that in and of itself it warrants publication",ZxjFAfD0pSy
456, The case for publication would be stronger if the corpus was manually annotated and/or there was a more extensive analysis of corpus characteristics.,ZxjFAfD0pSy
457," Generally, the language is a bit hard to follow",ZxjFAfD0pSy
458, It is not clear how you identified the hashtags,ZxjFAfD0pSy
459,The paper presents a dataset of over 3 million tweets in Arabic collected during the initial months of the COVID-19 pandemic,ZxjFAfD0pSy
460,"Authors selected relevant hashtags related to public policies, measures, solidarity messages, etc",ZxjFAfD0pSy
461,The paper presents the main statistics of the corpus and briefly discusses the data collection methodology.,ZxjFAfD0pSy
462,I commend the authors for their effort in this endeavour,ZxjFAfD0pSy
463,"The creation of new linguistic resources is always a time-consuming process, but it is extremely valuable for research in NLP",ZxjFAfD0pSy
464,"Furthermore, resources in languages other than English are necessary to diversify our methods and technologies and ensure they are scalable to these scenarios",ZxjFAfD0pSy
465,"In this respect, I consider the work relevant.",ZxjFAfD0pSy
466,"However, my main concern is that I think the work is still very initial to be considered for presentation in EMNLP",ZxjFAfD0pSy
467,"At this moment, the authors have ""only"" collected the data (which I agree is an important part of the research), but it remains to be seen how this data can be used to successfully answer some interesting questions in NLP",ZxjFAfD0pSy
468,"Furthermore, the description of the dataset and data collection methodology is not sufficiently detailed in order to make this process as transparent and reproducible as possible",ZxjFAfD0pSy
469,"Hence, unfortunately, I have to recommend that this work is rejected at this moment, while at the same time I recommend the authors to continue their research and submit an updated and extended version in future venues.",ZxjFAfD0pSy
470,#### Some questions I consider could help the authors improve their work:,ZxjFAfD0pSy
471,"- How was the selection of hashtags and categorization? Was it the work of a single person, or was some sort of committee designed, and in that case, how was disagreement dealt with? If the selection was performed by a single person, then it is harder to argue that the hashtags and categories are objectively meaningful, but at least is important to disclose this information.",ZxjFAfD0pSy
472,"- Can authors detail which (if any) strategies were used for filtering or identifying unwanted messages (e.g., hate speech) or irrelevant messages (e.g., I have anecdotally seen that replies to an official source often contain a large portion of messages which are plain spam, completely unrelated to the original message).",ZxjFAfD0pSy
473,"- Is there some classic NLP task that the authors can show, at least with simple baselines, can be aided by or performed in this dataset? For example, apply sentiment analysis to the tweets and estimate a percentage of agreement/disagreement between retweets and original messages",ZxjFAfD0pSy
474,"- Can authors provide additional statistics of the dataset, for example, timelines showing the prevalence of different hashtags correlated with major events in the Arab world (e.g., curfew application)",ZxjFAfD0pSy
475,"Similarly, an analysis of the most common terms used in different categories",ZxjFAfD0pSy
476,The idea is to give the reader a view as deep as possible into the content of the dataset such that they can judge if it will be useful for some specific task.,ZxjFAfD0pSy
477,"- Regarding collected retweets, are these plain retweets, or retweets with comments, or both? I think plain retweets, even if valuable to understand how a tweet flows through the network, are less relevant than retweets with comments which can also be used to estimate stance or opinion w.r.t",ZxjFAfD0pSy
478,"- Line 43: Update to more recent statistics and include the specific date to which ""to date"" refers.",ZxjFAfD0pSy
479,- Line 233: I couldn't find the dataset repository URL in the document.,ZxjFAfD0pSy
480,"Once again, I commend the authors for their hard work so far and recommend they continue working on this very important line of research.",ZxjFAfD0pSy
481,I think this is a good resource (esp,ZxjFAfD0pSy
482,given it is in Arabic and thereby focuses on other-than-English data),ZxjFAfD0pSy
483,"However, the paper in its current form falls short in providing any deeper look at the dataset",ZxjFAfD0pSy
484,There are also a few relevant references missing,ZxjFAfD0pSy
485,- line 45-47: consider updating the infection numbers or state the date when the numbers were accurate,ZxjFAfD0pSy
486,- line 69-71: needs a reference,ZxjFAfD0pSy
487,- line 89: which government accounts?,ZxjFAfD0pSy
488,"- line 124-130: what are the limitations of that tool? How is the sampling done? How do you know which part of the Tweet population you are getting? Some references you’d want to look at here are [1], [2] and [3] (see below:",ZxjFAfD0pSy
489,- line 135-137: how were they categorised? By whom? What was the inter-rather agreement?,ZxjFAfD0pSy
490,- line 233: the link is not stated so I cannot access the data,ZxjFAfD0pSy
491,"Overall: this paper would do well to also include a section on previous work - esp that on COVID-19 and NLP, many of which has been published at the COVID-19 ACL workshop",ZxjFAfD0pSy
492,"Relevant datasets, studies and findings should be discussed.",ZxjFAfD0pSy
493,I would also want to see analyses on the dataset,ZxjFAfD0pSy
494,"which topics are discussed in the tweets (using LDA, for example)? What can we learn from the data?",ZxjFAfD0pSy
495,A key limitation is further see is that it focuses on Twitter without discussing the limitations that follow,ZxjFAfD0pSy
496,# [REVIEW] Tracking And Understanding Public Reaction During COVID-19: Saudi Arabia As A Use Case,KVJhxtEbZ7n
497,EMNLP COVID19 — 26th Sep 2020,KVJhxtEbZ7n
498,This paper seeks to use Twitter to better understand the emotional responses of the Saudi population to COVID-19,KVJhxtEbZ7n
499," As a first step, the researchers built an Arabic sentiment lexicon from several sources and augmented by some manually analysis to identify sentiment terms specific to the Saudi dialect",KVJhxtEbZ7n
500," Second, they geolocated the tweets using CrimsonHexagon",KVJhxtEbZ7n
501," Third, they assigned sentiment scores to tweets based on a process of (a) filtering tweets using the lexicon developed in step 1; and (b) applied NB & SVM to an annotated subset of these tweets [Note that this step is somewhat unclear]",KVJhxtEbZ7n
502," First, public sentiment fluctuated substantially over the course of the pandemic, with sentiment improving (i.e",KVJhxtEbZ7n
503," Second, hashtags were used to home in on specific themes (e.g",KVJhxtEbZ7n
504,"support for decisions, social solidarity) should general support for government COVID-19 containment policies",KVJhxtEbZ7n
505," Third, the method was able to identify specific geographical locations that exhibited in their tweets greater than average negativity.",KVJhxtEbZ7n
506,"My overall assessment is that this is a worthwhile effort, but as it stands, the work is somewhat undercooked",KVJhxtEbZ7n
507, The methodology is not entirely clear.,KVJhxtEbZ7n
508, The writing can be a little hard to follow at points and generally would benefit from tightening up,KVJhxtEbZ7n
509," If we take the abstract as an example, there are a number of issues present:",KVJhxtEbZ7n
510,	* “The COVID-19 had a great impact” ,KVJhxtEbZ7n
511,	* “While governments are taking extreme measures to **compact** the spread of the virus…”  I don’t think that “compact” is the right word here.,KVJhxtEbZ7n
512," The background for the work is extensive, but somewhat unfocussed.",KVJhxtEbZ7n
513, Some of the citations (e.g,KVJhxtEbZ7n
514,"Drus and Khalid, 2019) should probably be without brackets (i.e",KVJhxtEbZ7n
515," It sounds like the geolocation from CrimsonHexagon is something of a black box, given the quotation you use",KVJhxtEbZ7n
516, Is there any evidence regarding the reliability of their geolocation algorithms?,KVJhxtEbZ7n
517, Geographical distribution (Fig 3) looks about right given population centres in Saudi.,KVJhxtEbZ7n
518,"This work described the sentiment analysis for Saudi Arabia based on the Twitter data from January 1, 2020, to April 10, 2020",KVJhxtEbZ7n
519,The Twitter dataset was processed by Crimson Hexagon to identify both hashtag topics and geolocations of the posts,KVJhxtEbZ7n
520,"To identify the sentiment of the posts, sentiment lexicons were expanded based on the Arabic sentiment lexicons dataset by 4 annotators",KVJhxtEbZ7n
521,"To generate the ground truth sentiment dataset, more than 129K tweets were samples and annotated according to the expanded lexicons",KVJhxtEbZ7n
522,NB and SVM models were trained and tested on the ground truth data,KVJhxtEbZ7n
523,"Based on the results, both sentiment distributions over time and topics were discovered",KVJhxtEbZ7n
524,It also showed sentiment variations in different cities,KVJhxtEbZ7n
525,"In this reviewer's view, this work is well structured",KVJhxtEbZ7n
526,The 'Method' section needs more explanations and improvements,KVJhxtEbZ7n
527,"To expand the lexicon, 4 annotators extracted words expression emotions",KVJhxtEbZ7n
528,"After annotation, do they reach a certain agreement (Kappa statistics)?",KVJhxtEbZ7n
529,"Can you please clarify how to annotate the sentiment of posts based on the lexicons? Is human involved in this? If not, what is the algorithm to identify the sentiment of posts based on lexicons? One post may contain more than one sentiment keywords",KVJhxtEbZ7n
530,"After training the SVM model (the best model shown in Table 4), please clarify if you apply this model to the entire dataset for the sentiment distribution in Figures 1 and 2.",KVJhxtEbZ7n
531,Overall: a good attempt to show NLP-related work on COVID-19 for Arabic language data.,KVJhxtEbZ7n
532,"However, the paper in its current form falls short of a few requirements, the most important of which is the lack of statistical testing and thereby the lack of alignment between the findings and the conclusions that are drawn.",KVJhxtEbZ7n
533,- the introduction could do with some references of relevant work on social media studies around COVID-19 (incl,KVJhxtEbZ7n
534,- line 83-84: needs a reference,KVJhxtEbZ7n
535,"- line 114: reference missing --> ""?""",KVJhxtEbZ7n
536,- line 116-120: the research questions are not motivated enough,KVJhxtEbZ7n
537,Why is it interesting/necessary/worthwhile to look at sentiment? Why is it important to know the geographical distribution?,KVJhxtEbZ7n
538,- section 2.2: this section seems redundant and could go I think.,KVJhxtEbZ7n
539,- line 259: why do the tweets need to be related to influenza? This needs clarification.,KVJhxtEbZ7n
540,- line 296-299: how were the keywords and hashtags categorised? Who did this? What was the annotators' agreement?,KVJhxtEbZ7n
541,- line 317: the section numbering is off,KVJhxtEbZ7n
542,- line 322: provide stats for the exclusions and general corpus descriptives,KVJhxtEbZ7n
543,- line 353: what do we know about the validity of Crimson Hexagon? ,KVJhxtEbZ7n
544,- line 369-377: why were only tweets between 160-170 characters selected for sentiment identification?,KVJhxtEbZ7n
545,- related: how was the labelling done? Provide details of the procedure.,KVJhxtEbZ7n
546,- table 4: provide more detailed performance metrics,KVJhxtEbZ7n
547,- fig 1: the figure is off - the percentages do not align when they should.,KVJhxtEbZ7n
548,- line 440-470: this needs proper statistical testing - right now there is no way to assess the findings in a quantitative manner according to statistical standards,KVJhxtEbZ7n
549,- line 476-478: how were the topics labelled?,KVJhxtEbZ7n
550,- fig 2: are the differences really meaningful? Statistical testing would help understand this.,KVJhxtEbZ7n
551,- fig 3: not really clear what the figure means and the use of spatial statistical models would be more appropriate here.,KVJhxtEbZ7n
552,"- lastly: at a few places, the wording is off.",KVJhxtEbZ7n
553,"In this work, the authors use a dataset built from reddit posts to identify pandemic-related stress factors",gjnazop9oCb
554,"The framing of the problem is nicely outlined, and the focus on college students is a relevant one",gjnazop9oCb
555,"The dataset and baseline comparsion dataset are well constructed, but when 'filtering' for only college student related posts it decreases in size to almost being only 5% of the collected set",gjnazop9oCb
556,A discussion of the demographics of reddit users would have better strengthened the authors argument,gjnazop9oCb
557,"The techniques applied to the dataset are sufficient to elucidate what the authors are trying to show, but many details are obscured from the reader, hindering both reproducibility, and clarity of the writeup",gjnazop9oCb
558,The sentiment analysis part is a bit dry and lacking in additional details/purpose,gjnazop9oCb
559,Seems rather odd that on Figure 4 there are no neutral posts related to family,gjnazop9oCb
560,"One of the major issues is the lack of usage of appropriate vocabularies/lexicons for the depression evaluation, as well as the lack of a detailed qualitative evaluation",gjnazop9oCb
561,"Overall, the paper needs additional details to be self-standing and extra clarity and rigor is needed for publication worthiness",gjnazop9oCb
562,The study collected posts from Reddit and use common NLP techniques (e.g,gjnazop9oCb
563,"topic modelling, sentiment analysis) to find out some stress factors and effects among young people",gjnazop9oCb
564,"The findings are interesting and intuitive, but I am concerned about two things: 1) Is the data source limited, why not include other social media like twitter? Is there a fact that young people use Reddit more often than other social media ? 2) The authors put much effort in topic modelling, it would be better to give some qualitative analysis rather than only quantitative insights",gjnazop9oCb
565,3) Not sure what is the goal of sentiment analysis ? what is your accuracy then ?,gjnazop9oCb
566,This study aimed to analyze depression-related issues reported by Reddit users using statistical and NLP techniques,gjnazop9oCb
567,Strengths of this study include the methodologies used to systematically analyze content using linguistic techniques to find out the stress-inducing factors,gjnazop9oCb
568,"Weaknesses of this study include the lack of supporting documentation suggesting Reddit is a place where those suffering from depression and/or related symptoms express themselves, a lack of justification for choosing Reddit over a traditional survey-based approach, and the failure to rely on previously established terms to identify health concerns",gjnazop9oCb
569,To improve this paper I’d like to see the authors answer the following questions: 1)Did the authors consider using the Unified Medical Language System (UMLS) to identify depression-related terms? Why or why not? 2) What degree of statistical significance did this study rely on? 3) Why did this study introduce a sentiment analysis in the discussion section? This seemed out of place.,gjnazop9oCb
570,"Additionally, this study made a number of claims without appropriate supporting documentation",gjnazop9oCb
571,"I’d like to see this corrected, for example, how did this study determine that “the data here spans across geographical, demographic and socio-cultural barriers,” and how did it determine statistical significance? Please explain",gjnazop9oCb
572,The authors have developed rule-based strategies to generate term variants for the SARS-CoV-2 virus and COVID-19 disease and examined the usage of these variants in the literature.,Yd6haDmVDSq
573,"They distinguish the task from NER; I agree it is not NER, but I do think it is comparable to normalization to a very small set of (two) identifiers",Yd6haDmVDSq
574,"In that light, some assessment of the quality of the terminology in terms of Precision/Recall would potentially be valuable",Yd6haDmVDSq
575,"Are any of the terms ambiguous? The authors also assume that if a term is instantiated in the literature, it is valid",Yd6haDmVDSq
576,"Is it possible that there is a spurious match between a term and the literature? Furthermore, given the comment about the need for regular updates, why not just leave the terms in the dictionary? Perhaps those terms can anticipate variation?",Yd6haDmVDSq
577,I'm a little bit confused by the analysis in Table 1,Yd6haDmVDSq
578,"If the Union of all of the resources is considered the ""complete"" dictionary, shouldn't we be interested in how many terms are unique to each resource? That is, how many terms are added from each source that contribute to the final set of terms? And, shouldn't we consider the term-level overlap between them in order to establish agreement, e.g",Yd6haDmVDSq
579,"which terms are in all 3, 2, or only a single resource? ",Yd6haDmVDSq
580,"Figure 2 could be more interesting if we were also told the proportion of articles each of these unique terms appeared in, because the literature was also increasing during that time; this would give a sense of the rate of adoption of these 'novel' terms",Yd6haDmVDSq
581,Perhaps some 'error bars' could suggest the variation in the distribution of the terms.,Yd6haDmVDSq
582,"The authors in Section 2.1 identify 3 types of entities: The SARS-CoV-2 virus, the disease it causes (COVID-19), and the pandemic",Yd6haDmVDSq
583,So the third type (naming the pandemic) is excluded from the dictionary? ,Yd6haDmVDSq
584,I'm wondering how generalizable/productive the rules are that expand the terms,Yd6haDmVDSq
585,"Some are obviously highly specific to this virus, but others such as adding ""infection"" to the name of a virus to produce the disease, or adding ""disease"" to the end of a base disease term, seem like they would be generalizable",Yd6haDmVDSq
586,It would be interesting to see whether such patterns apply for other virus-disease associations.,Yd6haDmVDSq
587,"All in all, a useful resource in a narrow context",Yd6haDmVDSq
588,It would be nice to understand the broader utility of the methodology.,Yd6haDmVDSq
589,"This paper present a technique to expand gazetteers referring to Covid19 (disease) and Sars-cov-2 (virus), consisting of a set of rules.",Yd6haDmVDSq
590,"In addition, there is an analysis of the result applying it to a collection called LitCovid.",Yd6haDmVDSq
591,My biggest concern with this paper is that it is presented as a way of expanding coverage of automated tools,Yd6haDmVDSq
592,"However, that utility is never shown",Yd6haDmVDSq
593,This by itself might not be an issue with a workshop paper,Yd6haDmVDSq
594,"However, there are reasons to believe that it will be limited: the novel terms belong probably to the long tail and are very rarely used, and maybe even in a redundant way with the more standard terms",Yd6haDmVDSq
595,"In that sense, Table 1 provides the wrong information",Yd6haDmVDSq
596,"It is not the number of terms that is important, but the combined number of occurrences of those terms in a given document",Yd6haDmVDSq
597,"As ~80% (70%) of the terms referring to Covid19 (Sara-cov-2) are covered by the basic expression, it would seem that the percentage that is covered by your expanded list might be very small",Yd6haDmVDSq
598,"3 addresses this with the top-1/2/5 terms, but it is not clear how many additional terms (or even documents) are captured with your expanded list.",Yd6haDmVDSq
599,"There could be value in analyzing in what situations non-standard terms are used, and if those are preferred by a certain public or region",Yd6haDmVDSq
600,"However, besides Fig 1 (which I found one of the most interesting parts of this paper), such an analysis is absent.",Yd6haDmVDSq
601,"This list would be very helpful, and will hopefully be provided as a push-request to the terminology list referred in the paper (https://github.com/Aitslab/corona)",Yd6haDmVDSq
602,"  - What is LitCovid: in order for the paper to be self-contained, specifying the type, source and some statistics on the collection would be helpful",Yd6haDmVDSq
603,The paper describes the generation of a dictionary of terms related to COVID-19 based on a set of rules,Yd6haDmVDSq
604,The rules allows to create a set of different combinations using a set of base-terms that allows to identify mentions to the disease by detecting terms that are not very common,Yd6haDmVDSq
605,The results showed that the approach developed by the authors can have interesting applications for example in bibliometrics as the detection of those concepts less used can help in this field,Yd6haDmVDSq
606,"From the NLP perspective, the technical advances are very limited although the results provided are reasonable useful.",Yd6haDmVDSq
607,This paper proposes two separate models for multilingual emotion analysis and misinformation classification using Tweets,9H1ODFqgIEk
608,"The authors use publicly available datasets for both tasks, and add Conv1D and Dense layers for fine-tuning the pre-trained multilingual BERT model",9H1ODFqgIEk
609,"After briefly reporting the performance of the two models on the test sets, a bar chart is plotted for each task to show the distribution of emotion labels and misinformation classes.",9H1ODFqgIEk
610,"Before referring to the content of the paper, I would like to strongly urge the authors to proof-read and run a grammar/format checker on the paper, as there are many formatting and grammatical issues that degrade the readability of the paper",9H1ODFqgIEk
611,Add whitespace after the full stop,9H1ODFqgIEk
612,Add whitespace before the left bracket and remove whitespace before the full stop.,9H1ODFqgIEk
613,Fix trivial typos that can be spotted with a spell checker.,9H1ODFqgIEk
614,"Regarding the content of the work, I agree that multilingual misinformation detection can be useful especially in times like this when digesting wrong information could potentially impact the well-being of the person",9H1ODFqgIEk
615,"However, due to the lack of baselines, it is difficult to evaluate the effectiveness of the proposed models",9H1ODFqgIEk
616,"As the main contribution of the paper is the proposal of the multilingual models, the strength of the models in comparison to other baselines should have been presented clearly.",9H1ODFqgIEk
617,"Also, it would be informative if the performance scores were given for each language as well",9H1ODFqgIEk
618,"From my experience, the vanilla tokenizer provided by the multilingual BERT tends to over-tokenize the sentences in low-resourced languages; and their corresponding embeddings are less robust which may result in varying levels of performance for different languages",9H1ODFqgIEk
619,I am wondering if the distinctive patterns in the distribution of emotions for each language are due to the varying performance of the model or there is actually something distinctive about the Tweets.,9H1ODFqgIEk
620,"If possible, a more in-depth analysis using the trained models would be nice.",9H1ODFqgIEk
621,This paper proposes a multilingual framework for tweet analysis,9H1ODFqgIEk
622,It considers two types of tweet analysis: emotion classification and misinformation classification,9H1ODFqgIEk
623,The proposed framework trains a multilingual BERT model on labelled corpus and uses the trained model for emotion/misinformation detection,9H1ODFqgIEk
624,"There is no doubt that the task of emotion and misinformation analysis is important during the pandemic period, a fast-changing time period with explosion of information",9H1ODFqgIEk
625,"Further, from a practical use point of view, the adoption of multilingual approach is potentially a good solution to address the problem of limited data availability",9H1ODFqgIEk
626,"That is, a model trained on a corpus in one language can be transferred to use in different language context",9H1ODFqgIEk
627,"However, the language setting is different for emotion classification task and misinformation classification task",9H1ODFqgIEk
628,"The emotion classification model is trained a corpus that only contains English tweets, but the misinformation classification model is trained on a multilingual dataset",9H1ODFqgIEk
629,"This setting may be due to data availability, but I think the authors can improve the experiments by comparing the results with a monolingual BERT model",9H1ODFqgIEk
630,Does the multilingual BERT model make contributions? ,9H1ODFqgIEk
631,The authors should do a thorough proof reading,9H1ODFqgIEk
632,The presentation of the paper is a bit difficult to follow,9H1ODFqgIEk
633,This work reports some experiments using the multilingual BERT model on Twitter data from different datasets in several languages: the COVID-19 Real World Worry Dataset (Kleinberg et al,9H1ODFqgIEk
634,"2020), the Coronavirus Facts Alliance Dataset (Alam et al",9H1ODFqgIEk
635,"2020), and the dataset of tweets collected by Chen et al",9H1ODFqgIEk
636,"The supervised experiments aimed at detecting emotion (8 classes labeled in the Twitter data) and misinformation (5 classes: false, half-false, no evidence, misleading and true).",9H1ODFqgIEk
637,"Although some of the ideas are interesting and the initiative to analyze multilingual data is compelling, several issues prevent me from accepting this work at its current state.",9H1ODFqgIEk
638,"Authors tested the multilingual BERT under the assumption that the same pretrained model could fit all datasets, regardless of the language",9H1ODFqgIEk
639,As if the same multilingual model fits all,9H1ODFqgIEk
640,"The article could have been improved if this assumption had been validated or contrasted, by comparing the results when monolingual models are used in each data set",9H1ODFqgIEk
641,"For example, by applying the monolingual English BERT model to the English dataset, a French monolingual BERT model to the French dataset..",9H1ODFqgIEk
642,Does a multilingual BERT model help or causes noise in some datasets?,9H1ODFqgIEk
643,"There is a major problem with the writing style: it needs to be improved thoroughly, and several grammar, spelling and typographic errors need to be fixed",9H1ODFqgIEk
644,"- From a qualitative point of view, the analysis of Twitter data, enhanced through NLP, gives an enriching panorama of the public opinion regarding the COVID-19 disease",9H1ODFqgIEk
645,- The approach considers Twitter data in several languages beyond English (e.g,9H1ODFqgIEk
646,"French, Indonesian, Japanese, Portuguese, Spanish, etc.)",9H1ODFqgIEk
647,"- There are methodological issues regarding the experiments, which may induce to think that results are not reproducible or generalizable.",9H1ODFqgIEk
648,"- The article needs a great deal of work to correct grammar errors, ortographic and typographic errors",9H1ODFqgIEk
649,"Moreover, an an effort of synthesis is required: several excerpts are redundant or revolve around the same ideas about the spread of information in social media, etc.",9H1ODFqgIEk
650,"Abstract: What does CMTS stand for? Is it a typo of ""CMTA""?",9H1ODFqgIEk
651,"4.1.1: The authors seem to refer by ""tokenization"" to 2 different processing steps",9H1ODFqgIEk
652,"The ""tokenization"" step refers to the segmentation of text or sentence items into individual items (""tokens""); it does not imply obtaining vectors",9H1ODFqgIEk
653,"After tokenization, each token is then converted to a vector representation",9H1ODFqgIEk
654,"4.1.3: the authors mention that they used ""dropout layers"", but what value exactly? ",9H1ODFqgIEk
655,"5.1: the authors state that they ""created a list of Out-of-vocabulary (OOV) words which were replaced with meaningful complete words.""; I think this is not expressed correctly",9H1ODFqgIEk
656,What criteria did they follow to replace the OOVs? Did they use synonyms included in the vocabulary? Or do authors mean that OOV abbreviations and acronyms were expanded to full words in the vocabulary?,9H1ODFqgIEk
657,"Regarding results, authors only reported scores on one round of experiments; the outcomes do not seem solid enough to be generalizable",9H1ODFqgIEk
658,"A good methodological approach is initializing the model with different random seeds and test it in several experimental rounds; then, authors should report the average F-score and standard deviation.",9H1ODFqgIEk
659,"5.3: ""The bar plot shows..."" -> Which one: Figure 2 or 3? The same happens in Sect",9H1ODFqgIEk
660,"Figures 2 and 3: the colors do not distinguish well each class when printed, please use different patterns (horizontal, vertical lines...)",9H1ODFqgIEk
661,The font size in the legend is too small.,9H1ODFqgIEk
662,- Unify use of uppercase or lowercase letters in the title of the article.,9H1ODFqgIEk
663,"- The acronym ""CMTA"" should be defined since the beginning of the article.",9H1ODFqgIEk
664,"(not exhaustive): ""various task"" -> ""tasks"" (p",9H1ODFqgIEk
665,"1); ""two separate deep neural network model"" -> ""models"" (p",9H1ODFqgIEk
666,"1); ""have use"" -> ""have used"" (p",9H1ODFqgIEk
667,"3); ""contained noises"" -> ""noise"" or ""noisy content"" (p",9H1ODFqgIEk
668,- Check ACL citation style: e.g,9H1ODFqgIEk
669,"1): ""(Matsa and Shearer, 2018)(Hitlin and Olmstead, 2018)"" => ""(Hitlin and Olmstead, 2018; Matsa and Shearer, 2018)"" ",9H1ODFqgIEk
670,- The authors are encouraged to split long sentences into short text fragments for the sake of clarity,9H1ODFqgIEk
671,"For instance, the 2nd sentence of the first paragraph in the Introduction; the first sentence of Sect",9H1ODFqgIEk
672,"2: Unify use of single quotes; they are sometimes used, but not in all words: ’anger’, ’disgust’, ’fear’, anxiety, sadness, happiness, relaxation ,and desire",9H1ODFqgIEk
673,"Regarding names of languages, no single quotes are needed (Sect",9H1ODFqgIEk
674,- There are many missing white spaces between words and punctuation marks (e.g,9H1ODFqgIEk
675,"between a bracket and the next word, etc): e.g",9H1ODFqgIEk
676,"- Footnote 4 and 6 are not needed, the URL is provided in footnote 2",9H1ODFqgIEk
677,The same happens for footnotes 5 and 7.,9H1ODFqgIEk
678,"- ""it is divided into four phases"" -> I counted 5",9H1ODFqgIEk
679,"This work introduces a light weight retrieval and reranking model, as well as an easy-to-use web search service",WYyPpXNXQyC
680,"Although the model has only 620 parameters and does not use the sophisticated Transformer variants like Bert,  it still ranks the second position in the third round of submission.",WYyPpXNXQyC
681,"The writing quality of the paper is pretty good, and the logic is nice",WYyPpXNXQyC
682,I believe that the work is innovative.,WYyPpXNXQyC
683,There are still several weak points worth mentioning,WYyPpXNXQyC
684,It seems that the preliminary work of the model  come from (Almeida and Matos,WYyPpXNXQyC
685,This work should be cited at the first moment when mentioned,WYyPpXNXQyC
686,"Say, the third paragraph of the introduction, ""BioASQ system in our work"".",WYyPpXNXQyC
687,Please add citation to “BM25” in the section 2.2.,WYyPpXNXQyC
688,"Are both the query and paragraph initialized by a pre-trained Word2vec model? There is no clear explanation in the experiment part, but the readers could get the above clue in the last paragraph",WYyPpXNXQyC
689,"So, if ""yes"", declare them clearly earlier, pls",WYyPpXNXQyC
690,"The effect of the re-ordering model on the third round of Baseline is weak, so does the UIowaS team",WYyPpXNXQyC
691,This paper proposes a very light-weight reranking model for retrieving documents from the CORD-19 dataset,WYyPpXNXQyC
692,The impact is that the proposed model would encourage wider application in cases where computation resources are a constraint,WYyPpXNXQyC
693,"The proposed model, while only having 620 parameters, performed surprisingly well (ranked 2nd in the 3rd round).",WYyPpXNXQyC
694,The paper is well-written and well-motivated,WYyPpXNXQyC
695,"I specially like the 3-round of testing and corresponding ""lessons learnt"" parts",WYyPpXNXQyC
696,"It offers some insights into the technical details that would cause substantial difference in the evaluation performances, and thus inspire future works.",WYyPpXNXQyC
697,One limitation is the lack of proper explanation on the baseline in the 3rd round,WYyPpXNXQyC
698,The paper mentioned a bug in feedback data but still not sure why the baseline performance is missing,WYyPpXNXQyC
699,"it should correspond to our phase-I baseline results"", but where are the numbers? How far is it off from the system ""ours""?",WYyPpXNXQyC
700,This paper presents a currently in-development system for information retrieval in the CORD-19,WYyPpXNXQyC
701,Authors present a pipeline that is being evaluated in the TREC-COVID challenge and shows a clear advantage with respect to other approaches despite (or thanks to) being based on a simpler neural ranking component,WYyPpXNXQyC
702,"While it may not necessarily be the top-performing approach, authors claim that the simplicity of the neural ranking component and the overall pipeline makes it more feasible to deploy online and use for real-time queries",WYyPpXNXQyC
703,"However, the experimental data provided in the paper (which I briefly cross-checked w.r.t",WYyPpXNXQyC
704,"the TREC-COVID leaderboard links provided in the paper) positions this system with a very good performance, among the top-3 in several metrics",WYyPpXNXQyC
705,A prototype of the system is deployed and usable online (I've been able to perform some queries while others have taken too long),WYyPpXNXQyC
706,"In general, I believe this paper provides a valuable approach and a tool the community can benefit from, and I think it is very relevant for this workshop",WYyPpXNXQyC
707,My only suggestion is regarding the evaluation,WYyPpXNXQyC
708,"As it is currently written in the paper, there is too much emphasis (in my opinion) on the idiosyncrasies of the TREC-COVID challenge, which makes the evaluation section unnecessarily long",WYyPpXNXQyC
709,"On the other hand, I would appreciate some experimental results to back the hypothesis that this type of system is easier to deploy and faster to execute than the alternatives.",WYyPpXNXQyC
710,"**Reasons to accept:** The paper presents a clear result with demonstrable effectiveness, as validated by experimental data that is publicly available and a prototype system available online.",WYyPpXNXQyC
711,**Reasons to reject:** Some claims regarding the scalability and practical advantages of this system require further experimentation to be completely justified.,WYyPpXNXQyC
712,The authors aim to identify the mental health dynamics on social media during COVID-19 pandemic,WsDilMI9unn
713,"In this paper, they concentrate on identifying the people with depression through analyzing their tweets",WsDilMI9unn
714,They create a dataset by using a pre-existed distant-supervision methodology including cases (depression) and controls,WsDilMI9unn
715,"They investigate the classification performance on SVM, and then turn to 8 classification models.",WsDilMI9unn
716,"The authors create a distantly supervised dataset and perform a careful investigation on the dataset, especially from the view of data imbalance",WsDilMI9unn
717,"The algorithmic part is less novel nor informative, as the author mainly use the classical classification models",WsDilMI9unn
718,I am personally opt to regard the dataset created in this research as the main contribution,WsDilMI9unn
719,"So, more accurate description of this part is expected",WsDilMI9unn
720,"The dataset in this paper is created by a ""distant-supervision methodology"", but the details are not sufficient",WsDilMI9unn
721,More examples and the quality evaluation is expected.,WsDilMI9unn
722,The authors could enunciate the performances comparison at section 3.2.2.,WsDilMI9unn
723,"In this paper, the authors attempt to develop a methodology to predict population depression rates across different countries from social media data (Twitter)",WsDilMI9unn
724,"The paper is well structured with clearly outlined aims, assumptions, and weaknesses",WsDilMI9unn
725,The discussion section provides a nice overview and is a good example of how machine learning results can be interpreted using domain knowledge,WsDilMI9unn
726,"In my opinion, it indicates that the authors went the extra mile to gather information about the subject of their analysis",WsDilMI9unn
727,"The authors apply previously developed methods in a well-designed set of experiments, however, they manage to achieve only moderate performance",WsDilMI9unn
728,- The concept of a “distantly supervised dataset” should be clearly explained.,WsDilMI9unn
729,- Why were the classifiers described in section 3.2.2 trained for only 1 epoch? Training for longer might improve the performance of the classifiers.,WsDilMI9unn
730,- The authors also specify that Diagnosed samples were treated as 5 times more valuable,WsDilMI9unn
731,At what stage was this weighting implemented? How was number 5 chosen? ,WsDilMI9unn
732,- How was the data split into training and validation sets?,WsDilMI9unn
733,- The authors should specify the 2-week period within which the data described in section 3.1 was gathered,WsDilMI9unn
734,- The false-negative example in Table 6 doesn’t sound like the person has been “diagnosed with depression”,WsDilMI9unn
735,"Was it labelled as positive because of other, more affirming posts by the same user within a certain time period?",WsDilMI9unn
736,"- In section 4, were tweets from different countries analysed by respective pre-trained classifiers?",WsDilMI9unn
737,"I recommend that this paper be revised and resubmitted as a short-paper, focusing on the unique challenges of multi-national mental-health predictions.",WsDilMI9unn
738,"The paper aims to provide ""organisations with a methodology for monitoring and analysing temporal mental health dynamics using social media data""; however, they do not gather enough data or train a sufficiently successful model to do that successfully",WsDilMI9unn
739,The paper does a good job of applying established methods for mental health analysis on social media data and the inclusion of a BERT classifier is compelling,WsDilMI9unn
740,The paper over-represents its usefulness in several areas.,WsDilMI9unn
741,The paper may be better suited as a 4-page short-paper,WsDilMI9unn
742,"In that condensed format, the paper could focus on its unique contribution of analyzing data across national boundaries",WsDilMI9unn
743,This claim should be supplemented by country specific analysis of depression and suicidality,WsDilMI9unn
744,These are known to vary widely by culture.,WsDilMI9unn
745,"Lastly, the authors should include a discussion of the ethical principals informing their decision making during this study.",WsDilMI9unn
746,"Two additional nits: (1) the authors should include the AUC metric, which is conventional for this space; (2) the authors should use effect size or confidence intervals instead of significance testing, which has flaws on the massive N found in NLP.",WsDilMI9unn
747,- Methodologically consistent with the literature ,WsDilMI9unn
748,- Lots of superficial information in the paper,WsDilMI9unn
749,"The methods are conventional--well explained here and in previous works--however, the deep models are under documented and should be supported diagrams, more detailed description, or code",WsDilMI9unn
750,"Those models, likely, could not be reproduced.",WsDilMI9unn
751,This paper proposes a system for biomedical entity recommendation,lukVnNC-Hc
752,"The system performs entity recommendation in a pipeline manner with three steps: named entity recognition, relation extraction, and entity recognition",lukVnNC-Hc
753,The paper shows that the recommendation accuracy can be enhanced if multiple ontologies are used for recognising and linking the entities,lukVnNC-Hc
754,The paper is well-written and easy to follow,lukVnNC-Hc
755,"My major concern is that whether the experimental results provide sufficient evidence to support the hypothesis that the authors formulate: if multiple different ontologies are used for recognising entities, the accuracy of entity recognition increases",lukVnNC-Hc
756,"As shown in Figure 2, the accuracy of using all ontologies (ALS-all) outperforms any other dataset with only one ontology (e.g., ALS-chebi which only includes entities in CHEBI ontology)",lukVnNC-Hc
757,This might be a positive sign showing that other ontologies are contributing to model’s understanding about how to recommend CHEBI entities,lukVnNC-Hc
758,"However, it might be also simply because of the model’s learning curve: the data in ALS-all is a super set of ALS-CHEBI, and the model simply learns more with more available data, no matter which ontology the extra data comes from",lukVnNC-Hc
759,And this can be evident by that the accuracy in Figure 2 (ALS-all>ALS-chebi>ALS-go>ALS-hp~=ALS-do) is actually roughly proportional to the data set size if we look at the size of each data set in Table 4,lukVnNC-Hc
760,"As such, the authors should consider to another baseline scenario where the entities are randomly sampled, without considering the ontologies.",lukVnNC-Hc
761,"Secondly, the rating matrix is not implicit feedback",lukVnNC-Hc
762,Implicit feedback means the scenario where rating is not available and only users’ actions are available,lukVnNC-Hc
763,"In implicit feedback setting, the interaction between users and items is only recorded as 0 or 1 (interacted or not)",lukVnNC-Hc
764,"Therefore, pairwise ranking is pervasively used for learning",lukVnNC-Hc
765,"The ALS algorithm is usually preferred in the setting of explicit feedback, rather than implicit feedback",lukVnNC-Hc
766,"Reasons to accept: well-written, data set can be useful",lukVnNC-Hc
767,Reasons to reject: the design of the experiments cannot fully support the claim in the paper,lukVnNC-Hc
768,This paper proposes a pipeline for the automatic extraction of entities and relations from the CORD-19 dataset and recommendation of relevant entities in those papers,lukVnNC-Hc
769,"The authors apply a system (MER, Couto and Lamurias, 2018) for the automatic extraction of entities which is seeded with 4 ontologies in the biomedical domain",lukVnNC-Hc
770,"A total of 9000 documents from CORD-19 are automatically annotated with entities, from which 100 documents are manually curated and a small subset is used to evaluate the inter-annotator agreement and manually annotate relevant relations (relations are defined in the ontologies used)",lukVnNC-Hc
771,"Afterwards, a recommendation technique (LIBRETTI) is applied by considering author-entity-mention counts as the user-item-rating triplets",lukVnNC-Hc
772,"Thus, as I understand, the overall pipeline proposed has the purpose of suggesting an author of a paper in the annotated dataset with novel entities that might be of interest for that author and not mentioned in their papers.",lukVnNC-Hc
773,The main hypothesis of the paper is that the use of ontologies from different domains for the NER phase improves the quality of the recommendation,lukVnNC-Hc
774,"While this hypothesis is effectively demonstrated by the experimental results, I believe this is a direct consequence of the fact that these ontologies are from different domains and thus mostly disjoint, which in my opinion renders the hypothesis self-evident",lukVnNC-Hc
775,"With respect to the results, the significance of the metrics provided is hard to evaluate without some comparison with alternative systems or at least some baselines.",lukVnNC-Hc
776,"Although I consider there is value in the proposal, since building such a recommendation system at a large scale (e.g., at the scale of Semantic Scholar or Google Scholar) would be extremely valuable for researchers, I still consider a significant effort is necessary both to improve the extraction and recommendation procedures, but also regarding manual annotation, evaluation, and the actual development of such a tool",lukVnNC-Hc
777,"Finally, I commend the authors for their effort",lukVnNC-Hc
778,"I recommend working on improving the motivation of the research; at least personally, it was hard for me to understand the underlying motivation for recommending entities, and I think this is a very important point.",lukVnNC-Hc
779,**Reasons to accept:** The automatically and manually annotated corpora can be valuable resources for the community,lukVnNC-Hc
780,"Also, the source code is provided, which improves reproducibility and fosters collaboration.",lukVnNC-Hc
781,**Reasons to reject:**  The significance of the results is hard to evaluate since there is no comparison with alternatives or baselines.,lukVnNC-Hc
782,"- About the phrase ""an IAA of 0.2978 which indicates fair agreement"" -- It is my understanding that a fair Kappa agreement is considered above 0.70 unless the authors are using a different formulation, in which case I would recommend the authors to explicitly state and justify the threshold above which they consider the agreement ""fair"".",lukVnNC-Hc
783,"- The Precision, Recall and F1 scores are considered ""high"" by the authors, however, since there is no baseline or comparison it is hard to determine the significance of these measures.",lukVnNC-Hc
784,"- Recurrent typos in page 2: *""¡article,topic,cardinality¿""*, *""¡author,entity,rating¿""*, in Page 4: *""¡user, item, rating¿""*, ..",lukVnNC-Hc
785,(I believe this stems from the incorrect to use of $<$ and $>$ in LaTeX),lukVnNC-Hc
786,The authors develop datasets for NER and RE extraction of COVID-19 literature,lukVnNC-Hc
787,They used the generated data to generate concept recommendations.,lukVnNC-Hc
788,- The developed datasets might be valuable to further researchers,lukVnNC-Hc
789,- I do not understand why would it be useful to recommend concepts to someone,lukVnNC-Hc
790,It might be because of my limited expertise on the field.,lukVnNC-Hc
791,The paper explores the task of experts extraction and expertise topic extraction from COVID-related literature,_opmUB8v-Y-
792,"While the methods seem reasonable, the evaluation is quite problematic, as explained below:",_opmUB8v-Y-
793,"* For term extraction, the evaluation is mainly based on the MeSH terms, which I don't think is appropriate",_opmUB8v-Y-
794,"Based on ""When labelling an article, indexers select terms only from the official MeSH list – never other spellings or variations"" ([quote from here](https://onlinelibrary.wiley.com/doi/full/10.1111/ijcp.12767#:~:text=MeSH%20terms%20are%20official%20words,never%20other%20spellings%20or%20variations)), the evaluation using MeSH terms risks penalizing words extracted that share the same topic but different surface forms with the MeSH terms",_opmUB8v-Y-
795,"For example, ""heart attack"" would be not be recognized as a successful extraction since the word used in the list is ""Myocardial Infarction""",_opmUB8v-Y-
796,"* For expert extraction, there are two ways as evaluation:  ERC panel member matching and h-index",_opmUB8v-Y-
797,Both evaluation methods are quite problematic,_opmUB8v-Y-
798,"    *   For ERC panel members matching, the authors have already pointed out its limitation in the discussion ""The ERC panel members on the contrary contained only a few Asian specialists ..",_opmUB8v-Y-
799," the panels being rather centred on Europe and North America""",_opmUB8v-Y-
800,So the evaluation is biased and tells little about the results,_opmUB8v-Y-
801,    * The h-index tells mainly the productivity and citation impact of an author,_opmUB8v-Y-
802,It is just not an appropriate measure for expertise,_opmUB8v-Y-
803,"For example, a person has a higher h-index but few work related to COVID-19 would potentially be recognized as a top expert by this metric",_opmUB8v-Y-
804,"> ""Typically, researchers rely on metrics of publication and citation impact to evaluate the level of expertise of their peers, but these metrics are not as reliable nor directly comparable across scientific fields and bibliographic databases""",_opmUB8v-Y-
805,    But I don't see any advantage of using h-index over other metrics of publication and citation impact,_opmUB8v-Y-
806,* There is no comparison between the proposed method and any other baseline,_opmUB8v-Y-
807,So it is hard to interpret all the reported results,_opmUB8v-Y-
808,"As an NLPer, I had a hard time finding the definition of MeSH terms and the annotation criteria for MeSH terms",_opmUB8v-Y-
809,It would be better if the authors could add some definition and details about MeSH in the paper,_opmUB8v-Y-
810,This study proposes a term extraction method to extract expertise topics from coronavirus related papers which aims to find experts accordingly,_opmUB8v-Y-
811, My main concern is on the evaluation part.,_opmUB8v-Y-
812,"First, the study does not compare with any baseline methods or other term extraction methods",_opmUB8v-Y-
813,The effectiveness of the proposed method is thus not clear.,_opmUB8v-Y-
814,"Second, it is confusing that using MeSH terms for evaluating extracted expertise topics",_opmUB8v-Y-
815,MeSH terms are not designed for expertise topics at all,_opmUB8v-Y-
816,"It annotates the terms wherever applicable to the ontology, not key terms or expertise terms",_opmUB8v-Y-
817,"For instance, https://pubmed.ncbi.nlm.nih.gov/32134205/ has a MeSH term 'Humans', which is not the main term of the study at all",_opmUB8v-Y-
818,Having an overlap between MeSH terms does not necessarily imply the expertise topics are extracted.,_opmUB8v-Y-
819,"Third, it is even more puzzled on using h-index to 'quantify' the expertise..",_opmUB8v-Y-
820,Is it a reasonable metric? Why an h-index of 20 was selected?,_opmUB8v-Y-
821,"Fourth, looking at the extracted terms, it seems that they are not COVID-19 specific",_opmUB8v-Y-
822,"For example, 'infection control'  and 'antibody response' are general terms for different types of coronaviruses",_opmUB8v-Y-
823,Whether it can find specific expertise terms for COVID-19 is not clear,_opmUB8v-Y-
824,The study could apply the method to LitCovid (https://www.ncbi.nlm.nih.gov/research/coronavirus/) which consists of PubMed articles that are on COVID-19 and it has curated topics to conduct a case study for evaluation,_opmUB8v-Y-
825,"For instance, compare the extracted terms from COVID-19 articles with the terms from articles on other coronaviruses",_opmUB8v-Y-
826,"The authors combine an off-the-shelf term extraction system (Saffron) and manually collected MeSH terms with a tf-idf based method (Bordea (2010, 2013)) for identifying scientific experts in under-indexed literature in the CORD-19 dataset",_opmUB8v-Y-
827,- the authors apply existing technologies to a new problem,_opmUB8v-Y-
828,- I have trouble following the evaluation; it has many suspect steps and I feel that they are underaddressed,_opmUB8v-Y-
829,I would like a proper metric here instead of a series of ad-hoc approaches,_opmUB8v-Y-
830,"As an example h-index is not a good measure for expertise in a novel and/or developing area, which is one of the main focuses of the paper",_opmUB8v-Y-
831,"- The authors present a pipelined approach for this technique, but they don't investigate how errors propagate within the pipeline",_opmUB8v-Y-
832,I don't have a sense for what their numbers mean,_opmUB8v-Y-
833,What happens if we strictly use MeSH terms and manually tagged documents? How does this impact the overall expert identification? How sensitive is the expert identification scoring to the h-index; what's the distribution of scores?,_opmUB8v-Y-
834,"- this is a straightforward application of existing technology, not a methods development (this is a much weaker complaint than the evaluation angle)",_opmUB8v-Y-
835,"- some of the methodology is arbitrary but would likely matter in practice, e.g",_opmUB8v-Y-
836,choosing how many extracted terms to use?,_opmUB8v-Y-
837,"- the subarea splits and use of ERC experts seem to mostly distract given that there seem to be few extracted ERC experts, rendering both the ERC and the split moot.",_opmUB8v-Y-
838,- what instructions was the expert annotator given for the MeSH terms?,_opmUB8v-Y-
839,- low quality term extraction may lead to overly aggressive MeSH term matching,_opmUB8v-Y-
840,How did you compensate for this?,_opmUB8v-Y-
841,- what proportion of researchers are ERC panel members? This is a crucial point to understanding the evaluation of expert identification,_opmUB8v-Y-
842,- what was the h-index threshold you settled on?,_opmUB8v-Y-
843,- why use this word-mesh-term overlap instead of an existing MeSH tagger?,_opmUB8v-Y-
844,I am deeply dissatisfied with the evaluation methodology,_opmUB8v-Y-
845,I would be much happier if a less ad-hoc version were performed on a limited subset,_opmUB8v-Y-
846,"Given the lack of results using ERC panels as experts, a large portion of the paper seems irrelevant (null results are fine, but there's no meaningful investigation of the null result)",_opmUB8v-Y-
847,I think that the idea of expert discovery could be explored on better tagged datasets (e.g,_opmUB8v-Y-
848,"the portion of CORD-19 that has already been indexed, or any other subset of PubMed), allowing for easier measurement of the decay for any portion of the pipeline.",_opmUB8v-Y-
849,The paper presents an approach to detecting COVID-19-related symptoms in social media data (Twitter),DFJhXXPZrM7
850,The authors use word embeddings generated by BERT and build a graph of tokens based on their similarity to the learnt context embedding which allows them to iteratively identify more and more symptoms,DFJhXXPZrM7
851,"The paper would benefit from some technical clarifications and, in my mind, can be extended to the long format",DFJhXXPZrM7
852,The study presents an original methodology,DFJhXXPZrM7
853,Since the method is unsupervised the authors validate its performance by manually calculating precision for a few identified symptoms,DFJhXXPZrM7
854,They also test the method on a previously developed and annotated dataset for adverse drug reaction detection and show that the method generalises quite well,DFJhXXPZrM7
855,"- To improve the reproducibility of the study, the details about BERT implementation should be included.",DFJhXXPZrM7
856,- The process of graph generation is not straightforward and should be accompanied by examples and/or illustrations,DFJhXXPZrM7
857,- It is unclear what the similarity scores reported in table 1 represent for manual and graph-based approaches,DFJhXXPZrM7
858,Are these the cosine similarities between a given token and the seed word “cough”?,DFJhXXPZrM7
859,- I am not sure what this notation means “##raine”?,DFJhXXPZrM7
860,- Legends should be added to Figures 2 and 3 to show how node colours correspond to similarity values,DFJhXXPZrM7
861,"- For the annotated ADR dataset, is it possible to calculate other metrics (e.g",DFJhXXPZrM7
862,The author represented an unsupervised graph-based approach for the detection of symptoms of COVID-19,DFJhXXPZrM7
863,The paper and idea is good,DFJhXXPZrM7
864,1-The propose method will have several useful applications if it can be generalized and better than traditional methods.,DFJhXXPZrM7
865,2- The author test their method on 2 different dataset ,DFJhXXPZrM7
866,1-The methodology needs further explanation ,DFJhXXPZrM7
867,"2- There is no comparison with traditional method that are able to capture such symptoms for instance LDA , W2V approaches",DFJhXXPZrM7
868,"Sometime a simple method works better than complex one , particularly when the language context is simple ",DFJhXXPZrM7
869,This work reports an approach to symptom detection on Twitter data,DFJhXXPZrM7
870,Graph-based relations between a seed word and the more similar words are obtained by means of a similarity measure; the context embedding value is used to represent each word and compute the cosine similarity value with regard to the seed word,DFJhXXPZrM7
871,"The authors applied their method to a collection of COVID-19-related tweets (using the word ""cough""), and also conducted their experiment on an ADR corpus (Sarker & González 2015), using the term ""pain""",DFJhXXPZrM7
872,Their method obtained similar symtom words in both cases and yielded promising results that could be pursued in other pharmacovigilance tasks.,DFJhXXPZrM7
873,- I found this is an original method that will interest the audience of the workshop.,DFJhXXPZrM7
874,"- The article is clear, although sone methodological aspects need further clarification and some excerpts minor need revision",DFJhXXPZrM7
875,"- As authors already point out, the method currently detects only single-word terms, not multi-words, which may be essential to detect fine-grained description of symptoms (e.g",DFJhXXPZrM7
876,"- The experiment is only conducted using one word (""cough""); it could provide more solid results if more terms related to the COVID-19 symptomatology had been explored.",DFJhXXPZrM7
877,- I also missed a pragmatic perspective and brief discussion as to how these types of approaches would be valuable in the real medical-use or pharmacovigilance context,DFJhXXPZrM7
878,Healthcare professionals could validate these lists of medical terms,DFJhXXPZrM7
879,"This could yield a quality reference dataset, and vice versa, healthcare professionals could get valuable, unknown data about symptoms to take into consideration (and probably not reported to date)",DFJhXXPZrM7
880,The authors could develop this aspect,DFJhXXPZrM7
881,"Namely, developing an interface to explore and show these associated terms would be a great contribution of this work.",DFJhXXPZrM7
882,"The first column in Table 1---""Cough (Manual)""---needs more explanation",DFJhXXPZrM7
883,"Do authors mean that they selected manually a set of words related to ""cough"", then computed the cosine similarity value? Please, provide more details in the running text.",DFJhXXPZrM7
884,"In Section 2.1, authors have to provide more details about the BERT model they used: e.g",DFJhXXPZrM7
885,BERT cased or uncase? Did authors use the models released in the paper by Devlin et al,DFJhXXPZrM7
886,"2019? Did they resort to domain embeddings such as SciBERT or BioBERT? Or did they train their own model? What were the hyperparameters used (learning rate, dimension of hidden state, use of dropout, batch size...)?",DFJhXXPZrM7
887,"1, Introduction: ""SARS-nCOV"" -> ""SARS-CoV-2"" or ""SARS-nCoV-2""",DFJhXXPZrM7
888,1: colors are not distinguished when printed in black and white; authors should think of an alternative to improve this.,DFJhXXPZrM7
889,"4, Figure 4: These figures are, in my opinion, small to be read adequately",DFJhXXPZrM7
890,I suggest authors to make them larger and move one or two to an Appendix,DFJhXXPZrM7
891,This paper proposes an end-to-end phrase identification and linking model for COVID-19 concepts,fJCcajDO8Tx
892,Experiment results look pretty good in terms of F1,fJCcajDO8Tx
893,Some more explanation and analysis would substantially benefit this paper.,fJCcajDO8Tx
894,One limitation is that this paper over-emphasized the necessity of being end-to-end,fJCcajDO8Tx
895,the concept wikifier has to perform ..,fJCcajDO8Tx
896,"in an end-to-end fasion,..."" No, it doesn't have to",fJCcajDO8Tx
897,Being end-to-end only makes it look nice.,fJCcajDO8Tx
898,Experiment results show SciBERT has terrible Recall,fJCcajDO8Tx
899,This might be due to domain issue,fJCcajDO8Tx
900,"But why is this also the case for SciBERT-FT? Maybe there are some limitations in the process/model that overkills candidates, but no explanation/analysis on this.",fJCcajDO8Tx
901,"This paper presents a new dataset of COVID-19-related mentions extracted from Wikipedia, and some experiments for concept mapping and entity linking",fJCcajDO8Tx
902,"The dataset was annotated by using the available curated links to COVID-19-related concepts, and authors conducted some postprocessing to remove annotations of non-medical mentions (e.g",fJCcajDO8Tx
903,"This dataset was then used as an experimental resource to test entity linking experiments, where concepts are restricted to the COVID-19 disease and occur in Wikipedia (""Concept wikification"")",fJCcajDO8Tx
904,"The authors applied a 2-step approach for the task: first, unambiguous entities are string-matched, then ambiguous entities are resolved through 3 methods: a majority rule-based voting scheme, a BERT-based classifier using SciBERT, and a SciBERT-based classifier fine-tuned on the dataset",fJCcajDO8Tx
905,"By using this latter approach, the authors obtained promising results.",fJCcajDO8Tx
906,"I liked the article and I think could provide an interesting contribution to the workshop, especially owing to the release of this annotated dataset and the trained models.",fJCcajDO8Tx
907,"The weaknesses I found are related to the experimental methods: because results were only reported on one round of experiments, the generalizability of the outcomes are not solid enough",fJCcajDO8Tx
908,"A good methodological approach is to test the model in several rounds with different random seeds or random initializations, and then report the average F-score and standard deviation.",fJCcajDO8Tx
909,"Finally, I think a more thorough description of the dataset is missing (e.g",fJCcajDO8Tx
910,"number of tokens, examples of entity types...)",fJCcajDO8Tx
911,I provide some other comments below.,fJCcajDO8Tx
912,"4: authors could also take a look at BioBERT, which was trained on PubMed article abstracts",fJCcajDO8Tx
913,"Lee J, Yoon W, Kim S, et al",fJCcajDO8Tx
914,BioBERT: a pre-trained biomedical language representation model for biomedical text mining,fJCcajDO8Tx
915,"5, Table 2: What does ""essential medicine"" stand for? General medical concepts? Generic or frequent medication names? Please, explain this or give an example.",fJCcajDO8Tx
916,1: References need to be sorted: e.g,fJCcajDO8Tx
917,"""(Ratinov et al., 2011; Lin et al., 2017; Nguyen et al., 2016)"" => ""(Ratinov et al., 2011; Nguyen et al., 2016; Lin et al., 2017)""",fJCcajDO8Tx
918,This paper addresses the wikification of COVID-19 concepts,fJCcajDO8Tx
919,"Overall, I think this is a reasonable short paper for this workshop",fJCcajDO8Tx
920,Significance: not life-changing but certainly an important problem,fJCcajDO8Tx
921,- The dataset seems to be adequate (it is nice that the authors release it) and the models that are applied are appropriate,fJCcajDO8Tx
922,- The result that fine-tuning on the dataset improves performance is interesting.,fJCcajDO8Tx
923,"- It would have been nice if the authors had provided more details about the dataset, like the distribution of concepts or a list of the most common concepts.",fJCcajDO8Tx
924,- The strong match SciBERT (no fine-tune) seems to perform worse than the baseline,fJCcajDO8Tx
925,Why? Some error analysis here would be helpful,fJCcajDO8Tx
926,Does this suggest that F-score is not the best metric here? There seems to be a big difference between precision and recall for the baseline.,fJCcajDO8Tx
927,"- As for the evaluation, it would have been an interesting baseline to compare SciBERT with BERT-base, although this omission does not warrant a rejection in my opinion",fJCcajDO8Tx
928,Please include it if you're able to run the experiment.,fJCcajDO8Tx
929,This work is interesting to read,txOTpsCuQwT
930,This direction of study would offer insights to the community behaviors w.r.t,txOTpsCuQwT
931,"COVID-19, in addition to the related works that focus on Biomedical literature",txOTpsCuQwT
932,"However, justifications and explanations in this paper are very unfortunately insufficient.",txOTpsCuQwT
933,"The word ""explain"" appeared many times across the paper, but they should actually be ""correlate"" because the methodology used in this paper does not constitute an explanation.",txOTpsCuQwT
934,"Although the paper presents lots of technical details on neural models and text preprocessing, it lacks a proper explanation of how data are filtered, e.g",txOTpsCuQwT
935,"in the 3rd paragraph of Sec 3, how the use of the keywords liberals/democrats not presenting a bias in this study? Is keyword ""republicans"" also used? Further any control on the metioning of keywords and their community? (e.g",txOTpsCuQwT
936,maybe democrats are mostly mentioned by republicans and vice versa?),txOTpsCuQwT
937,"In the 2nd paragraph of Sec 3, how does having the county-specific model ""combat"" the large variation of word embeddings trained on small data? This is not explained at all.",txOTpsCuQwT
938,"In Table 1, what are the scales of those association numbers? BTW the table caption is weirdly formed and needs fix.",txOTpsCuQwT
939,This paper studies the relationship between online language relating to COVID-19 and counrty-level behavior patterns in the United States.,txOTpsCuQwT
940,"The authors show that the variation in how people perceive the virus can reveal people's stance towards social distance measures, as well as towards Trump.",txOTpsCuQwT
941,"* Novel way (Section 3) to use data from multiple sources, building associations between people online language and their stances or behavior patterns.",txOTpsCuQwT
942,"* The writing of Section 4.4 and 4.5 is hard to understand, hard to connect these two sections and other sections",txOTpsCuQwT
943,Suggest to provide more intuitive explanations.,txOTpsCuQwT
944,* The section 5 is too brief,txOTpsCuQwT
945,"Details about data, method, setup are missing.",txOTpsCuQwT
946,"* Footnote 2, 5: period missing",txOTpsCuQwT
947,* Suggest organize Section 2 into Section 2.1 explaning tweets and Section 2.2 explaning mobility data,txOTpsCuQwT
948,"* Page 3, 'we fine-tune that baseline model', do you mean 'continue training'?",txOTpsCuQwT
949,"* Suggest to add more intuitive explantions about the results, helping readers to understand these correlations.",txOTpsCuQwT
950,"The paper presents an interesting analysis on the correlation between a population’s tendency to adhere to social distancing policy and the association of the virus with the political left, fraud and ultimately, individuals’ political party identification",txOTpsCuQwT
951,"Utilizing Google community mobility reports, the authors approximate the amount of people staying at home by change in their mobility in residential areas",txOTpsCuQwT
952,"The second part of the work supports the initial findings by demonstrating that (based on twitter data analysis) counties that tend to social distance less, are those that supported Donald Trump in the 2016 election.",txOTpsCuQwT
953,"I found this work interesting, well-structured and -written, and an enjoyable read overall",txOTpsCuQwT
954,I have a few comments and clarification questions:,txOTpsCuQwT
955,"Section 2.1: the (presumed) positive correlation between residential mobility and social distancing needs to be better explained; it not entirely intuitive; yet, is one of the key assumptions of this work.",txOTpsCuQwT
956,"Building county-specific embeddings could be done using distributed representation for geographically situated language, as described in https://www.aclweb.org/anthology/P14-2134.pdf",txOTpsCuQwT
957,"Table 1 needs more detailed interpretation IMO: say explicitly what are independent and dependent variables, what the numbers in the table represent (regression coeffs? pairwise correlations?)",txOTpsCuQwT
958,"Also, the somewhat low R^2 in the first three models needs better interpretation.",txOTpsCuQwT
959,Section 4.4: more details re the generation of an experimental document would be appreciated – *how* do you manually alter tweets in the control document? Some examples could help at this point.,txOTpsCuQwT
960,Table 2: are the differences in control vs,txOTpsCuQwT
961,"As mentioned above, I enjoyed this work, and assuming authors’ clarifications re the above point in the final version, I’m recommending it for acceptance.",txOTpsCuQwT
962,# [REVIEW] COVID-19/EMNLP Workshop -- Sentiment and Moral Narratives during COVID-19 [paper 18],GpoArQXDoYQ
963,This short paper presents a lexicon-based approach to understanding moral narratives in English-language Twitter data,GpoArQXDoYQ
964," It’s an interesting approach, and nice to see a paper that utilises psychological theory",GpoArQXDoYQ
965, The paper presents 2 core results:,GpoArQXDoYQ
966,"Tweets pertaining to social distancing are characterised by empathy, compassion, and protection, and tweets pertaining to misinformation characterised by the opposite qualities",GpoArQXDoYQ
967,Tweets pertaining to loyalty fluctuate over time,GpoArQXDoYQ
968,"My overall view is that this paper and line of research is promising, but currently needs a little more time to marinate before it is ready for publication",GpoArQXDoYQ
969,"* The writing is generally comprehensible, but there are some points that would benefit from being tightened up",GpoArQXDoYQ
970," “ Containing the pandemic urged for rapid measures, the success of which hugely rely on mass cooperation” and“Understanding indepth the human values triggered and who may resonate with those, is essential to fight the infodemic.”",GpoArQXDoYQ
971,* Suggest listing 4 exemplar countries on first page in the body of the paper (although they are currently listed in the abstract),GpoArQXDoYQ
972,"* The use of embeddings to expand the lexicon seems reasonable, but was there an attempt at evaluating the words identified?",GpoArQXDoYQ
973,* Technical details are somewhat lacking (e.g,GpoArQXDoYQ
974,packages used for word embedding work),GpoArQXDoYQ
975,"* My understanding is that MFT, while very influential in moral psychology, is also quite controversial and competes with stage based models and theories that are more influenced by moral philosophy (e.g",GpoArQXDoYQ
976," However, I think the choice of MFT is sensible given your goals, but could be expanded on a little",GpoArQXDoYQ
977," Also, it would be helpful to explicitly state that the MoralStrength lexicon explicitly draws from MFT",GpoArQXDoYQ
978,"* Minor point, but in Section 4, \citet{} should probably be used to reference the Shanthakumar paper.",GpoArQXDoYQ
979,"* “indifference, happiness, sadness, emotions are included, essential for getting a holistic understanding of the users’ intend.”  gaining a holistic understanding?",GpoArQXDoYQ
980," When you say that the choice of hashtags was inspired by Shanthakumar, did you make any changes?",GpoArQXDoYQ
981,"* “Finally, this group is more authoritative with a pronounced feeling related to the obligations of social relationship” I’m not sure if you mean authoritarian here?",GpoArQXDoYQ
982,* I’m not clear on how reliable the Grouping of hashtags is,GpoArQXDoYQ
983," A quick search of twitter suggests that the hashtag #Trump is used both to propagate misinformation, and to attempt to correct it.",GpoArQXDoYQ
984,"* Figure 1 — text is too small to read - also, I’m not sure how useful the confidence intervals are",GpoArQXDoYQ
985,* Figure 1 — emotions (i.e,GpoArQXDoYQ
986,"loyalty, etc) should probably be presented on the graph, not just in the caption",GpoArQXDoYQ
987,* I’m a bit confused about why you chose the countries you did given that all your tweets were in English,GpoArQXDoYQ
988," How representative are English language tweets generated from Italy? Also, isn’t Twitter severely restricted in China?",GpoArQXDoYQ
989,"The choice of categories chosen — loyalty, fear, inspiration — don’t seem to map very well to MFT",GpoArQXDoYQ
990,* Evaluation is currently somewhat lacking,GpoArQXDoYQ
991,The work sets out to answer two COVID related questions looking into Twitter data,GpoArQXDoYQ
992,The questions are if people cooperate or compete at the time of crisis and what are the major moral values of people believing in conspiracy theories,GpoArQXDoYQ
993,Each tweet is annotated using a moral and a sentiment lexicon,GpoArQXDoYQ
994,"Also based on presence of certain hashtags, all the tweets are divided intto two categories",GpoArQXDoYQ
995,The research questions are answered based on the average moral and sentiment score of each tweet,GpoArQXDoYQ
996,The paper needs to be proofread,GpoArQXDoYQ
997,There are sentence structure issues throughout the paper,GpoArQXDoYQ
998,"Some examples: “with the in four exemplar countries” , “communications Campaigns”, “derived to a total number Of”, “we were based on”, “being 5 the”, “understanding of the users’ intend”, “is a quite big fluctuation”.",GpoArQXDoYQ
999,The choice of hashtags for breaking the tweets to two behavioural groups needs to be explained.,GpoArQXDoYQ
1000,It could be useful to give some examples of how the scoring is done,GpoArQXDoYQ
1001,"Need to be clarified if only 273,924 out of 3,163,500 tweets were used for the analysis",GpoArQXDoYQ
1002,If so this need to be explained in the data collection section.,GpoArQXDoYQ
1003,"Figure 1 the y-axis could be labelled with (loyalty,fear and inspiration).",GpoArQXDoYQ
1004,The answer to question two is based on the negative correlation of fear and loyalty but Loyalty does not seem to follow the fear trend,GpoArQXDoYQ
1005,Even when fear goes down loyalty does not keep going up,GpoArQXDoYQ
1006,Given we cannot explain the fluctuations in the loyalty the answer to question 2 is not satisfactory,GpoArQXDoYQ
1007,This work characterized the sentiment and moral analysis based on more than 3M English Tweets from the Coranavirum Twitter Data,GpoArQXDoYQ
1008," The data analysis was performed according to two lexicons: 1) MoralStrength lexicon for moral valence based on Moral Foundation Theory (MTF),  2) DepecheMood++ for sentiment scale calculation",GpoArQXDoYQ
1009,Moral lexicons were expanded based on word embeddings,GpoArQXDoYQ
1010,Each word in the tweet was annotated based on these two lexicons and each tweet is marked by the average value over 8 sentiments and 5 moral dimensions,GpoArQXDoYQ
1011, Tweets frequencies were then calculated for two behavioral groups: Social Distancing(SD) group and the Misinformation propagators(M) group,GpoArQXDoYQ
1012, Average morality values were further compared for the two groups,GpoArQXDoYQ
1013," Loyalty (Morality), fear (Sentiment), and inspiration (Sentiment) evolutions were studied from February to May based on 4 different countries: China, New Zealand, Italy, US",GpoArQXDoYQ
1014,"In this reviewer's view, this work is a worthwhile contribution",GpoArQXDoYQ
1015,It provides special insights into the relationships between behavior and morality and sentiment for the COVID dataset,GpoArQXDoYQ
1016,Please clarify how the annotation is performed,GpoArQXDoYQ
1017,Is it to match each word to the lexicons in the two dictionaries(morality and sentiment)? ,GpoArQXDoYQ
1018,"The 'Hashtag/keywords' in Table 1 and 2, are they listed based on certain criteria or just the keywords related to COVID19 from the original Twitter data? ",GpoArQXDoYQ
1019,What does the 'Fear' column mean in Table 2 (the averaged moral values)? Is it the fear score or the ratio of posts? ,GpoArQXDoYQ
1020,"In Figure 1, for each line, there is a shaded area",GpoArQXDoYQ
1021,Is it the range of scores?,GpoArQXDoYQ
1022,"From Table 1, the sum of the number of posts for M and SD groups is far less than 3,163,500 (the total number of tweets being collected)",GpoArQXDoYQ
1023,"Please clarify after grouping to M and SD, where do the rest of the posts go?",GpoArQXDoYQ
1024,This paper introduces a very interesting and useful question-answering resource about COVID-19,0X9O6VcYe_
1025,"The corpus consists of 2200 frequent question-answer pairs, extracted from 40 trusted online sources plus 24k social media questions semantically-aligned (by experts) with one of the former dataset.",0X9O6VcYe_
1026,I really like the resource and think it is a good contribution to the workshop,0X9O6VcYe_
1027,Just have one suggestion regarding the manuscript and one advice about the chatbot that the authors intend to develop based on the corpus:,0X9O6VcYe_
1028,I missed some information on how BM25 was trained,0X9O6VcYe_
1029,Did you do it taking only the questions into account or you also use the answer linked to the candidate question?,0X9O6VcYe_
1030,"Regarding the chatbot to be developed, it is important to notice that the answer to many questions  about COVID may change along the time",0X9O6VcYe_
1031,"For instance, during quarantine, the question “Can I go to a bar?“ would be negative, whereas after the end of the lockdown would be positive",0X9O6VcYe_
1032,I am not sure how you can control the update of 2200 questions automatically,0X9O6VcYe_
1033,It is important to think about that in order to do not spread misinformation.,0X9O6VcYe_
1034,This paper describes the curation efforts to create a QA dataset on COVID-19,0X9O6VcYe_
1035,"It collected 2,200 question-answer pairs from popular websites",0X9O6VcYe_
1036,"Then it extracted 27, 000 unanswered questions from tweets, identified the most similar questions in the collection and provided top 5 answers",0X9O6VcYe_
1037,Then the provided answers were further manually annotated (whether they are relevant),0X9O6VcYe_
1038,"For the 27, 000 unanswered questions, it seems that only the questions similar to the existing questions in the collection can be kept",0X9O6VcYe_
1039,"If an unanswered question is a new topic of COVID-19, the top retrieved answers will be irrelevant, and health experts will not provide new answers based on the description",0X9O6VcYe_
1040,"Therefore, many new questions will be potentially missed",0X9O6VcYe_
1041,"And what is the motivation of only annotating the questions that are similar to the existing questions in the collection? Critically, the questions that are significantly different from the existing questions are more valuable and need the power of manual curation",0X9O6VcYe_
1042,Adding these questions will enrich the datasets,0X9O6VcYe_
1043,"In contrast, if a question is similar to the existing questions, adding it will just have one more similar instance",0X9O6VcYe_
1044,"Second, the study needs to explain how to use this dataset in detail",0X9O6VcYe_
1045,"For instance, the statement 'Over 18, 000 examples were judged to be less than 1% relevant, indicating that the majority of the questions extracted from twitter are irrelevant to the answered questions in our dataset' seems that most of the questions do not have a precise answer yet",0X9O6VcYe_
1046,How to train a QA model in this case?,0X9O6VcYe_
1047,"Third, from the methodology level, while BM25 is effective, it does not capture the semantics of the questions",0X9O6VcYe_
1048,Did the study also try to use other methods to calculate the semantic similarity between the questions such as using word or sentence embedding?,0X9O6VcYe_
1049,"Also importantly, the dataset is not public for now",0X9O6VcYe_
1050,More specific comments cannot be made,0X9O6VcYe_
1051,The paper presents a potentially useful dataset of COVID-19-related frequently asked question-answers,0X9O6VcYe_
1052,The link given in the paper does not yet allow the access to the dataset,0X9O6VcYe_
1053,(https://covid-19-infobot.org/data/) Presumably this will be made available upon publication?,0X9O6VcYe_
1054,"Introduction: When explaining the three aggregation efforts, what does the 1st mean by ""generating high quality information""? ",0X9O6VcYe_
1055,"In this sentence “To aid in this effort, we aggregate factual information in the form of verified questions and answers to help answer frequently asked questions about the pandemic.”",0X9O6VcYe_
1056,Better to use question-answer pairs instead of “questions and answers”.,0X9O6VcYe_
1057,"Section 2:  This sentence is vague: ""abstract away adding this information to our set""",0X9O6VcYe_
1058,When updating a question-answer pair how the update is done,0X9O6VcYe_
1059,The paper lacks the explanation of how the question-answers are updated,0X9O6VcYe_
1060,Figure 2 is not a clear example,0X9O6VcYe_
1061,"The answer to the question of ""What is COVID-19?"" is not correct – COVID-19 is an acronym for “Coronavirus Disease 2019”",0X9O6VcYe_
1062,"The answer is a URL, if the correct answer is to be found there, then perhaps an example of the website content should also be included",0X9O6VcYe_
1063,"The example also does not have any indication of the quality of the answer, and the impression gained is that this might not be a very useful resource at all",0X9O6VcYe_
1064,"It might be more accessible to show a few records in the database, or at least to use a very accurate example from the documentation together with a snapshot of the answer that would be made available",0X9O6VcYe_
1065,"The figure's title indicates the inclusion of metadata, but it does not have the ""date/ update date"" metadata mentioned under section 2.1.",0X9O6VcYe_
1066,Section 3: Repeated the “We list the the number of question-answer”,0X9O6VcYe_
1067,Section 4: Need correction “We additionally collection”?,0X9O6VcYe_
1068,"Here Qorona and CovidFaq are mentioned, but there is no other reference to them later as if the questions from these sources are used or not? If yes how? If no, why they are mentioned?",0X9O6VcYe_
1069,"Section 4.1 After Twitter data is collected, what technique/tool is used to extract questions? What indicated that a tweet does contain a question?",0X9O6VcYe_
1070,What techniques is used to group semantically similar questions? Is it topic modelling or something else?,0X9O6VcYe_
1071,The process of extracting questions from Twitter seems to be the main part of this research but is not explained properly to be useful to the research community,0X9O6VcYe_
1072,This paper introduces a multilingual dataset of 6871 utterances across 4 language + a mixture of English and Spanish,Ku-nv600bNM
1073,"The dataset itself is an interesting contribution for the research community, which the authors complement with the study of different cross-lingual transfer learning techniques",Ku-nv600bNM
1074,"I consider the paper to be appealing for the audience of the workshop, however it is not clear whether it is a short or a long one",Ku-nv600bNM
1075,"I am considering it a short one, although the authors use the ""annex escape"" to complement important aspects of the paper",Ku-nv600bNM
1076,"In terms of methodology, could the authors elaborate more on the choice of the 16 intents? What was the basis for chosing them over others?Also, I would have liked to have more details on the ontology they mention in the beginning of Section 2",Ku-nv600bNM
1077,The C Section of the Appendix is a bonus point in terms of reproducibility of the results,Ku-nv600bNM
1078,"However, I do not understand Table 6 in Section B of the same Appendix",Ku-nv600bNM
1079,Why was German considered less relevant than the results in Spanish and French (Table 3),Ku-nv600bNM
1080,Table 5 is quite explanatory and an important part of the paper,Ku-nv600bNM
1081,"However, I would ask for the authors to elaborate more on the distinction between some of the intent categories, that seem quite similar",Ku-nv600bNM
1082,"For example, ""I traveled to new york recently"" could also be understood as ""travel"".",Ku-nv600bNM
1083,This paper introduces a multilingual dataset for detecting COVID-19 specific intents and a Spanish test set for code-switching,Ku-nv600bNM
1084,"The strength of this paper is that they introduced a dataset to the community, provided several baseline models in the experiments, and showed that using cross-lingual representation is useful in this task",Ku-nv600bNM
1085,"However, there are some major problems about the dataset which the authors need to elaborate more on",Ku-nv600bNM
1086,* The paper presents to the community a public multilingual dataset for detecting covid-19 specific intents in user utterances,Ku-nv600bNM
1087,* The paper shows that cross-lingual representation could improve the baseline models in this task,Ku-nv600bNM
1088,* The paper is well written and provides relatively comprehensive comparison between baseline models,Ku-nv600bNM
1089,It also provides analysis about the performance of these models,Ku-nv600bNM
1090,"* The dataset is synthetically created by annotators based on an ontology, but there is no description about the ontology",Ku-nv600bNM
1091,"Furthermore, there is no discussion about how close this synthetic dataset is to real data",Ku-nv600bNM
1092,I wonder if the synthetic data could reflect the real world problem or it is just a much more simplified problem with utterances expressed in less diverse forms,Ku-nv600bNM
1093,"* The authors did not mention how and why the 16 intents are chosen, and also lack the definition of these intents",Ku-nv600bNM
1094,Is the formulation of these intents based on the real data or the synthetic data? Do most of the real data fall into these intent categories?  ,Ku-nv600bNM
1095,"*  The authors need to elaborate more on the details of the annotation process, including the number of annotators to annotate each utterance and the inter-annotator agreement among annotators",Ku-nv600bNM
1096,How did they deal with a sample that received different annotation labels ( majority vote? adjudication among annotators? just throw them away? )? These details are important for other researchers to assess the quality of the dataset,Ku-nv600bNM
1097,    In general the authors need to provide more details about the dataset,Ku-nv600bNM
1098,Otherwise it is hard to assess the quality of the dataset and makes it less useful to the community.,Ku-nv600bNM
1099,* I would suggest the authors give some significant test statistics when they claim the performance scores are significantly better,Ku-nv600bNM
1100,"* It would be interesting to see the breakdown of scores(Precision, Recall, F1) for each intent category and some analysis of the difficulty/easiness to identify each category",Ku-nv600bNM
1101,Showing cases with correct/incorrect predictions could also be helpful,Ku-nv600bNM
1102,This work presents a multilingual dataset for intent detection of COVID-related utterances,Ku-nv600bNM
1103,"Besides, the authors built various baselines and experimented with code-switched data (Spanglish)",Ku-nv600bNM
1104,- The dataset is open-sourced and could be helpful for further COVID-related development.,Ku-nv600bNM
1105,- Reasonable analysis and discussions on baseline results.,Ku-nv600bNM
1106,- Hyperparameters of models were provided.,Ku-nv600bNM
1107,- The dataset `is synthetically created by annotators based on an ontology describing all intents with few representative examples`,Ku-nv600bNM
1108,"However, no details on how synthetically created, the information about annotators, the ontology and how it was created, and the seed examples were provided",Ku-nv600bNM
1109,There is also no discussion on how close the dataset is to real utterances,Ku-nv600bNM
1110,"These issues make the dataset, i.e., the main contribution, less useful",Ku-nv600bNM
1111,"- For Table 3, it might be better to have a plot instead of a table to show the trend when increasing % training.",Ku-nv600bNM
1112,"- The authors should discuss why zero-shot performance with XLM-R Large is better than using 10% Spanish data, and why it performs worse than the base model under the setting of 80% French data.",Ku-nv600bNM
1113,Authors has used data distillation methodology to augment the data,-VigZOltxoq
1114," The idea is good, and the experiments used seem OK",-VigZOltxoq
1115,"However, the contribution needs more evaluation",-VigZOltxoq
1116,For instant the authors need to plot learning curve to know how Bert model improves with different % of dataset,-VigZOltxoq
1117,Second author may investigate how many manually labelled data is required to reach the current performance with data augmentation and see how worthy data augmentation is compared to increase of manually annotated data (how many time and efforts it can save),-VigZOltxoq
1118," Third, I would recommend the authors to investigate the data they have used and check if they are annotated based in robust guideline, it is worth to try this approach in well representative data to see its feasibility",-VigZOltxoq
1119,"the main issue of some annotated data is that not because it is small but because it is not representative, and they are more vulnerable to noise and overfitting when they are augmented and the performance on test data is likely not a real improvement",-VigZOltxoq
1120,The author adopt data distillation model into the tweet stance analysis in support of monitoring public opinion on COVID-19 intervention measures,-VigZOltxoq
1121,The research design and experiment results are of good quality,-VigZOltxoq
1122,Some details of the experiments are expected to answer: ,-VigZOltxoq
1123,* How many rounds for the teacher/student models in data distillation achieves convergence in performance?,-VigZOltxoq
1124,* What about the standards and quality control for manual labeling of lockdown-train,-VigZOltxoq
1125,"(306 Against, 223 Support and 565 Neutral)?",-VigZOltxoq
1126,* Figure 2 is not informative sufficiently to support the result.,-VigZOltxoq
1127,This study aimed to use Twitter data to better understand stance toward COVID-19 intervention measures,-VigZOltxoq
1128,The topic is timely and experiments seemed appropriate,-VigZOltxoq
1129,However the approach taken to develop the manual labels was not fully described,-VigZOltxoq
1130,"In other words, how were the manual labels determined?  It was unclear whether the authors conducted interrater reliability to obtain an understanding of how reliable the manual coding was",-VigZOltxoq
1131,"Given the models were based on these labeled data, this is rather important to document and demonstrate that the manual data coding process was done in a reliable fashion",-VigZOltxoq
1132,"To accomplish this the authors need to write out the rules for ’Support’, ’Against’, and ’Neutral’ as well as provide examples (either example tweets or words from the tweets for each case)",-VigZOltxoq
1133,Without this context it is hard to determine this study ultimate value to the field,-VigZOltxoq
1134,The paper describes work in progress whose goal is to the collect a hate speech corpus with Argentinian Spanish Tweets about COVID-19,X3qj-gUFHZJ
1135,"Once the collection is finished, authors also intend to answer questions regarding social science, using SOTA computational tools",X3qj-gUFHZJ
1136,-  is there a continuity between hate speech during the pandemic and those that previously existed?,X3qj-gUFHZJ
1137,- is there any difference in how hate speech is expressed by users in the different newspapers and over time? ,X3qj-gUFHZJ
1138,- which communities are targeted by hate speech in the pandemic context? ,X3qj-gUFHZJ
1139,- to what extent do newspaper articles induce the emergence of hate speech?,X3qj-gUFHZJ
1140,- is hate speech linked to a snowball effect or to the performance of some influencer users?,X3qj-gUFHZJ
1141,- is there a link or community among people who produce hate speech? ,X3qj-gUFHZJ
1142,"Although the idea is great and the work is going on a very positive direction, I saw some flaws in the description of the experiment",X3qj-gUFHZJ
1143,"Moreover, despite the fact this is a short paper, I agree with the reviewers that more comprehensive results are necessary before the publication of the manuscript/",X3qj-gUFHZJ
1144,Here are some suggestions to the authors:,X3qj-gUFHZJ
1145,"The acronyms OT, NPAs and RPs are counter-intuitive and confusing",X3qj-gUFHZJ
1146,I suggest the authors to change them or refer to the proper term,X3qj-gUFHZJ
1147,The fluency of the paper will increase.,X3qj-gUFHZJ
1148,"How were the query search (COVID-19, COVID, Wuhan…) and seed words (China, Bolivia, etc.) defined?",X3qj-gUFHZJ
1149,"If one of the paper’s goal is to obtain Spanish tweets (preferably from Argentina) associated with the COVID- 19 pandemic, why haven’t you used the geolocation function from Twitter? (However, we do not have information of tweet authors’ demographics",X3qj-gUFHZJ
1150,How many data was annotated so far?,X3qj-gUFHZJ
1151,I think this work might make for a good paper if the dataset annotation had been completed and there was a comprehensive analysis of the data,X3qj-gUFHZJ
1152,"Overall, I agree with the sentiment of Reviewer 2 in that the direction and questions are interesting but a more comprehensive result if needed for publication.",X3qj-gUFHZJ
1153,I think figure 2 could be seen as a contribution if the authors had explained why the findings that they purport are significant and what question they answer,X3qj-gUFHZJ
1154,"Moreover, the questions mentioned in section 4.1 are important and interesting but do not seem related to the preliminary findings they present in the paper",X3qj-gUFHZJ
1155,"Once the dataset is collected, the authors should describe the dataset in detail and provide examples to help readers understand the value of their collected dataset",X3qj-gUFHZJ
1156,I very much look forward to seeing a completed version of this work the analysis of results,X3qj-gUFHZJ
1157,"This work proposes to annotate Spanish-language tweets, associated with coronavirus news articles, for hate speech",X3qj-gUFHZJ
1158,The article discusses the intended plan to annotate a set of tweets using multiple annotators and then build a machine learning system to identify more tweets containing hateful language,X3qj-gUFHZJ
1159,These tweets would then be used to answer several questions about hate speech during the coronavirus pandemic,X3qj-gUFHZJ
1160,"Finally, the paper presents preliminary results from a separate machine learning system.",X3qj-gUFHZJ
1161,"Firstly, I find the article clearly written and easy to understand",X3qj-gUFHZJ
1162,This work appears to be primarily a research proposal with a description of the proposed steps and an outline of the research questions to be discussed,X3qj-gUFHZJ
1163,"The data collection description is fairly clear, but the intended questions to ask are general and not well fleshed out",X3qj-gUFHZJ
1164,Unfortunately the additional data analysis (in sections 4.2 and 4.3) does not link well with the proposal to provide any support or specific research direction,X3qj-gUFHZJ
1165,"While the call for papers for this workshop mentions work in progress, this article seems to be a little too early work in progress.",X3qj-gUFHZJ
1166,Some further issues with the paper are outlined below,X3qj-gUFHZJ
1167,- The paper mentions Bender & Friedman’s data statements but does not provide the long form of a data statement (or as close as possible at this stage) as suggested by the cited paper,X3qj-gUFHZJ
1168,"- Apart from one research question in Section 4.1 (discussed below), the paper doesn’t provide reasoning why hate speech should be studied specifically during the coronavirus pandemic as opposed to any other time.",X3qj-gUFHZJ
1169,- The data analysis in the final section sounds quite interesting,X3qj-gUFHZJ
1170,You state that your results outperform the current best methods for the SemEval 2019 HatEval challenge,X3qj-gUFHZJ
1171,"Oddly, you then claim that it “does not perform as good as in the original domain”, Maybe I’m misunderstanding, but that performance is good, right?",X3qj-gUFHZJ
1172,- Section 4.1 provides a brief overview of the types of questions that you intend to ask with the final Twitter dataset,X3qj-gUFHZJ
1173,This is really lacking detail and it’s unclear how you will answer several of these questions with the dataset that you describe,X3qj-gUFHZJ
1174,"For the first descriptive question, how will you evaluate trends of hate speech from before the pandemic when your dataset will only include tweets on coronavirus articles? For the first explanatory question, how will evaluate the effect of newspaper articles on hate speech if you only have tweets related to newspaper articles and not other sources? You also suggest doing some sort of network analysis on Twitter users to identify influencers and community but don’t provide any details",X3qj-gUFHZJ
1175,Furthermore it is not clear if the data collected will contain this information.,X3qj-gUFHZJ
1176,- There’s a strange dip in tweets in mid May in Figure 2,X3qj-gUFHZJ
1177,Is there an interesting reason behind that?,X3qj-gUFHZJ
1178,The paper asserts the importance of translation technologies in crisis situations and describes the TICO-19 benchmark for validating and testing translation systems for low-resourced languages,-0xPrt01VXD
1179,"Also, other additional resources such as translation memories and in-domain monolingual data are presented",-0xPrt01VXD
1180,The paper concludes with initial benchmarked results using publicly available pre-trained models.,-0xPrt01VXD
1181,I think the work is well-aligned with the workshop's objective,-0xPrt01VXD
1182,I would like to applaud the authors for their efforts to construct such a benchmark with the under-served languages in mind.,-0xPrt01VXD
1183,I do have a few questions:,-0xPrt01VXD
1184,What does the 95% rate correspond to? Does it correspond to the direct assessment scheme employed in WMT?,-0xPrt01VXD
1185,Were there any domain-specific evaluation guidelines?,-0xPrt01VXD
1186,"If I understood the paper correctly, the additional resources in Section 5 are not used at all to train/fine-tune the ""Our OPUS"" and ""Our TED"" models? Is this correct?",-0xPrt01VXD
1187,This work described a translation system TICO-19 based on multiple sources including English PubMed and Wikipedia,-0xPrt01VXD
1188,"English documents were translated into 35 languages with terminologies provided by Facebook and Google, where the OPUS-MT system was employed.",-0xPrt01VXD
1189,"In the Quality Assurance subsection, It is not clear how the first editing is performed? How do you solve the disagreements? Can you provide examples?",-0xPrt01VXD
1190,"In the second round QA process, how the 95% rate was achieved? How do you evaluate?",-0xPrt01VXD
1191,The MT is pre-trained on OPUS parallel data,-0xPrt01VXD
1192,It is not clear how do you use the resources in section 5 to adjust the pre-trained system.,-0xPrt01VXD
1193,"Can you please clarify the structure of the pipeline system? After collecting the data and specifying the target language, how do Facebook, Google terminology datasets being used in the MT system?",-0xPrt01VXD
1194,"The authors describe the TICO dataset, a development and testing dataset for multi-lingual medical translation",-0xPrt01VXD
1195,"They describe in great detail the creation of this dataset, and the QA measures they undertook",-0xPrt01VXD
1196,"I am particularly a fan of Table 8 which includes specific measures and details about which dataset underwent which parts of their QA process, although I note there appears to be an extra empty aggregate row.",-0xPrt01VXD
1197,"The authors provide a great overview of the varying languages, grouping them for relative importance in the translation effort, and making a qualitative assessment of the resources available for each of them.",-0xPrt01VXD
1198,Overall I think that this is a high quality development and testing set,-0xPrt01VXD
1199,"I would be happy to see this paper accepted, although I think there are some easily tackleable areas for improvement",-0xPrt01VXD
1200,It's not clear to me whether or the not the authors intend on releasing their systems (licensing of the data?),-0xPrt01VXD
1201,"As is, I would assume not, which would be unfortunate but not a reason to stop publication",-0xPrt01VXD
1202,"I disagree with the relative downweighting of the importance of the parallel data in the paper - the authors should document the sizes of the data they found, even if small",-0xPrt01VXD
1203," Licensing concerns are relevant for others using the data, but a proper description of it, including sizes and genres, belongs in this paper.",-0xPrt01VXD
1204,"I am concerned that the relative importance of the PubMed data in the evaluation datasets, by a small number of documents providing a large number of sentences, will primarily reward systems for a somewhat random game of vocabulary whack-a-mole instead of rewarding the ability to produce a high quality translation over a diverse set of inputs",-0xPrt01VXD
1205,"While adjusting this is likely impossible at this point due to expense or annotation effort, I would like to see an explicit treatment of this potential issue.",-0xPrt01VXD
1206,Wherever possible I would request that the authors create wayback or archived versions of the links in the paper and to prefer full links over shortened ones instead of relying on bit.ly's promise to be around forever,-0xPrt01VXD
1207,This will help ensure that their work remains accessible from a long term perspective.,-0xPrt01VXD
1208,This paper describes a question-answering system that is particularly designed for COVID19-related questions,R1jUmdauTnW
1209,The system is capable of providing two types of answers: potential spans containing the answers to the questions and potential bio-medical entities that the query user might be interested in,R1jUmdauTnW
1210,"The system design of the paper is well justified, and a online demonstration of the system is provided",R1jUmdauTnW
1211,I just have several questions as below.,R1jUmdauTnW
1212,"First, the ""related entities"" service in the online demonstration seems not working well",R1jUmdauTnW
1213,I tried several entities including the example shown in the paper but did not get any returned results in terms of the related entities.,R1jUmdauTnW
1214,"Second, I like the idea of retrieving both answers and related entities for query users",R1jUmdauTnW
1215,Do the authors think that it is possible to use the two systems to enhance the performance of each other in the future? Now the two systems seem disjoint to me.,R1jUmdauTnW
1216,"Finally, the authors claim that one of the highlight of the system is that it's real-time",R1jUmdauTnW
1217,"Of course, I've tried the online demonstration and did not feel significant delay in getting answers",R1jUmdauTnW
1218,But it is necessary for the authors to provide evalution results on its efficiency,R1jUmdauTnW
1219,"This work presents a real-time QA tool covidAsk, which provides both the answer/supporting documents, as well as related entities",R1jUmdauTnW
1220,The framework mainly uses two previous works (DenSPI and BEST) with BioBERT on CORD-19 and PubMed,R1jUmdauTnW
1221,"Despite some issues mentioned below, the paper contains substantial content that could promote the development of COVID-related QA/IR systems.",R1jUmdauTnW
1222,- The online demo was not functioning,R1jUmdauTnW
1223,"I have tried on multiple days with multiple ips, but only the cached examples work",R1jUmdauTnW
1224,"For example, https://covidask.korea.ac.kr/search?query=What+can+I+do+to+protect+my+family+against+COVID-19%3F will return an internal server error.",R1jUmdauTnW
1225,"- For a *real-time* system, there should be evaluations on latency, computing resources needed, etc",R1jUmdauTnW
1226,- I didn't see any evaluation on the entity search engine side,R1jUmdauTnW
1227,"- Table 5: how should we interpret the result? From my understanding, the performance of this work is much worse compared to some of the systems",R1jUmdauTnW
1228,"In that sense, would it make more sense to use one of the QA systems plus a regular search engine?",R1jUmdauTnW
1229,"- Section 1, Paragraph 4: The development of ...",R1jUmdauTnW
1230,"- Section 1, Paragraph 5: ""The first challenge is that there are no QA datasets that are tailored specifically to COVID-19",R1jUmdauTnW
1231,""" there is at least contemporaneous work COVID-QA (https://openreview.net/forum?id=JENSKEEzsoU).",R1jUmdauTnW
1232,- Section 3.4 NBCI -> NCBI,R1jUmdauTnW
1233,"This study presents a COVID-19 QA system, COVIDASK",R1jUmdauTnW
1234,It uses two models previously developed (DENSPI and BEST) as the basis and adapted accordingly to the evaluation on a manually crafted COVID-19 QA dataset,R1jUmdauTnW
1235,The manuscript is easy to follow,R1jUmdauTnW
1236,"First, why the indexing is at phrase-level? From Table 5 (the evaluation on the IR part), it seems that the search effectiveness on phrase-level indexing is lower than other systems indexing at passage or paragraph level",R1jUmdauTnW
1237,"Second, the evaluation dataset for the QA part was created by the authors themselves",R1jUmdauTnW
1238,Was the system evaluated on public COVID-QA datasets such as https://github.com/deepset-ai/COVID-QA and https://github.com/castorini/pygaggle/ ? The evaluation results on these datasets will be more representative since different COVID-19 QA systems can be evaluated on the same datasets.,R1jUmdauTnW
1239,Minor comment: please include more detail on the system such as the update frequency and any APIs supported.,R1jUmdauTnW
1240,The paper describes the construction of a website (system) that provides users with COVID-19-related information aggregated and translated from multiple reliable sources,5DrUl9nn5y
1241,Extensive use of crowdsourcing is done to check the reliability of the resources as well as to annotate them,5DrUl9nn5y
1242,The resources in languages other than English and Japanese are translated using a machine translation system called TexTra.,5DrUl9nn5y
1243,Reasons to accept: A large amount of human-annotated web documents is a valuable resource on its own,5DrUl9nn5y
1244,It is both costly and labor-consuming to build such a dataset.,5DrUl9nn5y
1245,Reason to reject: I am not sure if the evaluation of the topic classification is fair,5DrUl9nn5y
1246,A keyword-based baseline sounds too weak in comparison with a BERT-based neural network,5DrUl9nn5y
1247,A more sensible baseline would be an embedding-based similarity measure.,5DrUl9nn5y
1248,"Also, even with the BERT-based topic classifier, the precision of some topics is very low",5DrUl9nn5y
1249,It would have been interesting to see if the inter-annotator agreement is also low for such topics,5DrUl9nn5y
1250,"I think this is especially important because, in order to justify the validity of the dataset, the authors should have posted the reliability of the annotations among the annotators.",5DrUl9nn5y
1251,"In addition, as the system makes heavy use of machine translation, a simple result table about the quality of the translation would be have been informative.",5DrUl9nn5y
1252,"All in all, I acknowledge that the authors went to great lengths to construct a potentially useful dataset",5DrUl9nn5y
1253,"However, its potential value of the dataset is not convincingly presented in the paper in its current state.",5DrUl9nn5y
1254,This paper addresses an important topic,5DrUl9nn5y
1255,I visited the website and it certainly seems like a complicated and useful tool.,5DrUl9nn5y
1256,"I would really like to accept this paper based on the magnitude of work that the authors have put into the pipeline and dataset, but the paper in its current form seems a bit lacking in analysis and evaluation",5DrUl9nn5y
1257,"How is this paper beneficial to the NLP community? It certainly is a useful website for the general public, but it is unclear to me what I have learned and what ideas can be useful for NLP researchers or others working in the area.",5DrUl9nn5y
1258,"What are the details for the topic classification? E.g., what is the distribution of topics and how were they annotated, and with what annotator agreement? Did some articles belong to other topics? What was the ground truth? It could be helpful to show a confusion matrix for the BERT classifier.",5DrUl9nn5y
1259,Is there any evaluation of the translated text?,5DrUl9nn5y
1260,The main area of improvement that I see in this paper is that there is not much analysis of such a large dataset,5DrUl9nn5y
1261,Are the topics that are annotated with the articles the same or similar to articles that could be discovered by unsupervised clustering methods? Did they vary for the countries based on the number of cases at the time?,5DrUl9nn5y
1262,Any possible analysis on the distribution of n-grams?,5DrUl9nn5y
1263,"If there is a more thorough analysis of the system and/or an argument for what can be learned from this paper or how this paper can be useful for the NLP community, I would be happy to change my rating",5DrUl9nn5y
1264,"The paper describes a system that aggregates news and official sources on Covid-19 and presents them with a web interface to the public, as a way of providing reliable, comprehensive and up-to-date information",5DrUl9nn5y
1265,"The system is international, making extensive use of machine translation",5DrUl9nn5y
1266,It makes use of crowdsourcing in two places,5DrUl9nn5y
1267,The first use is to solicit recommendations for good information sources,5DrUl9nn5y
1268,"The second is to gather training and test data on individual articles, asking about relevance to Covid-19, helpfulness, the quality of translation and membership of 9 topics",5DrUl9nn5y
1269,The system also makes use of NLP components,5DrUl9nn5y
1270,"A classifier, based on BERT, classifies articles as to whether they are relevant to Covid-19, and assigns them to the 9 topics",5DrUl9nn5y
1271,"Furthermore, they deploy a pre-existing machine-translation system.",5DrUl9nn5y
1272,"Reasons to accept: The system being described potentially meets a need for citizens to have access to reliable, relevant and up-to-date information; the value of this paper largely depends on whether the system lives up to this promise",5DrUl9nn5y
1273,"Also, the system is of some interest to the NLP community",5DrUl9nn5y
1274,"The article classifier appears to get good results for relevance-to-Covid-19 - an F score on 0.84, substantially above a keyword-based baseline",5DrUl9nn5y
1275,The list of reliable information sources that they have collected is ,5DrUl9nn5y
1276,Furthermore it is often interesting to hear about the contexts into which NLP systems are to be deployed.,5DrUl9nn5y
1277,"Reasons to reject:  In general this paper suffers from a lack of evaluation, or even thought about evaluation, except for the NLP components (the evaluation of the classifiers is OK and the machine translation is done using a published system)",5DrUl9nn5y
1278,"The introduction sets out a rationale for building such a system, but does not present any evidence that such a system would be taken up by the public, or result in them being better informed that without it - the benefits are simply asserted",5DrUl9nn5y
1279,The conclusion is very brief and makes no mention of how and even whether the impact of the system will be studied,5DrUl9nn5y
1280,I also have concerns about the reliability of the crowdsourced annotations,5DrUl9nn5y
1281,"The system collects information from 10 people per article, yet no mention is made of how often the annotators agree",5DrUl9nn5y
1282,"Relatedly, the F scores for classification into 9 topics are a lot lower than for the relevance-to-Covid-19 classifier",5DrUl9nn5y
1283,"It is not clear whether this is caused by the classifier not being so good at the task, or whether the low scores reflect a task that is hard for humans to do consistenly",5DrUl9nn5y
1284,Some discussion of inter-annotator agreement would be helpful here.,5DrUl9nn5y
1285,"Conclusion: This paper describes a system that has a lot of promise, but provides very little information about how well it lives up to its promise",5DrUl9nn5y
1286,As such I cannot recommend that the paper is published in its current state.,5DrUl9nn5y
1287,This paper presents a system designed to help medical professionals to quickly get short answers about COVID-19 based on multiple source documents,k8f2nsLqyTZ
1288,"The system took part in a related Kaggle competition and won one of the tracks, which means that the answers for one particular question regarding Covid (What has been published about information sharing and inter-sectoral collaboration?) were considered to be the most relevant by medical experts",k8f2nsLqyTZ
1289,"The system consists of a three modules: Document Retriever, which includes Query Paraphrasing and Search Engine (Anserini), Relevant Snippet Selector (HLTC-MRQA and BioBERT) and Multi-Document Summarizer",k8f2nsLqyTZ
1290,"The authors released their tool and source code, which is undoubtedly very helpful for both medical professionals and NLP community working on similar tasks",k8f2nsLqyTZ
1291,"The search/snippet extraction/ranking part follows an established pipeline, and the authors improved the extraction results by using the ensemble of a domain-specific model (BioBERT) with generic one (HLTC-MRQA)",k8f2nsLqyTZ
1292,"However, the parts of the system which sound more novel raise some concerns.",k8f2nsLqyTZ
1293,"The Query Paraphrasing subsystem - the authors paraphrased the Kaggle task questions manually to improve the retrieval results, since, as they say, automatic question simplification methods did not help to improve the retrieval",k8f2nsLqyTZ
1294,One concern is that such paraphrasing could have introduced bias for Kaggle questions and is obviously not scalable for arbitrary questions; another question is why would you call it a “subsystem” instead of stating that the original questions were too complicated for the system to retrieve meaningful results?,k8f2nsLqyTZ
1295,The summarisers (both extractive and abstractive) are evaluated on datasets not related to COVID-19 or medical literature datasets,k8f2nsLqyTZ
1296,"Though it is true that there is no multi-document QFS dataset for COVID-19, the authors could have used a medical QFS dataset such as Mollá, Diego, and Maria Elena Santiago-Martinez",k8f2nsLqyTZ
1297,“Development of a corpus for evidence based medicine summarisation.” (2011),k8f2nsLqyTZ
1298,"[https://sourceforge.net/projects/ebmsumcorpus/], which would give a better indication of summarisation performance than unrelated news/debates datasets",k8f2nsLqyTZ
1299,"Moreover, though the suggested extractive and abstractive models improve over the baselines of Lead and vanilla BART, the reported results for DUC 2005, 2006, 2007 datasets are worse than that of old non-neural extractive models [see, for example, (Ye, S., Chua, T",k8f2nsLqyTZ
1300,Document concept lattice for text understanding and summarization,k8f2nsLqyTZ
1301,"Information Processing & Management, 43(6), 1643-1662.] and recent neural abstractive models [for instance, (Zhu, Haichao, Li Dong, Furu Wei, Bing Qin, and Ting Liu",k8f2nsLqyTZ
1302,“Transforming Wikipedia into Augmented Data for Query-Focused Summarization.” arXiv preprint arXiv:1911.03324 (2019)],k8f2nsLqyTZ
1303,There is no qualitative evaluation of the results apart from the claim that “effectiveness of the system has been proved by winning one of the tasks”,k8f2nsLqyTZ
1304,"Unfortunately, it’s just one task out of ten where the authors knew the questions and pre-processed them to achieve better results",k8f2nsLqyTZ
1305,"If one checks the results of the system for other questions, say “What do we know about asymptomatic transmission”, 4 out of 6 sentences of the abstractive summary have no relation to the question but rather talk about paediatric patients and PTSD",k8f2nsLqyTZ
1306,"If quantitive evaluation against the COVID corpus was impossible, the authors could have performed a qualitative evaluation of relevance/factuality of the resulting summaries in line with recent tendencies to evaluate factuality instead of relying on ROUGE scores.",k8f2nsLqyTZ
1307,"A suggestion rather than criticism - the results could have probably be improved by incorporating more biomed-related resources, for example, by fine-tuning on PubMed or CovidSum dataset instead of CNN/DailyMail ",k8f2nsLqyTZ
1308,Authors present question answering and query focused multi-document summarization techniques for mining scientific literature given a query,k8f2nsLqyTZ
1309,"The paper is very well-written with enough detail across the pipeline comprising three modules: 1) Document Retriever, 2) Relevant Snippet Selector, and 3) Query-focused Multi-Document Summarizer",k8f2nsLqyTZ
1310,They provide good evaluation with baselines and analysis,k8f2nsLqyTZ
1311,Open-sourcing the code along with clear instructions is commendable,k8f2nsLqyTZ
1312,"Related work section could shed additional light on similar approaches or settings, but is understandable given the page lmits",k8f2nsLqyTZ
1313,Have authors interrogated cascading errors due to the nature of the pipeline? It’d be good to briefly comment on that,k8f2nsLqyTZ
1314,This paper describes the CAiRE-COVID QA and query-focused multi-document summarization system for COVID-19 literature,k8f2nsLqyTZ
1315,The system links together several SOTA models in QA and summarization in a novel and effective way,k8f2nsLqyTZ
1316,"Overall, the modeling decisions are well justified, and the performance of the system is quite impressive.",k8f2nsLqyTZ
1317,"* The authors do not remark on factuality in abstractive summarization, though it would seem to be an important consideration here due to the domain being of healthcare and public health consequence.",k8f2nsLqyTZ
1318,"* Related: for both extractive and abstractive multi-document summarization, especially in the scientific domain, contradictions can be a problem",k8f2nsLqyTZ
1319,"How are the authors considering addressing this? Keeping track of sources as the authors have done for extractive summarization gives users a way of keeping track of this information, but what about in the abstractive case?",k8f2nsLqyTZ
1320,"Summary: This paper presents a conversational system, Expressive Interviewing, that is tailored to assist people in coping with the impact of COVID-19 on mental health",gIJfALc6Gz
1321,The system asks users a variety of questions in an attempt to make them write about their feelings and emotions,gIJfALc6Gz
1322,"Before and/or after interacting with the system, users are asked various questions about their emotional states and their interaction experience (e.g., stress levels, life satisfaction, meaningfulness of interaction with the system)",gIJfALc6Gz
1323,The system uses word occurrence frequency statistics from user inputs to select appropriate questions for specific topics or word categories,gIJfALc6Gz
1324,"To validate the system’s functionality and usefulness, the authors collected interactions with 174 users and report a thorough analysis on the impact of using the system based on the collected data",gIJfALc6Gz
1325,"Furthermore, the system’s usefulness for user interaction related to COVID-19 is compared Woebot, a related general-purpose mental health application offering a conversational agent",gIJfALc6Gz
1326,"Based on data from 12 participants discussing topics related to COVID-19, the authors show that using Expressive Interviewing, participants report lower stress levels as compared to using Woebot, and that it is easier to use, motivated the users to engage in the conversation more strongly and led to more meaningful interactions",gIJfALc6Gz
1327,"The paper is well-structured and easy to read, the interface is straightforward and easy to use, and the idea of providing such an online tool is interesting",gIJfALc6Gz
1328,The quantitative and qualitative analyses are thorough and provide insights into how users interact with the system,gIJfALc6Gz
1329,"The system’s internals are only described in the text, a figure or table to illustrate its functionality would be very helpful to better understand the underlying processes.",gIJfALc6Gz
1330,The comparison against Woebot furthermore suggests that Expressive Interviewing is better suited for users discussing their concerns related to COVID-19,gIJfALc6Gz
1331,"However, the authors do not provide a justification for why Woebot was selected for comparison and why their system was not compared against the Wysa tool",gIJfALc6Gz
1332,"Is there a reason for this? Furthermore, the sample size is very small and statistical analyses would support the findings of this experiment.",gIJfALc6Gz
1333,"In sum, I believe that this is an interesting tool which has the potential to find applications in in the context of COVID-19, but I would encourage the authors to better illustrate the system’s design and to conduct more detailed analyses on the comparison to the Wysa/Woebot conversational agents.",gIJfALc6Gz
1334,- Table 1: there’s a typo in the caption (“ratinga”).,gIJfALc6Gz
1335,"- Table 5: in the caption, there’s a missing “of” after “Comparative evaluation” and a typo “...with scores > 3 in a 7-point…”.",gIJfALc6Gz
1336,Overall - I like the idea and the paper is well-written,gIJfALc6Gz
1337,The online system is great - I did it and I much appreciate the authors' effort on making it available.,gIJfALc6Gz
1338,I feel that some comments need addressing;,gIJfALc6Gz
1339,- intro paragraph: references are missing,gIJfALc6Gz
1340,"It would also be good to look at some of thee other work on well-being, mental health, etc",gIJfALc6Gz
1341,- p1 (last sentence): you say multiple meta-analyses but mention only one,gIJfALc6Gz
1342,- p2 (paragraph on MI): maybe add example questions used in MI sessions,gIJfALc6Gz
1343,- general aspects about the chat interaction:,gIJfALc6Gz
1344,- - how long was the interaction?,gIJfALc6Gz
1345,- - how often does the system follow up?,gIJfALc6Gz
1346,- - what are the rules/criteria for following up (or not)?,gIJfALc6Gz
1347,- - what were the criteria for detecting emotions?,gIJfALc6Gz
1348,- - how was the detection of topics and emotions validated? And what was the performance?,gIJfALc6Gz
1349,"- - how often were responses flagged for the reasons given on p3 (right column, middle)",gIJfALc6Gz
1350,- - all in all: the comments above all require more detail on the system,gIJfALc6Gz
1351,- related: the sample is quite small: why not use it in an online study with a few hundreds? This would allow for a more representative view on the system and its comparison tools (see below),gIJfALc6Gz
1352,- another big issue relates to the statistical reporting:,gIJfALc6Gz
1353,"- - since you present multiple correlations, you should correct the significance alpha level by the number of comparisons (e.g",gIJfALc6Gz
1354,"0.05 for 1, 0.025 for 2 comparisons, 0.005 for ten comparisons, etc.)",gIJfALc6Gz
1355,- - absent that Bonferroni correction the findings capitalise on chance and might contain FP statistical artifacts.,gIJfALc6Gz
1356,- - using p < .05 is already very liberal (many argue that we need to move to stricter values --> https://www.nature.com/articles/s41562-017-0189-z),gIJfALc6Gz
1357,"- - an interpretation of ""just-not"" significant relationships is inappropriate as these fail to meet your own statistical criterion (even in its uncorrected and liberal form)",gIJfALc6Gz
1358,- - the majority of the results section would thus need rewriting,gIJfALc6Gz
1359,"- please add detail on the participants (who were they, where was the sample obtained from, etc.)",gIJfALc6Gz
1360,- a comparison to a non-chat-based tool would be interesting (e.g,gIJfALc6Gz
1361,how does your system compare to simple writing?),gIJfALc6Gz
1362,"- p7 (left col, bottom): ""more associated with the group [...]"" than what?",gIJfALc6Gz
1363,- the comparison with Woebot is interesting but incomplete - I'd like to see a proper sample that meets criteria of experimental research (e.g,gIJfALc6Gz
1364,either they get A or B and then you assess which one was better).,gIJfALc6Gz
1365,- - the comparison uses Likert scales but you report a binarisation based on an arbitrary cut-off (> 3) - please report means and SDs so we can assess differences between the users' ratings of either tool,gIJfALc6Gz
1366,"- - both points above will be solvable with a proper, large sample",gIJfALc6Gz
1367,"- I appreciate the scope of this paper is on introducing the tool but I'd really like to see a section on linguistic analyses of the responses (what did they write about, did emotions change during the coversation or depending on the topic?)",gIJfALc6Gz
1368,Overall: I'd like to see this paper reworked with proper analysis,gIJfALc6Gz
1369,The tool is great but it requires more adequate statistical tests and more analyses to fully introduce the system (and its limitations).,gIJfALc6Gz
1370,**Recommendation:** Authors must include system description that would allow for reproduction,gIJfALc6Gz
1371,"Comparison to Woebot is promising, but not thorough",gIJfALc6Gz
1372,Authors engage with ethical nature of their work,gIJfALc6Gz
1373,Missing methods section is glaring; system is not explained or reproducible,gIJfALc6Gz
1374,Authors should prefer interval or effect size over significance tests,gIJfALc6Gz
1375,Authors should discuss how they intend to assess their system earlier in the paper,gIJfALc6Gz
1376,The authors introduce a COVID-19 specific mental-health support chatbot that focuses on motivational interviewing and expressive writing,gIJfALc6Gz
1377,The assess the correlations of various mental health statuses against the time users spent using this bot in a study,gIJfALc6Gz
1378,"Additionally, they compare user-ratings of satisfaction against a standard system: Woebot",gIJfALc6Gz
1379,The paper has major shortcomings in terms of system description and analysis.,gIJfALc6Gz
1380,The paper's chief flaw is the omission of a meaningful system description,gIJfALc6Gz
1381,The author's have an obligation to describe the system in such a way that a skilled practitioner (or team thereof) would be able to reproduce the system,gIJfALc6Gz
1382,The only hints to how this system works are that it uses motivational interviewing and expressive writing as influences and that it is built using Python and Javascript,gIJfALc6Gz
1383,The authors should describe which NLP techniques are used for the various parts of their chat system and how these pieces interact with one another.,gIJfALc6Gz
1384,"Additionally, the paper's analysis is lacking",gIJfALc6Gz
1385,"The author's use significance testing for their analysis, which makes it hard to gauge the true meaningfulness of their findings",gIJfALc6Gz
1386,They should prefer effect size or confidence intervals,gIJfALc6Gz
1387,"Additionally, no statistical testing is done for the comparison with Woebot; however, this does not stop the authors from making claims about differences between the systems' performances",gIJfALc6Gz
1388,The authors must perform statistical tests if they wish to make claims about the differences in performance,gIJfALc6Gz
1389,"Authors should review [Yan, Song and Wu (2016)](http://www.ruiyan.me/pubs/SIGIR2016.pdf) as example, noting ",gIJfALc6Gz
1390,Clear distinction between system description and system evaluation,gIJfALc6Gz
1391,The paper describes AskMe system which is a query engine that searches COVID-19 literature and additionally offers further processing of the results using NLP tools.,f6WrxuptBwW
1392,"It outlines the system briefly and makes a comparison with other related search engines, namely, LitCovid and iSearch.",f6WrxuptBwW
1393,"While searching over the latest literature is indeed an important aspect, the search process is keyword-based (as opposed to vector-space-based) and limited to titles and abstracts.",f6WrxuptBwW
1394,"In addition, as the authors acknowledge in the paper, only a preliminary evaluation is performed, and the result is not yet convincing.",f6WrxuptBwW
1395,"Although the work in its current state is not yet mature, I do applaud the authors for building such a system that has a great potential to benefit medical researchers in the field.",f6WrxuptBwW
1396,The authors describe the AskMe system – a search engine utilizing the CORD-19 dataset to retrieve documents per natural language queries on the pandemic,f6WrxuptBwW
1397,The paper describes the engine in detail and provide a qualitative evaluation of its retrieval results to those of the LitCovid system,f6WrxuptBwW
1398,The paper is generally clear and well-written.,f6WrxuptBwW
1399,"The weaknesses of this work lie in two main aspects: (1) scoring algorithm for relevant document retrieval, and (2) qualitative (and not entirely convincing) evaluation",f6WrxuptBwW
1400,Re (1): Using only title and abstract for scoring a document is not considered sufficient for a retrieval task and would naturally render the proposed system inferior to others,f6WrxuptBwW
1401,"Additionally, I appreciate the retrieval algorithm presented on page 3, but wonder how it compares to traditional (SOTA among them) IR approaches, including vector space, probabilistic and language models",f6WrxuptBwW
1402,"Re (2): It’s hard to draw any conclusions from (largely inconclusive) evaluation by a single expert, as presented on page 4",f6WrxuptBwW
1403,"The authors could attempt, for example, the TREC-COVID (CORD-19-based) benchmark (https://ir.nist.gov/covidSubmit/index.html) and test how their engine performs on this labeled data, when compared to other search engines.",f6WrxuptBwW
1404,"All in all, it seems like an interesting but not sufficiently mature work in its current form.",f6WrxuptBwW
1405,This work describes how the LAPPS Grid was augmented to support querying over the CORD-19 corpus,f6WrxuptBwW
1406,"This extension makes available filtering features in Grid, as well as the suite of Grid NLP tools, for querying and accessing data in CORD-19",f6WrxuptBwW
1407,"The authors suggest that Grid retrieval performs at a comparable level to other COVID search engines like Vespa or CORD19.aws, though no significant evaluation was performed.",f6WrxuptBwW
1408,It’s hard to gauge from the presented evaluation exactly how this system performs relative to other systems,f6WrxuptBwW
1409,"The weakest part of the paper is the evaluation, which currently relies on a single expert evaluator comparing results from different search engines",f6WrxuptBwW
1410,The authors should consider evaluating on available CORD-19 retrieval datasets such as TREC-COVID (https://ir.nist.gov/covidSubmit/index.html).,f6WrxuptBwW
1411,This article describes experiments on MT of covid-related documents into low-resource languages,cei3i5Wa-kk
1412,"The article is well motivated, but it would help to focus on the challenges and current approaches for low-resource MT, including unsupervised methods",cei3i5Wa-kk
1413,"Existing research streams are mentioned in a sentence, without providing enough context",cei3i5Wa-kk
1414,"For work on the unsupervised paradigm, see for instance Artetxe et al",cei3i5Wa-kk
1415,For gaining space some parts of the motivation (such as Table 1) could be removed,cei3i5Wa-kk
1416,Another section where more information would be desired is on the used dataset,cei3i5Wa-kk
1417,"There is no mention of the process to translate the data and its quality, or whether it has been used for MT in previous work.",cei3i5Wa-kk
1418,"With regards to the experiment, it is limited to applying an standard supervised solution exploring only the use of factoring",cei3i5Wa-kk
1419,It would be interesting to explore more creative solutions and evaluation frameworks,cei3i5Wa-kk
1420,"For instance, they claim that the training data is insufficient, and they could test a learning curve to provide more clarity on this aspect",cei3i5Wa-kk
1421,Monolingual data could also be used to test extensions to the model.,cei3i5Wa-kk
1422,"On the evaluation, it would be interesting to provide context on what the BLEU scores mean for a practical system, and provide at least some qualitative error analysis.",cei3i5Wa-kk
1423,"- P1: ""very essential"": remove ""very""",cei3i5Wa-kk
1424,- P1: missing reference for English-Luganda SMT,cei3i5Wa-kk
1425,"- P2: ""one of the major languageS""",cei3i5Wa-kk
1426,"- P2: ""one of the official languageS""",cei3i5Wa-kk
1427,"- P2: ""low resolution"": low resource",cei3i5Wa-kk
1428,An Effective Approach to Unsupervised Machine Translation ,cei3i5Wa-kk
1429,"Mikel Artetxe, Gorka Labaka, Eneko Agirre ",cei3i5Wa-kk
1430,"This work reports on a series of experiments using neural machine translation systems for translating English into five low-resource languages (Lingala, Nigerian Fulfulde, Kurdish Kurmanji, Kinyarwanda, Luganda) focusing on information related to COVID-19",cei3i5Wa-kk
1431,"To do this, parallel corpora of approximately 3000 sentence pairs for each low-resource language are applied to two NMT models.",cei3i5Wa-kk
1432,"While this paper discusses an important topic, the datasets used to train the specified translation models from English into the low-resource languages are too small, and a larger amount of sequence pairs and/or a different approach (e.g., using domain adaptation techniques) to this task is required",cei3i5Wa-kk
1433,There is a missing reference at the end of Section 1 (English-Luganda SMT system).,cei3i5Wa-kk
1434,Some of the information in the Introduction could be moved to the Related Work section.,cei3i5Wa-kk
1435,The BLEU metric mentioned in the paper requires a reference which is not provided.,cei3i5Wa-kk
1436,The NLTK library used in the experiments requires a reference which is not provided.,cei3i5Wa-kk
1437,"In Section 2, is the phrase “low resolution” mistakenly used for “low resource”?",cei3i5Wa-kk
1438,This work presents NMT models for COVID-19 related documents for five low resource languages in Africa and Mid-East Asia,cei3i5Wa-kk
1439,"The topic presented is definitely crucial, and the paper is easy to follow",cei3i5Wa-kk
1440,I appreciate the author detailed all procedures to train and evaluate the models,cei3i5Wa-kk
1441,"However, there are a few key issues that should be resolved before moving forward:",cei3i5Wa-kk
1442,  * The translation model only takes <3k data for training,cei3i5Wa-kk
1443,I doubt if any useful information could be learned with this limited data,cei3i5Wa-kk
1444,The author may consider transfer learning and data augmentation to mitigate the scarcity of the data,cei3i5Wa-kk
1445,  * The vocabulary contains only 300 tokens,cei3i5Wa-kk
1446,Is there any specific consideration for this?,cei3i5Wa-kk
1447,  * The paper uses unigram BLEU for evaluation,cei3i5Wa-kk
1448,"However, unigrams only capture limited signal, and it is hard to make system comparison and justify that factored NMT is better with a rather limited metric",cei3i5Wa-kk
1449,BLEU-4 seems to be a better option.,cei3i5Wa-kk
1450,"  * Given the test dataset has only 100 sentences, it is important to obtain confidence intervals to support the argument of one system is better than another",cei3i5Wa-kk
1451,  * The author mentioned `..,cei3i5Wa-kk
1452,"to ensure that COVID-19 related *authentic information* reaches the common people in their own language...` However, it is unclear whether the information was translated factually correctly",cei3i5Wa-kk
1453,"In the long run, it is crucial to check the correctness of the translated sentences to make sure all critical information was translated correctly.",cei3i5Wa-kk
1454,This paper introduces an application that enables researchers to explore COVID-19 literature,oNQvUVz4yb1
1455,"The functions of the application include finding similarity between publications, targeting central sentences in a publication, and extracts NER from publications",oNQvUVz4yb1
1456,"* This application could be useful for researchers to conveniently explore publications related to COVID-19, or maybe any other topics not limited to COVID-19",oNQvUVz4yb1
1457,"* While the proposed methods are reasonable, the lack of direct evaluation raises the question how well they  perform",oNQvUVz4yb1
1458,"For example, STS seems a key component in constructing the publication network and finding central sentences, but there is no direct evaluation how well the proposed method finds similar publications",oNQvUVz4yb1
1459,"Despite the indirect evaluation using ""one corpus of the topic of",oNQvUVz4yb1
1460,"transcriptional-regulation"", the performance of SciBERT may not be consistent in STS corpus from other domain",oNQvUVz4yb1
1461," If the STS is already poor at the first place, errors could propagate and amplify in the pipeline and make results less accurate",oNQvUVz4yb1
1462,"Also in finding central sentences, how good is using STS by SciBERT compared to other traditional methods, such as traditional text ranking algorithms? And there is no direct evaluation of the OGER in COVID-19 publications",oNQvUVz4yb1
1463,"Could OGER be poor in recognizing COVID-19 NERs that have not been seen in the training data of OGER? Without any quantitative analysis to answer these questions, the application is less useful to the community",oNQvUVz4yb1
1464,* How did the authors chose 0.35 and 0.65 for Eqn.2 ? ,oNQvUVz4yb1
1465,"In general the application could be potentially promising and helpful, but the authors need to have some direct evaluation to show the efficacy of the application",oNQvUVz4yb1
1466,This demo paper presents a system for searching COVID-19 literature and relating similar sentences both within and across documents,oNQvUVz4yb1
1467,The search component is augmented with concept search,oNQvUVz4yb1
1468,The goal according to the authors is to facilitate skim reading by visualising  salient connections between sentences.,oNQvUVz4yb1
1469,I would like to applaud the authors for this effort which shows that a lot of work has been put into making the system operational,oNQvUVz4yb1
1470,I find the eagle-view of the internal and external links interesting and definitely worthy of further exploration,oNQvUVz4yb1
1471,"I would also like to raise several shortcomings, possible misunderstandings from my part, and suggestions for improvement.",oNQvUVz4yb1
1472,"In section 3.2, a corpus on transcriptional regulation is introduced, but little is said about it and the annotations it contains",oNQvUVz4yb1
1473,"Similarly, a short description of DistilBERT is in place, as well as motivating the decision to include this model in the present study.",oNQvUVz4yb1
1474,I find interpreting the results from Table 1 quite difficult: How exactly was this study involving correlation carried out? What does e.g,oNQvUVz4yb1
1475,the row including SciBERT tell us? Is it about correlation of cosine scores to human judgements in the transcriptional-regulation corpus? ,oNQvUVz4yb1
1476,"In 3.2.2 (Network of publications), could the authors say more about the directionality of the graph? Is it not the case that edge weight e(A->B) should equal e(B->A) since the set of sentence connections is the same in both cases, and the cosine is symmetrical? Similarly, eq",oNQvUVz4yb1
1477,"(2) distinguishes between s_i->s_j and s_j->s_i, but I fail to see how these can be different.",oNQvUVz4yb1
1478,"If I wrongly understand STS to be the cosine similarity, please make that clear in the paper.",oNQvUVz4yb1
1479,The coverage of the tool appears rather limited; how will the tool scale to larger collections? ,oNQvUVz4yb1
1480,"For computing semantic similarity over a large number of sentence(/document) combinations, Maximum Inner Product Search (MIPS) algorithms may be relevant",oNQvUVz4yb1
1481,"These are used to find the approximate top k documents, using running time and storage space that scale sub-linearly with the number of documents.",oNQvUVz4yb1
1482,"There is little evaluation in the current paper, both in terms of the appropriateness of the STS measure and the usability, and no related tools are discussed either",oNQvUVz4yb1
1483,"This paper contains a substantial related works section, which may be useful: https://arxiv.org/pdf/2008.07880.pdf.",oNQvUVz4yb1
1484,"I would suggest the authors to not use “smart” to describe the tool as it doesn’t tell the reader much, and there’s no explanation in the paper what makes the tool smart",oNQvUVz4yb1
1485,"Also, try to provide a more informative title for the paper, e.g",oNQvUVz4yb1
1486,“exploring COVID-19 literature with semantic similarity networks”,oNQvUVz4yb1
1487,"Finally, the paper should be proofread (e.g",oNQvUVz4yb1
1488,"firsts → first, and many more), and checked for coherence, e.g",oNQvUVz4yb1
1489,"“To grasp the nitty-gritty of a document or a collection of them is clearly much more than summarizing or finding interconnections but, comprehend what is expressed in the texts is part of the process.”",oNQvUVz4yb1
1490,The study authors describe an NLP platform that aims to identify central knowledge items within a collection of publications by: 1) highlighting the central sentences in an article; 2) creating a semantic connection graphs of related articles 3) enabling browsing across semantically related statements an; 4) and enabling named entity searches,oNQvUVz4yb1
1491,"To achieve these tasks, the authors use Semantic Textual Similarity (STS) and Named-Entity Recognition and Disambiguation",oNQvUVz4yb1
1492,"While the concept is interesting, the authors do not demonstrate its accuracy or conduct any evaluations of the platform on COVID-19 literature, but rather perform an indirect validation of STS on the topic of transcriptional regulation",oNQvUVz4yb1
1493,"In the results section, the study authors primarily describe the features of the tool",oNQvUVz4yb1
1494,"From the information that was presented in the paper, it is difficult to determine the applicability or the effectiveness of the platform in aiding knowledge identification/discovery/exploration and summarization as it relates to a diverse and rapidly expanding evidence base",oNQvUVz4yb1
1495,"In building the application, the authors use exising NLP platforms, namely SciBERT and OGER, a biomedical/genetic entity recognizer",oNQvUVz4yb1
1496,"In order to better assess the publication, the authors would need to provide further examples of the tool's performance",oNQvUVz4yb1
1497,This work is centered on automatic detection of tweets containing self-reported symptoms by COVID-19-positive patients,Gr7aDbSOxri
1498,The problem is framed as a binary classification task,Gr7aDbSOxri
1499,They use dataset from a previous study and train a BERT classifier to classify the tweets,Gr7aDbSOxri
1500,Their focus on developing an early warning system is commendable.,Gr7aDbSOxri
1501, Paper is comprehensible and well-written but authors could have done a better job at optimizing the space limitations,Gr7aDbSOxri
1502,Paper lacks detail on the technical contributions,Gr7aDbSOxri
1503,"Given the data imbalance issue, it would be better if additional metrics like Cohen’s Kappa are computed and ROC Curves are shared",Gr7aDbSOxri
1504,Dataset section could have benefitted from more detail and the Experimental Dataset is on shaky grounds both from a timeline standpoint and confusion with flu symptoms standpoint,Gr7aDbSOxri
1505,"Given the broader overlap of COVID-19 symptoms with flu symptoms, authors should consider dedicating a subsection to this point and do further analysis on false positives and false negatives",Gr7aDbSOxri
1506,Authors should also share the rationale behind picking BERT-large model and consider doing more baselines.,Gr7aDbSOxri
1507,"In this work, the authors present a text classification approach for the automatic detection of twitter posts containing self-reported COVID-19 Symptoms",Gr7aDbSOxri
1508,"This work is quite interesting and very needed, as there is a clear difference in finding posts that mention symptoms and actually being able to attribute them to the user",Gr7aDbSOxri
1509,The contribution is well framed and nicely presented alongside other similar approaches or related works,Gr7aDbSOxri
1510,"However, these first sections are a bit long for a short paper, taking space away from other more insightful section like having a proper dataset description, which is a bit anemic in this paper pointing out to a different paper, and only having a Table 1 to observe the massive class imbalance in the set (1 positive to 9 negatives)",Gr7aDbSOxri
1511,"Using a dataset limited to February, is a minor weakness as there are plenty of other larger and more comprehensive datasets available",Gr7aDbSOxri
1512,One of the initial issues is why apply the models to data from Dec,Gr7aDbSOxri
1513,2020 which was not the main time for COVID to be widely spread in larger parts of the Twitter population of users? (USA),Gr7aDbSOxri
1514,"A held-out set from further into the main pandemic months, or at least before the conception of the paper, would be a more realistic validation in terms of performance",Gr7aDbSOxri
1515,A large amount of space was given to show some tweet samples (which could be an appendix instead) taking away space for content,Gr7aDbSOxri
1516,The classifier built is well described with the results reported on Table 3,Gr7aDbSOxri
1517,"These numbers show that the classifier is performing unsurprisingly well on the most represented class, which was the negative one",Gr7aDbSOxri
1518,"It also shows that it misses 1 in every 3 positive tweets, which is definitely not ideal",Gr7aDbSOxri
1519,"Comparison with other classifiers, at least as baselines, should be the standard these days and it is missing from this paper",Gr7aDbSOxri
1520,"The discussion for an early warning system is interesting and the dataset used might be ideal for this, however the performance seems to not be quite there, more tuning and playing around with the architecture might give improvements",Gr7aDbSOxri
1521,"Overall, this is an interesting problem to solve, but the current manuscript needs considerable work to be a valuable and more robust contribution",Gr7aDbSOxri
1522,This work is about building a classifier to detect tweets that contain self-reported symptoms by COVID-19-positive patients automatically,Gr7aDbSOxri
1523,The authors built a BERT-based model that achieves reasonable performance.,Gr7aDbSOxri
1524,"- Easy to follow, straightforward storyline",Gr7aDbSOxri
1525,- Mostly reasonable choices of data/model/analysis,Gr7aDbSOxri
1526,"Overall, the work is still preliminary: the dataset was a contribution from another paper from the authors; the model is straightforward BERT; the analysis isn't sufficient (see below for details).",Gr7aDbSOxri
1527,"  - The authors chose to use BERT-large, which is ok",Gr7aDbSOxri
1528,"However, it would be better to include justifications on how much gain there is compared to a smaller model (BERT-base), which is more feasible for detection tasks.",Gr7aDbSOxri
1529,  - The authors may consider BERTweet (https://arxiv.org/abs/2005.10200),Gr7aDbSOxri
1530,"  - No baseline is included in the paper, making it hard to justify how well the model performs",Gr7aDbSOxri
1531,"I recommend the authors to add simple baselines, e.g., lexicon-based methods, for comparison.",Gr7aDbSOxri
1532,  - The most we care about should be the positive class,Gr7aDbSOxri
1533,"However, the positive class's performance isn't perfect",Gr7aDbSOxri
1534,"It would be hard to deploy systems with this error rate (precision = 0.65, recall = 0.8) to the wild",Gr7aDbSOxri
1535,The authors may also consider factoring the discourse and user demographics about the users into account to see whether there is a gain.,Gr7aDbSOxri
1536,"  - Given that the negative class is the majority, it seems less useful to include accuracy as an evaluation metric",Gr7aDbSOxri
1537,The authors should also consider emphasizing the positive class instead of highlighting the good performance of the negative class.,Gr7aDbSOxri
1538,  - There is no error analysis,Gr7aDbSOxri
1539,The authors should discuss why the false positives/negatives happened with their classifier.,Gr7aDbSOxri
1540,  - More details on model training should be provided,Gr7aDbSOxri
1541,"  - In table 2, negative side: `¡hashtag¿`, `amp;` should be fixed/escaped.",Gr7aDbSOxri
1542,The authors investigate twitter user’s reactions and concerns about COVID-19 in the US and Canada through topic modeling and aspect-based sentiment analysis,lKT2hyQ3FYx
1543,They report the change in the prevalence of 20 specific topics over time as well as inference of sentiment based on 545 aspect terms and 60 domain specific opinion terms,lKT2hyQ3FYx
1544,"While the described work is interesting, the authors did not evaluate their model and do not provide any evidence of the model accuracy",lKT2hyQ3FYx
1545,"From the information provided in the paper, it is not possible to determine if the model does actually preform as expected and if the proposed approach can be reliably used to inform public health decision-making",lKT2hyQ3FYx
1546,"While, theoretically, information obtained from sentiment analysis can be helpful in steering public health interventions, there is also a significant risk that false information can be detrimental by misguiding action and depleting limited public health resources",lKT2hyQ3FYx
1547,"For this reason, evaluation of models that are used by health authorities requires rigorous validation before it can be considered for use",lKT2hyQ3FYx
1548,"This work conducts experiments with topic modelling (using LDA) and aspect-based sentiment analysis (using a weakly-supervised approach) on a corpus of 320,000 tweets related to COVID-19 from Canada and the United States posted between January and May 2020",lKT2hyQ3FYx
1549,The findings show that there are both similarities and differences between the most popular topics for the Canadian and United States tweets,lKT2hyQ3FYx
1550,"An analysis of topic changes over time reveals that topic popularity is similar between tweets from both countries, and that the popularity changes match with public health activities related to the specific topics (e.g., social distancing and the number of tests and cases)",lKT2hyQ3FYx
1551,The sentiment analysis experiments show mixed sentiments for a few selected aspects,lKT2hyQ3FYx
1552,The experiments for aspect-based sentiment analysis could be described in more detail,lKT2hyQ3FYx
1553,"For instance, it is not specified how many public health experts edited the suggested lexicons and what the exclusion criteria for certain keywords were",lKT2hyQ3FYx
1554,It would also be helpful to provide a larger sample of identified aspects,lKT2hyQ3FYx
1555,"Furthermore, the authors compute sentiments for 545 aspect terms, but only show results (Fig",lKT2hyQ3FYx
1556,2) of a few selected aspects,lKT2hyQ3FYx
1557,"Here, it would be interesting to see, for example, averaged results across aspects",lKT2hyQ3FYx
1558,It would also be interesting to analyze how the sentiment changed over time (similar to the topic modelling approach).,lKT2hyQ3FYx
1559,"Overall, the proposed approach can be valuable for better understanding how people on social media react to the pandemic and corresponding governmental decisions",lKT2hyQ3FYx
1560,"However, the analysis could be more fine-grained, and additional experiments would be beneficial to better demonstrate the potential of such an analysis.",lKT2hyQ3FYx
1561,"**Recommendation:** Though mostly sound, the paper does not make a novel contribution; reject.",lKT2hyQ3FYx
1562,Dataset and method are clearly described,lKT2hyQ3FYx
1563,Approach is not novel - similar experiments have been performed on similar datasets,lKT2hyQ3FYx
1564,Proposed connection to potential interventions is not demonstrated,lKT2hyQ3FYx
1565,Not obvious how human-in-the-loop approach benefited anlaysis,lKT2hyQ3FYx
1566,The authors perform a topic analysis and sentiment analysis of an open Twitter dataset on the topic of COVID-19,lKT2hyQ3FYx
1567,The authors identify differences in the preference for topics between Canadian and American Twitter users,lKT2hyQ3FYx
1568,"Additionally, they identify differences between sentiment across topics, including negative sentiment towards the ""Asians"".",lKT2hyQ3FYx
1569,"Unfortunately, none of this is novel",lKT2hyQ3FYx
1570,"As many as 14 papers have performed topic analysis COVID-19 Twitter data as of early May [Ordun et al., 2020](https://arxiv.org/abs/2005.03082)",lKT2hyQ3FYx
1571,"And indeed, even some of the paper's more nuanced findings, such as the implications of anti-Asian or sinophobic sentiment have been documented (e.g., [here](https://arxiv.org/pdf/2004.04046.pdf) and [here](https://arxiv.org/pdf/2005.12423.pdf))",lKT2hyQ3FYx
1572,"Overall, the paper does is not novel enough in its approach, data, or findings to justify inclusion.",lKT2hyQ3FYx
1573,**Reproducability:** Researchers could easily reproduce this paper,lKT2hyQ3FYx
1574,The authors describe the development of a task-informed document retrieval framework that leverages latent factors learned through topic models,aONAwGO-Oee
1575,The framework is applied to the CORD-19 corpus and compared to a naıve keyword-based document retrieval approach,aONAwGO-Oee
1576,The authors note that they are not able to quantitatively compare the keyword and topic-modeling based approaches on the basis of precision and recall in the absence of relevance labels,aONAwGO-Oee
1577,The key intent of the CORD-19 dataset was to facilitate automation of knowledge synthesis for specific questions,aONAwGO-Oee
1578,"Given the exponentially increasing number of studies, automation of knowledge synthesis would require a model to, as precisely as possible, identify evidence that is most relevant and contains information which can be analyzed to provide answers to those questions",aONAwGO-Oee
1579,"While the idea of topic modeling is interesting, the authors do not provide any indication that such an approach, as described, would be able to support any relevant evidence synthesis",aONAwGO-Oee
1580,"Therefore, it is impossible to comment on the model and draw conclusions on its usefulness or advantages when compared to other information/document retrieval methods.",aONAwGO-Oee
1581,The paper presents a task-informed document retrieval framework for search over the CORD-19 dataset,aONAwGO-Oee
1582,"The authors suggest that latent variables found in topic distribution of each task and document can contribute to the higher quality retrieval, specifically, they score each document by the JSD between its topic distribution and that of the task at hand",aONAwGO-Oee
1583,"The approach is well described and sufficiently detailed throughout the paper, but lacks better motivation – why the authors think this method is likely to outperform the keyword-based search? Some concrete examples could be helpful",aONAwGO-Oee
1584,"Otherwise, the paper is clear, coherent, and very well-written.",aONAwGO-Oee
1585,"My main concerns about this work lie in two main aspects: (1) the lack of comparison to traditional methods in IR, e.g., vector space, probabilistic and language models, and (2) insufficient evaluation.",aONAwGO-Oee
1586,Re (1): Why using a somewhat simplistic keyword match model as the baseline while there exist established and successful approaches to IR? I found the proposed methodology creative and potentially novel and would be curios about how it compares to other IR techniques.,aONAwGO-Oee
1587,"Re (2): Considering the two approaches presented in the paper, the evaluation (presented mainly in section 4.2.3) makes is difficult to draw any conclusions: figures 4-5 present highly expected results (“by the virtue of the ranking”); surprisingly little documents are in the overlap of the two approaches, which highlights the need in adequate evaluation; no actual comparison between the two approaches in conducted",aONAwGO-Oee
1588,"The authors could use, e.g., the TREC-COVID labeled dataset for evaluation.",aONAwGO-Oee
1589,"I thought that was an interesting and creative approach, and the paper was a very enjoyable read overall",aONAwGO-Oee
1590,"The two issues above, however, prevent me from recommending it for acceptance",aONAwGO-Oee
1591,With an adequate evaluation (and proven benefits of the suggested approach) this could be a very good work.,aONAwGO-Oee
1592,Section 4.1.1 could be shortened or omitted; topic model coherence seems a bit off-topic.,aONAwGO-Oee
1593,"Figure 2 could be clearer if presented in negative (i.e., light) colors.",aONAwGO-Oee
1594,Page 3: “pipeline pipeline” -> “pipeline”,aONAwGO-Oee
1595,Page 7: “include include” -> “include”,aONAwGO-Oee
1596,Page 4: why 35 was chosen for k?,aONAwGO-Oee
1597,"The study proposed to use NMF to extract hidden topics from the COVID-19 Open Research Dataset  for 17 tasks, which was used for information retrieval for each task",aONAwGO-Oee
1598, The method is quite standard and straight-forward,aONAwGO-Oee
1599,Strength of this paper is : i)it showed the effectiveness of NMF over keyword approach,aONAwGO-Oee
1600, ii) the examples given in section 5 are inspiring.,aONAwGO-Oee
1601,"However, there are some weaknesses: i) The keyword approach is rather a simple baseline, authors may consider other vector space models or language models for IR",aONAwGO-Oee
1602,"ii) For evaluation, the paper did some effort in assessing topics, it would be better to evaluate the IR results further",aONAwGO-Oee
1603,"e.g., do some extrinsic evaluation on down stream tasks and see if the retrieved results are really beneficial; iii) Not sure whether the two key word sets are good or not",aONAwGO-Oee
1604,"Especially in the second set, it returned some noisy words (e.g",aONAwGO-Oee
1605,best) using tfidf for key word selection.,aONAwGO-Oee
1606,"Some questions for authors: In algorithm 1, what is ψ exactly ? how did you do the dimension projection (reduction) ?",aONAwGO-Oee
1607,This paper anchors on interpretability of machine learning solutions in the context of hate speech detection around COVID-19 social media,OLoP-Q2Wu4o
1608,"This problem is extremely crucial to address, especially in the current times",OLoP-Q2Wu4o
1609,They leverage the global feature importance from a model’s training dataset to reinforce or penalize new predictions when their local feature importance varies from the learned global values,OLoP-Q2Wu4o
1610,The paper seems to be put in haste and lacks good presentation,OLoP-Q2Wu4o
1611,Contributions section doesn’t clearly highlight why the proposed method is impactful,OLoP-Q2Wu4o
1612,Results section feels incomplete due to lack of any rigorous evaluation,OLoP-Q2Wu4o
1613,They should consider adding more qualitative samples to drive the point home on both the approach and interpretability aspects,OLoP-Q2Wu4o
1614,The dataset collected in the context of COVID-19 (Section 3.2) deserve more analysis and isn’t described adequately,OLoP-Q2Wu4o
1615,"While leveraging “proven methods” is understandable, additional context would be helpful as to why other approaches were not considered or evaluated",OLoP-Q2Wu4o
1616,"Finally, I would suggest them to remove Figure 1",OLoP-Q2Wu4o
1617,and consider providing multiple anonymized examples to illustrate the problem they are trying to solve.,OLoP-Q2Wu4o
1618,In this work the authors present their approach for hate and toxic speech detection in the context of the COVID-19 pandemic,OLoP-Q2Wu4o
1619,"For a short paper, the authors frame their solution well and discuss some of the relevant approaches by other researchers",OLoP-Q2Wu4o
1620,"One of the major drawbacks here is that almost no mention of transformer solutions, which have been more popular and better performing in the last few years",OLoP-Q2Wu4o
1621,While the focus is put more on the contribution of using SHAP (SHapley Additive exPlanations) to focus on the importance of the features in the general context,OLoP-Q2Wu4o
1622,"The biggest issue with this paper comes with the lack of clear and concise experiments (baseline evaluations on the non-covid datasets), and a proper way of evaluating their methodology on the COVID-19 set, which of course has no gold-standard at the time",OLoP-Q2Wu4o
1623," While the opening of the paper is quite well crafted, the important evaluation and results section needs considerable work for the paper to be clear and fully self-standing",OLoP-Q2Wu4o
1624,Sharing tweets like on the screenshot shown as figure 1 is definitely not ok in terms of privacy issues and it would go against Twitter's terms and conditions as well,OLoP-Q2Wu4o
1625,A paraphrased summary of the tweet and removing the author would be the best way to share,OLoP-Q2Wu4o
1626,This paper proposes a method for detecting hate speech that supposedly improves performance and explainability.,OLoP-Q2Wu4o
1627,"While the direction here is important and interesting, I think the paper has several key details that are missing and need to be included before it would be ready for publication.",OLoP-Q2Wu4o
1628,"First, if there is a quantitative evaluation of whether their proposed method improves performance, it was not clear to me",OLoP-Q2Wu4o
1629,"For example, having a Table with performances of the baseline versus their method (with respect to some ground truth) could clearly show the improvement in performance",OLoP-Q2Wu4o
1630,Or plotting an ROC curve could be appropriate here,OLoP-Q2Wu4o
1631,The datasets that were used are not clearly or adequately described,OLoP-Q2Wu4o
1632,What is the ground truth and how were they annotated? What is the relationship between the training sets (which do not appear to be COVID-related) and the test set? Is there a data distribution mismatch due to the different topics?,OLoP-Q2Wu4o
1633,Is there a quantitative way to measure explainability? All I see is one qualitative example.,OLoP-Q2Wu4o
1634,"Additionally, it seems that the authors proposed method shifts examples towards the ""none"" class, but it is unclear how this correlates with better performance",OLoP-Q2Wu4o
1635,I think what the authors mean to show in Figure 4 is that there are fewer false negatives,OLoP-Q2Wu4o
1636,But was the number of false positives the same? ,OLoP-Q2Wu4o
1637,Authors should explain why they have chosen to use CNN instead of BERT as the text classifier.,OLoP-Q2Wu4o
1638,This paper is built on their previous work on a parallel architecture to perform named entity recognition and normalisation simultaneously,n2MepuKpsX6
1639,"They use a dictionary-based system in conjunction with two models based on BioBERT, whose outputs are combined as per the entity type",n2MepuKpsX6
1640,They also use a manually crafted dictionary optimized for the new COVID-19 concepts. ,n2MepuKpsX6
1641,The paper overall is written well: easily understandable and transparent,n2MepuKpsX6
1642,"Their willingness to share the code, outputs, BioBERT models and even the annotations is appreciable",n2MepuKpsX6
1643,"However, the paper lacks novelty, rigor and doesn’t attempt to compare against other baselines",n2MepuKpsX6
1644,They should definitely try to add additional baselines in the event that the paper is accepted,n2MepuKpsX6
1645,This study aimed to improve the CORD-19 dataset and provide documentation on how the public can access their pipeline,n2MepuKpsX6
1646,This study understated the problem and the methods used to improve the CORD-19 dataset do not appear novel,n2MepuKpsX6
1647," While this study provides an open source that may be useful to the public and scientists, its technical contributions were unclear",n2MepuKpsX6
1648,"The authors describe a pipeline for Named Entity Recognition and Normalisation on the Covid-19 literature, with the results being distributed to the public via various means - PubAnnotation, EuroPMC, their own BRAT webservice, and downloads in four formats",n2MepuKpsX6
1649,The code to run the pipeline and the trained models are also made available,n2MepuKpsX6
1650,The system continuously responds to updates in the LitCovid dataset,n2MepuKpsX6
1651,"Much of their work uses a system that has previously been evaluated in a shared task - however they also add a Covid-19 specific terminology, COVoc.",n2MepuKpsX6
1652,"Reasons to accept: This paper presents a useful resource to community, in a way that is ready for use",n2MepuKpsX6
1653,"Most of the methods used have been previously evaluated, so the quality is known",n2MepuKpsX6
1654,COVoc is also a potentially useful resource.,n2MepuKpsX6
1655,Reasons to reject: Lots of the paper is spent describing the technical details of the parts of the system that have already been published and evaluated - space that would be better used to describe the novel contributions,n2MepuKpsX6
1656,"For example the whole description of COVoc is ""Additionaly, we employ the manually curated, COVID-19 specific terminology COVoc, containing over 250 terms"" and a URL for obtaining COVoc - substantially more on COVoc would be welcome",n2MepuKpsX6
1657,"Given this imbalance, it is hard to tell how much original work is being presented in this paper",n2MepuKpsX6
1658,"Much of the system _has_ been evaluated as part of a shared task, but no other teams contributed to that facet of the shared task, making it hard to know how the system compares with the state of the art",n2MepuKpsX6
1659,"The authors state that the pipeline ""with some effort could be modified using OGER's format conversion to process other dataset such as CORD-19"" - CORD-19 is an important resource and having ready-to-go annotations for this would be very useful.",n2MepuKpsX6
1660,"Conclusion: Despite my misgivings about the level of novelty in this paper, I think the public annotations are potentially of use to the community, and having a citable publication associated with the annotations would expedite use of these annotations, in an area where time is of the essence.",n2MepuKpsX6
1661,The authors apply an existing transformer encoder architecture to what may be a new QA dataset for COVID-19.,gE_od-SGu4n
1662,- the authors collect(?) a potentially useful QA dataset.,gE_od-SGu4n
1663,- the work suffers from major disfluencies that make reading challenging,gE_od-SGu4n
1664,- I can't tell if the authors collected/aggregated new data beyond a wget or if they used an existing dataset,gE_od-SGu4n
1665,"If they collected a new dataset, it needs much deeper documentation in terms of both quantitative measures (number of questions, breakdown into categories, length of questions and answers, distribution of languages), as well as qualitative measures (high level gloss of what the questions and answers look like, sources of information)",gE_od-SGu4n
1666,The existing measurements only partially cover these and are somewhat unclear,gE_od-SGu4n
1667,- The JHU-COVID-QA model is underdescribed,gE_od-SGu4n
1668,It's not clear which of Poly-encoder and JHU-COVID-QA is the intended baseline.,gE_od-SGu4n
1669,- why ignore the non-English languages?,gE_od-SGu4n
1670,- do you attempt to group together identical or similar questions?,gE_od-SGu4n
1671,- Task and model descriptions do not belong together,gE_od-SGu4n
1672,The formulation of a task and a solution to the task are independent.,gE_od-SGu4n
1673,The paper collects questions and answers and verifies them using experts at JHU and Bloomberg,gE_od-SGu4n
1674,And then trains adapts a polyencoder for a QA task,gE_od-SGu4n
1675,The given focus of the paper is definitely topical.,gE_od-SGu4n
1676,QA tasks are a problem of verified standing in Natural Language Processing and definitely something to be looked at.,gE_od-SGu4n
1677,The paper uses multiple evaluation metrics to evaluate the task they are undertaking.,gE_od-SGu4n
1678,Work done for the QA has been made available,gE_od-SGu4n
1679,Working of the PolyEncoder has been explained in detail.,gE_od-SGu4n
1680,A lot of work described in this paper seems to be at a high level,gE_od-SGu4n
1681,For instance the answers were verified by professional at John Hopkins University or the Bloomberg School of Health,gE_od-SGu4n
1682,Were these answers purely medical or clinical? If not how was the verification done? What was used for fact checking?,gE_od-SGu4n
1683,The URL to the chat-bot given seems to only answer trivial questions,gE_od-SGu4n
1684,"For instance if a question is asked about what is the current situation in XYZ place, a response appears saying ""COVID 19 news is always changing you can find more information about COVID19 followed by a generic URL).",gE_od-SGu4n
1685,For QA datasets what were the annotation metrics? Was it binary (Trusted vs Not Trusted) or on a Likert scale (5 points) or different? What were the labels? How was the correlation between features of the dataset built?,gE_od-SGu4n
1686,"The paper talks about building a QA dataset, testing and evaluating the same using standard metrics available",gE_od-SGu4n
1687,"However, details such as how the scoring of Q-Q pairs were done needs more light",gE_od-SGu4n
1688,"""We scored each of the question-question pairs through the experts"" seems very high level for a paper which includes building the dataset as a major contribution",gE_od-SGu4n
1689,Further description and analysis of the results are also needed.,gE_od-SGu4n
1690,Overall the paper has talked of a task which has potential and needs to be revised and presented in a better and more organized way,gE_od-SGu4n
1691,"The sections need to be arranged properly with possibly elongated sections on annotation, and analysis of results",gE_od-SGu4n
1692,Finally the paper needs to be checked for erroneous grammar and writing inconsistencies,gE_od-SGu4n
1693,This paper presents a Question-Answer (QA) dataset for COVID-19 related questions and also a QA machine learning system using a poly-encoder approach,gE_od-SGu4n
1694,Unfortunately the paper is challenging to read due to many spelling and grammatical mistakes and I am not 100% confident that I understand the scope of the work discussed,gE_od-SGu4n
1695,I would strongly recommend an editing service or at least the use of an automated system such as Grammarly in the future.,gE_od-SGu4n
1696,The work seems to be building a QA system as part of a chatbot that is currently live on a website (https://covid-19-infobot.org/),gE_od-SGu4n
1697,"The ordering of the paper is challenging and it is unclear if the entire dataset construction, QA system and chatbot are within the scope of this paper, or the focus of this paper is only supposed to be the QA system",gE_od-SGu4n
1698,The paper briefly describes a dataset of question & answers constructed by JHU experts,gE_od-SGu4n
1699,"Then, earlier in the paper, it describes the poly-encoder architecture used for the QA system",gE_od-SGu4n
1700,"And the linked website, and Github page (https://github.com/sseol11/Parlai_ver2/tree/master/parlai/tasks/covid19) show that this is part of a chatbot, which is not clear in the paper.",gE_od-SGu4n
1701,The paper presents results of the Polyencoder system (with ParlAI) using this JHU COVID-QA dataset and the results seem reasonable,gE_od-SGu4n
1702,"Unfortunately due to the lack of clarity, I can’t really recommend this paper",gE_od-SGu4n
1703,"I would, however, like to commend the authors on making their code public and suggest significant restructuring to improve the paper.",gE_od-SGu4n
1704,"- At first, I was confused whether references to COVID QA referred to the COVID QA dataset presented at the previous NLP COVID workshop (https://github.com/deepset-ai/COVID-QA)",gE_od-SGu4n
1705,It’d be preferable to discuss this dataset with some sort of comparison too.,gE_od-SGu4n
1706,- The paper also proposes another dataset (Q-Q) based on question similarity,gE_od-SGu4n
1707,However little information is provided on the rationale for this,gE_od-SGu4n
1708,"What is the purpose of question similarity for this task? More details are needed for how the dataset is constructed, e.g",gE_od-SGu4n
1709,"interannotator agreement, what different scores from 0-100 are judged, etc.",gE_od-SGu4n
1710,- Unfortunately the description of the Polyencoder architecture is particularly difficult to follow,gE_od-SGu4n
1711,- The example dialogue on the Github page (https://github.com/sseol11/Parlai_ver2/tree/master/parlai/tasks/covid19) includes a question about wearing a mask,gE_od-SGu4n
1712,"The answer states to only wear a mask if you have symptoms, which is certainly against medical advice in the US as well as most other countries.",gE_od-SGu4n
1713,- Is the chatbot at https://covid-19-infobot.org/ using this approach?,gE_od-SGu4n
1714,- What does 20(ft) mean in the name of the model?,gE_od-SGu4n
1715,This paper proposes a methodology for curating a topic model from CORD-19 documents to improve downstream NLP tasks in this domain,6Huoz_DkT2
1716,"Authors argue about the importance of curated vs fully automatic models and outline a set of requirements that a high-quality topic model should have, in order to be useful for end-users",6Huoz_DkT2
1717,"The paper also provides some preliminary analysis on the current state of this endeavour, but details are still too superficial to evaluate if the quality of the curated topic model is indeed a significant factor for improving other downstream tasks like QA or IR.",6Huoz_DkT2
1718,"I consider this paper could spark an interesting discussion in the workshop given the inter-disciplinary nature of the work, and this type of discussion is very necessary if the biomedical NLP research community pretends to produce results that are usable in practical scenarios",6Huoz_DkT2
1719,My primary concern is that the results are still very initial to evaluate the feasibility of the proposal or estimate the value that this resource could provide,6Huoz_DkT2
1720,"The authors appear to have previous experience in this type of task, which is an argument in favour of their success",6Huoz_DkT2
1721,"However, I would have appreciated more details that could help quantify the expected returns of this effort.",6Huoz_DkT2
1722,**Reasons to accept:** A very interesting and important discussion that can potentially benefit the research community and a very good exposition of the necessity of this resource and its requirements.,6Huoz_DkT2
1723,**Reason to reject:** Preliminary results are too superficial to allow evaluating the feasibility ,6Huoz_DkT2
1724,This paper presents a description of ongoing work involving curated topic modeling for improved exploration of COVID-19 literature,6Huoz_DkT2
1725,"The idea is based on including humans in the loop, so that the initial topic model can be better fit to experts’ needs",6Huoz_DkT2
1726,"The authors reflect on a list of desiderata that would make the use of topic models more acceptable to medical practitioners, such as the use of readable labels and structured search",6Huoz_DkT2
1727,"Then, they discuss their ongoing efforts in this direction",6Huoz_DkT2
1728,The paper is clearly written and a pleasure to read,6Huoz_DkT2
1729,"I especially liked the discussion of the desiderata that would enable easier adoption by medical experts, and the description of the intended use where the topic labels would be used in a way similar to MeSH terms.",6Huoz_DkT2
1730,"The actual work in progress is presented in broad terms only (with a few technical details for the more trivial parts such as preprocessing), which is in my opinion the biggest shortcoming of the paper",6Huoz_DkT2
1731,"I am wondering, for example, how the model is precisely recomputed after the user has provided feedback (incorporation of label information, deletion of words, removal of topics etc.)",6Huoz_DkT2
1732,"And, how are the topic labels assigned? More generally, since the document collections are ever growing, how do the authors plan to adapt the topic models when the new data comes in?",6Huoz_DkT2
1733,"I would like to draw the attention of the authors to a related paper at this workshop, which also studies medical multi-word expressions in topic models: https://openreview.net/forum?id=c-TkXmZC-Yk (Improved Topic Representations of Medical Documents to Assist COVID-19 Literature Exploration)",6Huoz_DkT2
1734,The paper also contains other ideas about refining topic models for COVID-19.,6Huoz_DkT2
1735,"When introducing the last desideratum, the authors mention that special purpose category systems are needed for COVID-19, but the link to topic models was initially opaque to me",6Huoz_DkT2
1736,It  became clear only at the end of the section.,6Huoz_DkT2
1737,The acronyms DSM and RDoC may be unfamiliar to the reader.,6Huoz_DkT2
1738,"Overall: Although I would hesitate to accept the paper for its empirical contributions, I do think the paper could lead to interesting discussion at the workshop due to its contemplating nature about the inclusion of an NLP component into medical literature search.",6Huoz_DkT2
1739,"This paper presents preliminary work towards a topic model for use by Covid-19 researchers, being developed with a human-in-the-loop process",6Huoz_DkT2
1740,"It explains the needs of the subject matter experts (SMEs) who are to use the model, and how fully automatic topic models do not meet their needs",6Huoz_DkT2
1741,"They present the work they have done so far in constructing automatic topic models as a starting point, and describe their plans for the involvement of humans.",6Huoz_DkT2
1742,"Reasons to accept: Their analysis of the desiderata for topic models, and their anticipated uses, is extensive, highly compelling, in line with my own experiences of attempting to deploy topic models and similar systems, and likely to stimulate interesting discussions at the workshop",6Huoz_DkT2
1743,"The initial NLP work looks reasonable, although the details there are vague",6Huoz_DkT2
1744,The final resource is likely to be of value to NLP workers and SMEs alike.,6Huoz_DkT2
1745,Reasons to reject: Their description of the plans human involvement is frustratingly brief and vague; the most useful part seems to be a pair of references to other group's work in 2017 and 2018,6Huoz_DkT2
1746,I get the impression that plans have not been finalised,6Huoz_DkT2
1747,The vaugeness is also a problem with their descriptions of the NLP work already conducted - the descriptions are a long way from providing reproducibility,6Huoz_DkT2
1748,"Finally, the description of the specific challenges of working with Covid-19 research, rather than biomedical research in general, is minimal.",6Huoz_DkT2
1749,"Overall: This work is highly preliminary, and thus lacking in detail, and as such, in my opinion, publication of this work at this stage would be premature",6Huoz_DkT2
1750,"However, much depends on what the organisers aims for the workshop are; it would make for a stimulating presentation and lively discussion on the day, and if the organisers prioritise this above making a long-term contribution to the literature, then maybe it should be accepted.",6Huoz_DkT2
1751,The authors label a part of a covid-19 research literature dataset and train a ML pipeline for annotating covid-19 research,CWfGhEFOTKU
1752,"They apply the developed model, and with simple text analysis and qualitative interpretation they create an ontology of covid-19",CWfGhEFOTKU
1753,- The authors use a large group of humans (21) to annotate data,CWfGhEFOTKU
1754,- They follow a simple straightforward modeling process (shown in Fig.2) to label total corpus.,CWfGhEFOTKU
1755,"- The pipeline, although takes a small labeled dataset provides promising results (see Fig.4 covid-19 ontology)",CWfGhEFOTKU
1756,"- The paper is well-written, and provides in detail the scope of the pipeline, how they labeled the data, and how they performed model deployment and the evaluation of results.",CWfGhEFOTKU
1757,- The reported Precision-Recall is in some cases really low (e.g,CWfGhEFOTKU
1758,I suspect this is due to the relatively small training-dataset (500 sentences).,CWfGhEFOTKU
1759,"- The ME, and ML models are CRF and a logistic regression",CWfGhEFOTKU
1760,The authors did not try different model architectures and do not report the predictive ability of other baseline models (e.g,CWfGhEFOTKU
1761,naive bayes) in order to appreciate CRFs and logistic regression's performance.,CWfGhEFOTKU
1762,"- Because of pipeline's low performance, they have to perform a qualitative analysis to faciliate COVID-19 knowledge discovery",CWfGhEFOTKU
1763,Therefore I kindly encourage them to address (if possible) following issues:,CWfGhEFOTKU
1764,- provide the accuracy of other models in place of ME (CRF) and ML (LL) and report your accuracy,CWfGhEFOTKU
1765,- provide the predictive ability of standard models for annotating data in other cases in order to provide a measure for your models' accuracy,CWfGhEFOTKU
1766,(What is a general acceptable precision and recall for tagging e.g,CWfGhEFOTKU
1767,- Since considerable time has passed since the submission of the paper,CWfGhEFOTKU
1768,Have you improved the pipeline? Did you label more data until now?,CWfGhEFOTKU
1769,"- Since data are available in Kaggle, and many researchers have analyzed this data, are there other models by researchers that performed the same task? If yes, please compare your pipeline with theirs, in order to show why is yours is better.",CWfGhEFOTKU
1770,This paper is a study of a use-case on using an ontology of information extraction to create a knowledge graph around Covid-19 scientific literature.,CWfGhEFOTKU
1771,"It is hard to get information extraction ""right""",CWfGhEFOTKU
1772,"Those frameworks that allow for high performance (F1) are often too simplistic, and those that are too fine-grained do not obtain a performance level which is useful",CWfGhEFOTKU
1773,"This is a nice example of a middle-ground: a rather fine-grained extraction of relationships, with detailed performance analysis",CWfGhEFOTKU
1774,"While it remains low, the analysis shows how to tune recall vs precision.",CWfGhEFOTKU
1775, * a good example on how to leverage existing research frameworks (in inf extraction in this case) for a new use-case,CWfGhEFOTKU
1776, * an annotated dataset which can be helpful for future research,CWfGhEFOTKU
1777,QUESTION: will this dataset be released? (I found the *.ann files on your github: are those all the annotations?),CWfGhEFOTKU
1778," * a complete study: annotations, algorithm, performance analysis, first results",CWfGhEFOTKU
1779, * The final outcome is obtained by gluing a number of parts together,CWfGhEFOTKU
1780,"While this is very pragmatic, it raises a number of questions (see below)",CWfGhEFOTKU
1781,"This is, if the end goal is to obtain a general graph, then a from-scratch approach might look different from what is proposed",CWfGhEFOTKU
1782,"Of course, a from-scratch approach is not what this workshop is looking for",CWfGhEFOTKU
1783, * the ML algorithms used are probably the weakest part of this proposal,CWfGhEFOTKU
1784,"The weight these days is to justify non-neural methods, and no ablation study of the features used is mentioned",CWfGhEFOTKU
1785,"The current pipeline approach consists in (i) extracting entities, (ii) extracting relations, (iii) constructing the knowledge graph",CWfGhEFOTKU
1786,"Many things could slip through the cracks between all those steps, but the magnitude of this is unknown, and despite the existence of joint extraction models they are not mentioned.",CWfGhEFOTKU
1787,"        * Is the annotation of relations done wrt the original gold annotations, or with respect to the result of the entity-extraction step?",CWfGhEFOTKU
1788,	* “selected by the authors from the CORD-19 corpus”,CWfGhEFOTKU
1789,What does this mean? Did you interact with the authors of that corpus?,CWfGhEFOTKU
1790,"	* What are the output classes of M_R? Are those all 10 relations of Table 2 + None? Following your pipeline approach, did you try with first predicting if there is a relation, and then which relation it is?",CWfGhEFOTKU
1791,	* The BILOUV encoding is redundant I believe,CWfGhEFOTKU
1792,Wouldn't you obtain better performance by predicting a simpler encoding?,CWfGhEFOTKU
1793,	* Fig 3 shows that the threshold obtaining the best trade-off is different for each entity type,CWfGhEFOTKU
1794,"This might indicate that independent sequence prediction models could obtain better performance, in particular as a conflict in the extraction of entities (eg, one span annotated as Concept and also as Action) is not really an issue for your final goal of displaying a graph of knowledge.",CWfGhEFOTKU
1795,"	* How does the number of supporting documents enter in your knowledge graph? This is, how do you combine the confidence of a prediction of your model, with the number of times that prediction was made (eg, <lymphopenia, indicator, Covid-19>  predicted only once with high confidence vs predicted often with medium confidence)",CWfGhEFOTKU
1796,"	* Instead of Fig 3, a prec-recall curve (or better, a prec-recall-gain curve [1]) might be more indicative of the efficiency of your ",CWfGhEFOTKU
1797,"[1] Flach, Peter, and Meelis Kull",CWfGhEFOTKU
1798,"""Precision-recall-gain curves: PR analysis done right."" Advances in neural information processing systems",CWfGhEFOTKU
1799,"This paper presents an approach to ""knowledge discovery"" on the Covid-19 literature, based on previous work in the more general biomedical domain",CWfGhEFOTKU
1800,"Its main contribution is a collection of annotated sentences, annotated by volunteers recruited via social media, for use as test and training data, complete with inter-annotator agreement scores",CWfGhEFOTKU
1801,"It also includes a baseline system trained on the annotated sentences, an analysis of the corpus, and the source code and data are available online.",CWfGhEFOTKU
1802,"The paper builds upon a body of work using the SAT+R (Subject-Action-Target plus Relations) formalism, a general purpose semantic model that has been applied to the biomedical domain, including its deployment as a standard in shared tasks.",CWfGhEFOTKU
1803,Reasons to accept: This seems like a reasonably competent application of an existing research programme to Covid-19,CWfGhEFOTKU
1804,It is always good to see datasets and evaluation resources,CWfGhEFOTKU
1805,"Their crowdsourced annotation is interesting - but the success may be dependent on extra goodwill being available in the time of Covid-19, so it's not clear how it will transfer.",CWfGhEFOTKU
1806,Reasons to reject: The value of SAT+R annotations is unclear to me,CWfGhEFOTKU
1807,"The inter-annotator F scores they have achieved are not great (.64 for entities and .49 for relations, with some relations having agreement as low as .08) - this may reflect the intrinsic subjectivity of the task, or a lack of developement of guidelines, or may be a result of their crowdsourced annotation approach",CWfGhEFOTKU
1808,"The F scores for their baseline system are very low - 0.58 - 0.00 for entities and 0.40 - 0.01 for relations - this is not a viable baseline, and is purely of value for comparisons",CWfGhEFOTKU
1809,"The authors do state that ""Previous attempts to apply this annotation model to medical text show that it is possible to obtain near-human-level accuracy with as little as 600 training examples"", but even if F scores comparable to the inter-annotator level are possible, those scores are not especially high",CWfGhEFOTKU
1810,"Given that the application for these Subjects, Actions, Targets and Relations is to build graphs, the probability of errors in even a small graph becomes very high",CWfGhEFOTKU
1811,"It may be that these efforts are part of a long-term research program which will reach the appropriate levels of accuracy by incremental progress in the fullness of time - if so, I question its application to the Covid-19 domain, where applications ready for use by biomedical researchers etc",CWfGhEFOTKU
1812,"Conclusion: The work looks like a competent extension of an already-existing research programme to the Covid-19 domain, and the evaluation resources it has produced may be of use to the knowledge discovery subcommunity",CWfGhEFOTKU
1813,I am not at all familiar with these kinds of knowledge discovery approaches so I find it hard to gauge the importance of the research or its likelihood of producing outcomes of value to biomedical researchers - especially of value to Covid-19 researchers in a timely enough manner,CWfGhEFOTKU
1814,"However, given that other people see fit to publish this kind of work, I very tentatively recommend publication",CWfGhEFOTKU
1815,This paper considers the hypothesis that the impact of COVID-19 in public mental health (specifically in individuals with mental health issues) can be measured by analyzing the users' behaviour in online forums related to mental health,4LIJshtHlnk
1816,"Specifically, the authors focus on 3 mental-health-related forums in the Reddit social network, measuring the increase or decrease in both the user activities as well as in the relative prevalence of certain keywords of interest",4LIJshtHlnk
1817,Authors apply time series analysis to evidence a significant difference in user's activity post-COVID with respect to the behaviour predicted by autoregressive models,4LIJshtHlnk
1818,"Furthermore, they analyze the relative change of word usage in certain categories, using LIWC clusters and an LDA topic model",4LIJshtHlnk
1819,"The main findings indicate that these forums indeed exhibit abnormal behaviour, i.e., it does show an increased activity in these forums that coincides in time and textual content with the COVID-19 pandemic",4LIJshtHlnk
1820,"However, two of the three forums analyzed actually exhibit a decrease in user activity, an issue which is noted by the authors but there is no attempt to explain it",4LIJshtHlnk
1821,"I also consider that the techniques and analysis applied are an initial approximation, but they lack the sophistication expected in a top-level NLP venue",4LIJshtHlnk
1822,"Specifically, the paper relies on descriptive statistics (word counting of LIWC clusters) and topic modelling techniques (LDA) which fail to account for complex linguistic phenomena that may be acting as confounding factors",4LIJshtHlnk
1823,Is my understanding that the fact that certain keywords show an increased prevalence does not necessarily imply that users are actually feeling an increased mental-health burden,4LIJshtHlnk
1824,Reaching this conclusion would require a deeper semantic analysis of the text.,4LIJshtHlnk
1825,"As such, I believe the paper establishes a clear and important hypothesis, provides initial evidence for it, and it is clearly written, but the contributions are not sufficient to demonstrate an actual increase in mental health issues in users of these platforms as opposed to an increase in the general discussion of topics related to the COVID-19 pandemic",4LIJshtHlnk
1826,I commend the authors for their efforts in this clearly important endeavour and I suggest they continue strengthening this analysis.,4LIJshtHlnk
1827,"**Reasons to accept:** The paper is clearly written, the methodology is thoroughly explained and carried out and the problem under discussion is relevant to the workshop.",4LIJshtHlnk
1828,"**Reasons to reject:** I believe the paper does not advance our understanding of the scientific problem under study, that is, the impact of COVID-19 in public mental health, as it does not provide any new insight or result in this matter.",4LIJshtHlnk
1829,This paper describes the analysis of messages published on Reddit under a set of specific subforums related with mental health topics,4LIJshtHlnk
1830,The authors have performed several analysis to understand the levels of preoccupation of the population on these forums with respect to the pandemia and how the people that use these forums rise,4LIJshtHlnk
1831,On the other hand a second analysis about the language and topics of discussion has been performed,4LIJshtHlnk
1832,The topic addressed is interesting and the technical background is solid,4LIJshtHlnk
1833,My main concern is refered to several points where some conclusions were arisen by the authors with respect the implications of the results obtained,4LIJshtHlnk
1834,"Since the authors didn't present any analysis of the contextualization of the topics or, for example, some sentiment analysis performed over the texts some of these conclusions can be false",4LIJshtHlnk
1835,"In this context, I recommend to check the paper and consider rewriting some of these parts.",4LIJshtHlnk
1836,"Paper has room for improvement, but makes clear additions to the field.",4LIJshtHlnk
1837,"Comparison between anxiety, depression, suicide is very relevant",4LIJshtHlnk
1838,Use of LIWC to supplement topic-modeling was a good decision,4LIJshtHlnk
1839,Traditional **Discussion** section is intermixed with the section 5: **Findings**,4LIJshtHlnk
1840,"An embedded topic model (Dieng, Ruiz, and Blei 2019) offers benefits over LDA ",4LIJshtHlnk
1841,Discussion of LIWC and depression/anxiety prediction for NLP is not particularly thorough,4LIJshtHlnk
1842,The authors examine how the content of three subreddits related to mental-health help seeking changes as a result of the COVID-19 pandemic,4LIJshtHlnk
1843,"To do so, they combine established methods for topic analysis (LDA) and psychological assessment of text (LIWC) with a time-series prediction approach (Prophet)",4LIJshtHlnk
1844,"Their analysis contributes to the field and their approach is satisfactorily documented and executed; however, the authors could improve their work with better organization and use of more current methods.",4LIJshtHlnk
1845,The authors comparison of anxiety and depression is an important contribution,4LIJshtHlnk
1846,USC's Understanding America Survey COVID-19 is doing this as well,4LIJshtHlnk
1847,Useful to show that NLP can be used to the same end,4LIJshtHlnk
1848,"The authors longitudinal analysis of established NLP techniques, LIWC and LDA, usefully allows them to identify topic-changes across the various subreddits.",4LIJshtHlnk
1849,The paper could be made more accessible through a more typical distinction between analysis and discussion,4LIJshtHlnk
1850,"As it is written, the authors analysis and discuss implications simultaneously--leading to temporary uncertainty over what is an evidence-backed finding and what is author speculation.",4LIJshtHlnk
1851,"The authors could also update their methodological choices, e.g., using [Embedding Topic Modeling](https://arxiv.org/pdf/1907.04907.pdf)(Dieng, Ruiz, and Blei 2019) in place of LDA",4LIJshtHlnk
1852,"fastText embeddings would be a natural choice for this, as the authors have already cited Wolohan, 2020.",4LIJshtHlnk
1853,"Lastly, the authors could also discuss more thoroughly the history of LIWC and word-count approaches in NLP for depression / mental health detection",4LIJshtHlnk
1854,(2004) is cited but only as a possible explanation for a finding,4LIJshtHlnk
1855,That paper is a significant forebearer to this work.,4LIJshtHlnk
1856,"This paper is highly reproducible, though associated code or Reddit post-IDs would help.",4LIJshtHlnk
1857,"The study converted the covid19 suggestion seek/give problem into a social media text classification task, the data is from Reddit and the experiments showed some average weekly emotional support sought/given changes",Fgwxi8nXVlC
1858,"I found the topic is interesting, but the presentation needs to be improved",Fgwxi8nXVlC
1859,"it would be better if the authors can give more statistics of the collected dateset, show the  agreement level of the annotators, given some reasons of the feature selection,  illustrate basic parameter settings for the model Random Forest (e.g",Fgwxi8nXVlC
1860,"how many trees and splits are there), and give the model performance level",Fgwxi8nXVlC
1861,"In general , I think the work can still be improved",Fgwxi8nXVlC
1862,This paper addresses the topic of COVID-19 online support forums with the purpose of automatically classifying posts that either seek or receive emotional or informational support,Fgwxi8nXVlC
1863,"While the topic of the paper is of interest for this workshop's audience, the paper could be improved both in terms of presentation of the methodology and results (as well as their discussion).",Fgwxi8nXVlC
1864,The authors exclude comments to the original posts during the collection of the dataset,Fgwxi8nXVlC
1865,"I did not understand this decision, could the authors detail their reasoning? Aren't comments more prone to hold some kind of support utterance? If one user asks for a specific information I would expect that the comments associated to the original question to contain some kind of informational support",Fgwxi8nXVlC
1866,Section 3.1 should be discussed in more detail,Fgwxi8nXVlC
1867,"I understand this is a short paper, however in the current form it wouldn't be possible to reproduce the work done by the authors",Fgwxi8nXVlC
1868,Which LIWC categories were considered reevant to emotional and informational support? How were the posts involving request or advice identified? What were the 20 topics generated using LDA? The results in Table 2 deserve a more thorough discussion,Fgwxi8nXVlC
1869,Interesting paper and with addressing the comments below this could be a candidate for this workshop.,Fgwxi8nXVlC
1870,- line: 46: define social support ,Fgwxi8nXVlC
1871,- line 100: provide full details (of how the support types are distributed across your sample) in addition to the two examples,Fgwxi8nXVlC
1872,- related: consider adding examples for each type being low/high.,Fgwxi8nXVlC
1873,- line 155: great to see proper agreement evaluations!,Fgwxi8nXVlC
1874,- line 195: I'd really like to see comparisons with other models (e.g,Fgwxi8nXVlC
1875,"SVM, simple linear regr., LASSO, etc.) - also: please add detail on the model used (did you treat the Likert scores as ""classes"" or predict continuous values?)",Fgwxi8nXVlC
1876,- line 200: the x-axis of the plot could do with refinement (e.g,Fgwxi8nXVlC
1877,"- line 227: the problem (predicting Likert-scale scores) can be formulated as a regression problem, so in addition to the r reported, I'd like to see regression performance metrics (at least: R-squared, RMSE and MAE)",Fgwxi8nXVlC
1878,- Fig 1: please assess statistically whether the lines in the plot are different - right now the interpretation relies on eye-balling.,Fgwxi8nXVlC
1879,- line 287-386 (Discussion section): you are now not talking about the prediction any more but focus on the findings derived from the plots,Fgwxi8nXVlC
1880,Please add a discussion of the prediction analysis and provide more rigorous testing of the plots.,Fgwxi8nXVlC
1881,- a key (and very interesting) finding is that the rate of support given/received is divergent for emotional and informational support - this merits more attention and I'd like to see more details on this (e.g,Fgwxi8nXVlC
1882,is it driven by specific posts /outliers; what is a possible explanation for that divergence).,Fgwxi8nXVlC
1883,Lastly: the interpretation of the RF findingfs (Table 2) deserve some review: r=0.40 means that the model merely explains 16% of the variance in the outcome variable (here: degree of support) - since R-squared = 0.16,Fgwxi8nXVlC
1884,This is not a lot so there will be many other factors aside from features used - I'd like to see this discussed in the paper.,Fgwxi8nXVlC
1885,The paper describes a COVID-19 QA system,R2Vm-G0ios
1886,It uses BM25 for the IR component and BERT models for the QA component,R2Vm-G0ios
1887,It provides both quantitative evaluations on the COVID-QA dataset and in-depth manual error analysis,R2Vm-G0ios
1888,The manuscript is well-written and the structure is clear,R2Vm-G0ios
1889,It would be more robust to provide the performance of baseline systems and other systems on the COVID-QA dataset,R2Vm-G0ios
1890,This will make it clear on whether the proposed system is indeed effective.,R2Vm-G0ios
1891,The manual analysis part is interesting,R2Vm-G0ios
1892,More details are expected: any suggested changes on the evaluation metrics? What are the recommendations from the study? This is critical for QA systems in production,R2Vm-G0ios
1893,"In this work the authors introduce their QA system that won one of the tasks in the round one of the Kaggle CORD-19 Challenge, and also make the case of the suitability of automatic metrics",R2Vm-G0ios
1894,"With an ambitious scope, the authors very effectively frame the problem and their QA system in contrast to others in the same competition",R2Vm-G0ios
1895,"The description of their system is quite clear and succinct, making this a very easy and intuitive read",R2Vm-G0ios
1896,"seems a loose and needs more refinement, as for example Table 1 just cherry-picks some other systems IR module to compare against (the top 5? what number was each? it just picks 3 out of 50 randomly)",R2Vm-G0ios
1897,"The evaluation of the QA system in section 4.2 is quite interesting and while brief, it shows the results are unintuitive and lead to the interesting idea of the suitability of automatic metrics after they performed a manual review",R2Vm-G0ios
1898,"This manual review is a good idea but it is lacking in depth and detail to be fully stand-alone, more discussion would be nice to have",R2Vm-G0ios
1899,"Overall, the paper proposes an interesting system and poses a very interesting question with regards the typical evaluation procedures for such systems, while it needs a bit of work and tidying up, it is a nice contribution",R2Vm-G0ios
1900,The paper presents a question answering system that won one of the tasks in the round one of the Kaggle CORD-19 Challenge,R2Vm-G0ios
1901,The authors describe the two system components – IR (retrieving the most relevant paragraph given a question in natural language) and QA (extracting the answer from the paragraph),R2Vm-G0ios
1902,"The paper further analyses a surprisingly low performance introduced by the system when fine-tuned on SQuAD and QuAC on an annotated dataset, revealing that the inherent preference of short answers by evaluation systems causes the inspected drop in accuracy.",R2Vm-G0ios
1903,"The paper is interesting, insightful, mostly clear and very well-written.",R2Vm-G0ios
1904,The main contribution of this work is summarized in section 4.2 – the analysis of automatic evaluation of QA systems w.r.t,R2Vm-G0ios
1905,"long answers, reflecting essentially the same information",R2Vm-G0ios
1906,"My main concern is that the conclusions are drawn based on 50 or so annotations done by a single annotator, who may well have preferences re short vs",R2Vm-G0ios
1907,long answers for what essentially are factoid questions,R2Vm-G0ios
1908,"That is, the “user preferences” as stated in the title are somewhat misleading",R2Vm-G0ios
1909,"Which leads me to my second concern – the two examples in figure 1 (“how many” and “when” questions) call for a short fact-based answer IMO, or, at least should rank a short and precise fact providing an exact answer to a query not inferior to a long paragraph including the answer plus some bits of potentially unnecessary information",R2Vm-G0ios
1910,Can the entire drop in EM and F1 in the last row in table 2 be attributed to the analysis in section 4.2? Are there any other potential factors that could affect the QA accuracy?,R2Vm-G0ios
1911,"I appreciate the authors’ analysis in figure 2, interesting!",R2Vm-G0ios
1912,"All in all, I think that’s a good work",R2Vm-G0ios
1913,"The fact that the proposed system (when fine-tuned on SquAD only, third row in table 2) outperforms ROBERTA-based solutions highlights the contribution of this work, which is sufficient to recommend for acceptance IMO, despite the two issues above.",R2Vm-G0ios
1914,The paper presents a QA engine that takes COVID-19 related questions and outputs a span-based answer in a piece of text belonging to the relevant article,DjTY4WKHy-K
1915,Article selection is based on finding out which textual chunks from the article is maximally similar to the question (using Sentence-BERT),DjTY4WKHy-K
1916,"When a set of articles relevant to the question is obtained, a general-domain BERT QA module outputs the span of text corresponding to the answer",DjTY4WKHy-K
1917,"The authors test these components as they are, without re-training or adaptation.",DjTY4WKHy-K
1918,"The pipeline separating retrieval and answer selection in general makes a lot of sense, and is clearly presented in the paper",DjTY4WKHy-K
1919,"Also, the authors consider a variety of COVID-19-related questions (from two different sources), and document them well in the appendix.",DjTY4WKHy-K
1920,I see a number of methodological shortcomings that in my opinion make the publication of the article in the current state premature,DjTY4WKHy-K
1921,I discuss those in the order as encountered while reading the paper.,DjTY4WKHy-K
1922,I would be curious to see some statistics about how often the model selects the answer from a chunk (QA step) that was not previously selected (retrieval step) as the maximum scoring one.,DjTY4WKHy-K
1923,The similarity calculation gives preference to locally maximally similar snippets of text with respect to the query,DjTY4WKHy-K
1924,"However, the importance of that snippet in the article has no weight by itself, so no indication of how central it is to that article",DjTY4WKHy-K
1925,"As an alternative, instead of just looking at the snippet maximising the cosine similarity, looking at the distribution of similarities could work better, e.g",DjTY4WKHy-K
1926,when there are multiple snippets answering the query.,DjTY4WKHy-K
1927,"The authors mention that they carried out an empirical evaluation to single out DistilBERT as the best architecture, but do not mention how this evaluation (albeit “only” qualitative) was carried out",DjTY4WKHy-K
1928,The same criticism applies to selecting the QA model,DjTY4WKHy-K
1929,"Because of this, there is little to learn from the paper---the comparison of model components was done only at face value.",DjTY4WKHy-K
1930,"Similarly, the answer evaluation has methodological issues, e.g",DjTY4WKHy-K
1931,"no mention of how many annotators graded the quality of answers, what was their agreement, how many answers were verified, and when the topic is deemed equivalent between the answer text and the question",DjTY4WKHy-K
1932,Some examples could be provided for each answer score.,DjTY4WKHy-K
1933,The authors go on to claim that “a substantial improvement to RECORD’s performances is brought by the analysis of the whole body of the articles”,DjTY4WKHy-K
1934,"But I’m wondering—improvement over what, and how was it measured? If the proposed tool can provide at least one precise answer ~60% of time, is this good or bad, and why? Further, more analysis could be done to show from which chunks (location in the text) the answers come from.",DjTY4WKHy-K
1935,"Finally, there is a lot of work involving QA for COVID-19, but the paper fails to address any of this work",DjTY4WKHy-K
1936,See this as a starting point: https://openreview.net/pdf?id=0gLzHrE_t3z.,DjTY4WKHy-K
1937,"This paper describes a QA tool for COVID-19 built on top of two components, a Sentence-BERT model for filtering papers by relevance, and a BERT-based QA model tuned on SQuAD",DjTY4WKHy-K
1938,"The authors test their model on two sets of questions, one created by the authors, and another set contributed by a regional healthcare facility, asking for human evaluators to score model results on a 4-point scale",DjTY4WKHy-K
1939,"The list of questions provided in Tables 1-4 are a good contribution, though the paper is lacking in implementation and experimental details.",DjTY4WKHy-K
1940,"The paper lacks experimental results, though the authors repeatedly refer to empirical comparisons",DjTY4WKHy-K
1941,"For the filtering step, the authors use Sentence-BERT on chunked papers, but do not compare to other baseline retrieval models, such as Anserini, CovidBERT, BioBERT, SciBERT etc, all of which the authors mention",DjTY4WKHy-K
1942,"The authors say Sentence-BERT was empirically better, but there are no results to support this",DjTY4WKHy-K
1943,"How much better? Similarly for QA, there are no numerical results showing that one model is better than another, just a statement that comparisons were performed",DjTY4WKHy-K
1944,All modeling decisions therefore seem incredibly arbitrary.,DjTY4WKHy-K
1945,There is also no way to understand how well the model performed,DjTY4WKHy-K
1946,"The authors report evaluation results, but are these numbers reasonable? Are the methods reported here comparable to what would be expected in a general domain setting for example? Or the COVID-19 domain? There are datasets on COVID QA (Tang et al 2020) that could be evaluated on to give a sense of the performance of this model.",DjTY4WKHy-K
1947,This paper builds a question-answering model which answers questions from the recently available CORD-19 dataset,DjTY4WKHy-K
1948,"While the work promised potential, major steps are missing in both experimentation and writing",DjTY4WKHy-K
1949,In the pre-processing step of the paper the authors mention they use a list of keywords identifying the COVID-19 virus,DjTY4WKHy-K
1950,"However, this list of keywords needs to be released or revealed to facilitate repeatability and better understanding of the pre-processing step.",DjTY4WKHy-K
1951,Similarly - the authors mention using k number of tokens less then 128 owing to the maximum capacity of the Sentence-BERT network,DjTY4WKHy-K
1952,"However, there is confusion in the above step",DjTY4WKHy-K
1953,"The authors mention that they choose a k-value slightly less than 128, however, in the same paragraph they also mention that they choose a k-value sufficiently smaller than 128",DjTY4WKHy-K
1954,"For repeatability purposes and for better understanding, revealing this number is required.",DjTY4WKHy-K
1955,The literature review section of the paper lacks specific numbers,DjTY4WKHy-K
1956,This is a rather crucial detail which is lacking,DjTY4WKHy-K
1957,"Since the primary contribution of the paper is an artificially intelligent question answering model which works on existing datasets, it is important to know exactly where this model stands in regards to a performance benchmark against current networks",DjTY4WKHy-K
1958,"It has been mentioned by the authors that owing to a lack of time and resources an empirical evaluation has been provided instead of a quantitative one, it does not show how the model in the paper stands up to existing work.",DjTY4WKHy-K
1959,"Section 2.3 mentions RECORD (the model proposed) extracts additional metadata such as title, authors, and so on to highlight reliability",DjTY4WKHy-K
1960,"Is this so that the person asking the questions knows that the answers are from a published source? Shouldn't that information already be clear owing to the dataset the model was trained upon? If that is not the case, then how does the additional data provide reliability? This needs to be specified in detail.",DjTY4WKHy-K
1961,In Section 4.1 - the authors mention that humans were asked to annotate a score for each provided answer,DjTY4WKHy-K
1962,"How were the annotators selected? Were they annotators familiar with the model or the dataset or current literature and a ground truth? Was there any inter-annotator agreement between scores on a particular answer? If so, what was that score? Or did one annotator score only one answer?",DjTY4WKHy-K
1963,"While the questions are detailed, it is suggested that the authors provide some of the sample answers from each of the classes",DjTY4WKHy-K
1964,Maybe a table showing a few questions with answers spanning scores 0-3 would be a very useful addition to this work.,DjTY4WKHy-K
1965,All the questions and all tasks are very well organized and detailed in appendix A.,DjTY4WKHy-K
1966,The bar charts and graphs provided are clear to understand and shows the claimed performance benchmark.,DjTY4WKHy-K
1967,The work is topical and promising,DjTY4WKHy-K
1968,There is a lot of scope to improve and contribute to future venues.,DjTY4WKHy-K
1969,"In conclusion, although the work described in the paper promises to be full of potential, the paper lacks a lot of crucial details",DjTY4WKHy-K
1970,The paper has very well presented supplementary material,DjTY4WKHy-K
1971,All questions and tasks they are listed under are extremely important,DjTY4WKHy-K
1972,The performance of 61.3% needs to be evaluated against other pre-existing benchmarks,DjTY4WKHy-K
1973,"The paper introduces a large-scale dataset with posts related to COVID-19 collected from Weibo, a social media in China",TrAt6uxl6vJ
1974,It describes in detail the process to collect the dataset and provides some interesting analysis of the dataset,TrAt6uxl6vJ
1975,* The dataset  is large and contains rich information such as location and post time,TrAt6uxl6vJ
1976,This could be helpful for further COVID-related researches,TrAt6uxl6vJ
1977,* This paper provides interesting analysis about the dataset such as the daily distribution of COVID-related posts and word clouds at different phases,TrAt6uxl6vJ
1978,* There are no deduplication steps to deduplicate tweets in the dataset,TrAt6uxl6vJ
1979,"The keyword-based collection could result in many duplicated tweets, for example, the same announcements from the government reported by lots of different news accounts, and popular tweets retweeted by other accounts",TrAt6uxl6vJ
1980,The duplicated tweets could bias the statistics of the dataset and further studies,TrAt6uxl6vJ
1981,"* While the main contribution of this paper is a large-scale dataset, there is no direct evaluation of its quality",TrAt6uxl6vJ
1982,It is unknown how many tweets in this dataset are directly related to COVID-19,TrAt6uxl6vJ
1983,person and location) could potentially pick up non-COVID-related posts (e.g,TrAt6uxl6vJ
1984,"searching ""Li Wenliang"" could pick up tweets that falsely accused him of spreading rumors or tweets that described his profile)",TrAt6uxl6vJ
1985," Another example is that a portion of words from Fig.4c and Fig.4d are not directly related to COVID-19, such as ""汇算 清缴""(settlement and payment), ""梵高 画作""(paintings of Vincent Van Goph) and ”后街男孩“(Backstreet Boys)",TrAt6uxl6vJ
1986," The precision of this keyword-based approach to collect COVID-related tweets remains unknown, which makes the dataset less useful to the community",TrAt6uxl6vJ
1987,* Some Chinese keywords do not correctly match their translation in English in the appendix table ,TrAt6uxl6vJ
1988," For example, ""美国 AND 例"" should be translated to ""USA AND cases "" instead of ""USA COV-19 AND cases""",TrAt6uxl6vJ
1989,"This is a short paper providing an overview of the collection of tweets posted on a popular Chinese social media platform called Weibo from December 1, 2019 to April 30, 2020",TrAt6uxl6vJ
1990,"The authors first create a pool of active users by filtering them based on their activity and the number of tweets, followers, and fans",TrAt6uxl6vJ
1991,They then compile a collection of tweets from these users using 179 manually pre-defined keywords.,TrAt6uxl6vJ
1992,- Why was the data collected only until the end of April? The authors claim that the pool of active users is dynamically maintained and if so it would be better to provide both the users and the readers with a more recent version of the dataset,TrAt6uxl6vJ
1993,"- In what languages are the tweets collected in Weibo-COV? I assume the majority is in Chinese, this should be stated explicitly somewhere at the beginning of the paper",TrAt6uxl6vJ
1994,- What does crawling time mean in this context? Please either specify in Table 1 or add the definition to the main text,TrAt6uxl6vJ
1995,"- Not sure what is meant by “Cirque du Soleil in Canada” in section 3.5, please review.",TrAt6uxl6vJ
1996,- Typos and grammar mistakes occur throughout the text (e.g,TrAt6uxl6vJ
1997,It would be nice to correct those to improve the readability of the paper,TrAt6uxl6vJ
1998,"This paper describes a dataset for COVID-19 built from Weibo, a Chinese social media platform",TrAt6uxl6vJ
1999,"The authors first maintain a Weibo active user pool -- around 20 million active users, and then collect their tweets using a list of specified keywords relating to COVID-19 (179 in total).",TrAt6uxl6vJ
2000,"- A large scale dataset, containing tweet content, interactive, location and retweet information",TrAt6uxl6vJ
2001,Not only text-based but also social network-based analysis can be potentially conducted on the dataset.,TrAt6uxl6vJ
2002,- The authors describe in detail how they build the dataset,TrAt6uxl6vJ
2003,- I am not sure whether collecting only active user's tweets makes sense,TrAt6uxl6vJ
2004,It is possible that some users create and start to post tweets because of (after) the pandemic,TrAt6uxl6vJ
2005,It may be worth analysing those users as well.,TrAt6uxl6vJ
2006,- Are these keywords manually choosen or decided based on their popularity? Also it looks to me some keywords are repeated,TrAt6uxl6vJ
2007,"For example, is the result filtered using keyword 'Doctor AND Li Wenliang' a strict subset of result using keyword 'Li Wenliang'?",TrAt6uxl6vJ
2008,"- The title of (Chen et al, 2020) paper has been updated to 'Tracking Social Media Discourse About the COVID-19 Pandemic: Development of a Public Coronavirus Twitter Data Set'",TrAt6uxl6vJ
2009,The authors develop a large dateset of 86 misconceptions along with 5000 annotated tweet-misconception pairs from COVID-19 related tweets that were generated in March and April of 2020,FCna-s-ZaIE
2010,"All tweets were manually labeled by researchers from the UCI School of Medicine as: 1) having a positive expression of the misconception, 2) contradicting/disagreeing with the misconception or 3) being neutral or not relevant to the misconception",FCna-s-ZaIE
2011,The researchers then evaluate the performance of the existing NLP systems on the dataset.,FCna-s-ZaIE
2012,"While the authors provide a good framework for developing and testing misinformation in social media, given the rapidly evolving/changing evidence base related to COVID-19, strong consideration should further be given to developing more automated systems for classifying social media content (e.g",FCna-s-ZaIE
2013,"bench-marking them against the content on the reputable websites, such as CDC, WHO or PHAC, rather than relying on human annotators to maintain the misconception databases current)",FCna-s-ZaIE
2014,"In the meantime, COVID-Lies provides a great starting point for the development of robust misinformation detection systems and their evaluation",FCna-s-ZaIE
2015,The authors generate a dataset containing 5000 related to 86 covid-19 misconceptions,FCna-s-ZaIE
2016,They also deploy a two-step process for classifying tweets,FCna-s-ZaIE
2017,"At the first step, they deploy a semantic model that tries to define the similarity of a tweet to one of the 86 misconceptions",FCna-s-ZaIE
2018,"Then, they perform stance detection to investigate if the tweet agrees to the specific misconception or not",FCna-s-ZaIE
2019,They use different models and techniques coming from NLI to investigate the abilities of models in misinformatio detection,FCna-s-ZaIE
2020,* Authors generate an new benchmark dataset for covid-19 misinformation detection.,FCna-s-ZaIE
2021,* They create a smart two step process for detecting misinformation,FCna-s-ZaIE
2022,* They investigate if general NLI archtiectures that are not domain adapted can help in misinformation detection,FCna-s-ZaIE
2023,* They use different architectures and evaluate their accuracy,FCna-s-ZaIE
2024,* They definitely provide new knowledge and interesting insights on how misinformation can be detected.,FCna-s-ZaIE
2025,* Models accuracy is generally low,FCna-s-ZaIE
2026,That could be due to the limited amount of observation (5000) and the high amount of potential classes (86 * 3),FCna-s-ZaIE
2027,I enjoyed the study and I definitely support its publication,FCna-s-ZaIE
2028,One thing that I would additionally want to see is comparing your results with these of a standard fine-tuned language model classifier,FCna-s-ZaIE
2029,"I would assume yours would be better, but such a comparison would provide clear evidence why shemantic association and stance detection is a better process to follow.",FCna-s-ZaIE
2030,This paper purposed a method for COVID-19 related misinformation detection,FCna-s-ZaIE
2031,The authors contribute a datasets with 5K annotated tweets on 86 COVID related misinformation,FCna-s-ZaIE
2032,"They evaluated many approaches for misinformation detection and stance detection, and the domain adapted BERTscore  and SBERT achieved the best performance in these two tasks",FCna-s-ZaIE
2033,"The paper is written in a clearly and concise way, and well motivated.",FCna-s-ZaIE
2034,Some further work is suggested for the authors to consider,FCna-s-ZaIE
2035,"In this study, the misinformation in tweets is annotated by experts",FCna-s-ZaIE
2036,"To adapt to new misinformation and automate the process, the authors can link the information in tweets with peer-reviewed scientific publications to detect the new misinformation in tweets",FCna-s-ZaIE
2037,The paper is about creating variations of COVID-19 drugs in Twitter using three different methods to capture posts with misspelled drug names,5fjIxS5Kahh
2038,The Title and the Abstract gives the impression that paper is about finding potential COVID treatments in social media,5fjIxS5Kahh
2039,"However, the research is about the use of automatic techniques for dealing with misspelled drug names in Twitter",5fjIxS5Kahh
2040,The Number of English tweets used in this study and the duration of data collection needs to be mentioned,5fjIxS5Kahh
2041,"It is mentioned as 424 million, where only 67% is English",5fjIxS5Kahh
2042,Its not stated how many of the tweets went through labelling process for COVID drugs,5fjIxS5Kahh
2043," If we only are targeting English tweets, then what is the point of labelling all 424 million tweets?",5fjIxS5Kahh
2044,"In the phrase “ For each term, each alphabet…” its more clear to use character/letter instead of alphabet.",5fjIxS5Kahh
2045,Explanation of the third methodology seems to assume prior knowledge of the technology used,5fjIxS5Kahh
2046,"Text tagging and annotation is used interchangeably, and I suggest using just tagging as annotation could imply manual effort in examining and labelling the tweets.",5fjIxS5Kahh
2047,Zinc is stated as being irrelevant whereas it is talked about as enhancing the clinical efficacy of chloroquine.,5fjIxS5Kahh
2048,Table 1 is unclear as what the “total annotated terms” represents? Is it the number of tweets?  And what is delta in the last row showing? ,5fjIxS5Kahh
2049,"In Table 2 the total frequency is around 472,000 so where did the rest of 723,129 tweets with mentions of drug go? It also would be helpful to show the total number of misspelled drug names frequency.",5fjIxS5Kahh
2050,"In table 5, the calculation of percentage increase column needs clarification",5fjIxS5Kahh
2051,"The total of 222,428 is calculated as 15% of what number?",5fjIxS5Kahh
2052,The paper points out that spelling correction is an important step in preprocessing covid-19-related tweets and enables identification of additional data,5fjIxS5Kahh
2053,The authors explore several approaches to correcting spelling mistakes in drug names using a corpus of covid-19 related tweets,5fjIxS5Kahh
2054,The results suggest that several spelling correction techniques should be applied together to comprehensively address the problem.,5fjIxS5Kahh
2055,"At the same time, my feeling is that the title of the paper does not correspond to its content",5fjIxS5Kahh
2056,The paper does not provide a characterisation of potential treatments but rather lists the most commonly mentioned drugs,5fjIxS5Kahh
2057,There is no further characterisation of the context in which those drugs are mentioned,5fjIxS5Kahh
2058,"Moreover, both the title and the abstract put emphasis on using machine learning, however, only 1 method out 4 is machine learning-based.",5fjIxS5Kahh
2059,"Overall, the format of this study seems more appropriate for a short paper",5fjIxS5Kahh
2060,"For a long paper, I would expect the authors to further analyse why the implemented algorithms give different results, what potential errors might be introduced as well as show some validation of the approach.",5fjIxS5Kahh
2061,"- When describing the second method used to generate misspellings the authors state “For each term, each alphabet is replaced with the closest alphabet on the QWERTY keyboard.” It is not clear what the authors mean by an “alphabet”, I am assuming it means a “letter”? How the closest letter on the keyboard is defined? Do variations include digits? Where is the recursion in this approach? I suggest the authors either cite a related research paper or provide a more detailed explanation.",5fjIxS5Kahh
2062,- Table 2 shows the number of mentions of the top 10 drugs,5fjIxS5Kahh
2063,It is unclear whether these numbers were calculated after applying spelling correction techniques or not.,5fjIxS5Kahh
2064,- I suggest moving the clarification for the data reported in Table 3 from the bottom of p.3 to when the table is first mentioned.,5fjIxS5Kahh
2065,"- It would be great to see more analysis of why the overlap between the three methods is only 15%, ideally, with specific examples.",5fjIxS5Kahh
2066,- Table 5 provides the numbers of additional terms identified using the described methods,5fjIxS5Kahh
2067,How many additional tweets does it allow to recover? How can the authors ensure the additional data is identified correctly?,5fjIxS5Kahh
2068,- The abbreviation for the Social Media Mining Toolkit should be introduced in the main text,5fjIxS5Kahh
2069,- It would be helpful if the authors could clarify whether the total number of annotated terms reported in Table 1 includes only drug-related terms or not? ,5fjIxS5Kahh
2070,In this paper the authors mine the COVID-19 chatter tweets previously released to identify the usage of COVID-19 drugs related vocabulary,5fjIxS5Kahh
2071,"While the paper is interesting, well-written and concise, the authors over-sell some of its aspects",5fjIxS5Kahh
2072,"The paper is straightforward, yet interesting and I would say it would be easily understood by a wide audience",5fjIxS5Kahh
2073,"The number of experiments are adequate, the results are clearly presented and the discussion of each of the steps of the methodology makes it easy to follow",5fjIxS5Kahh
2074,"On the downside, starting by the title, I considering it misleading as the paper solely addresses the use of drug-related terms in tweets",5fjIxS5Kahh
2075,The sole  use of COVID-19 drugs-related vocabulary is not an indicator of a possible treatment being followed by the author of a given tweet,5fjIxS5Kahh
2076,"The same idea is further reinforced in the conclusion, which refers to potential drug treatments available for COVID-19 patients",5fjIxS5Kahh
2077,"However, the experiments led by the authors only take into consideration drug vocabulary frequencies, so I fail to see how are these indicative for potential drug treatments",5fjIxS5Kahh
2078,The work presented is of interest and clearly exposed and should be presented as it is: a COVID-19 drug terms frequency on Twitter chatter,5fjIxS5Kahh
2079,"The abstract and introduction also lead the reader into thinking a 424 million tweets corpus was mined and annotated, however the corpus size is considerably smaller (the clean corpus has approx",5fjIxS5Kahh
2080,"100 million tweets, out of which only 67% are in English and were considered for this study)",5fjIxS5Kahh
2081,"Other remarks: in Table 1, what is delta in the last row? Could the authors elaborate on the differences of the drugs found using with the 3 different spelling methods? I would expect the list of drugs to be more similar, but with different frequencies",5fjIxS5Kahh
2082,"In this work the author presents a novel BERT architecture with the goal of provide a summarization of lengthy papers, applied to the CORD-19 dataset",nJ4Ro0vLEU
2083,The author does a great job at framing the problem and providing relevant related work,nJ4Ro0vLEU
2084,"The proposed model description is intuitive and seems reasonable, however, figure 1 is a bit difficult to read as it compressed for space constraints",nJ4Ro0vLEU
2085,"The dataset description is not clear at all, only discussing about the abstracts used from the CORD dataset, but then table 1 mentions 3 other datasets",nJ4Ro0vLEU
2086,"The 'experiment' section is quite brief and generic, things that should have been discussed are: was this setup for all dataset? just one dataset? and more details are needed",nJ4Ro0vLEU
2087,"On the results section the author only presents results on one dataset, with the proposed model not being the best performant",nJ4Ro0vLEU
2088,"The whole evaluation of the proposed model hinges on the manual review of ONE, summarized article, making this quite lax and not sufficient to show what the author claims in this paper",nJ4Ro0vLEU
2089,"Without a proper and rigorous evaluation, the discussion section seems a bit mute",nJ4Ro0vLEU
2090,"While the ideas in this paper of the novel model are interesting, the work seems rushed and not at the publication stage yet",nJ4Ro0vLEU
2091,The author combines two bert models and adds a transformer on top to perform extractive summarization,nJ4Ro0vLEU
2092,The model architecture is optimized to avoid catastrophic forgetting,nJ4Ro0vLEU
2093,* The author creates a hybrid architecture based on a state of the art language model.,nJ4Ro0vLEU
2094,* The example shows that the model satisfactorily generates extractive summarizations.,nJ4Ro0vLEU
2095,"*  The author does not provide evidence why their model is either better, or faster, or more computationally cheap than other alternatives",nJ4Ro0vLEU
2096,It shows that the proposed technique is slightly worse than BertSum.,nJ4Ro0vLEU
2097,"I  cannot assess if the paper provides a methodological contribution, given my limited level of expertise in language models.",nJ4Ro0vLEU
2098,"The authors present Continual BERT, a model designed for being able to continuously update and summarize COVID literature",nJ4Ro0vLEU
2099,It is trained using CORD-19 to predict abstracts from document text.,nJ4Ro0vLEU
2100,- the idea of online learning is interesting and has interesting properties,nJ4Ro0vLEU
2101,- The exposition of model is inconsistent in its detail - going into depth about relatively trivial modifications to a recurrent layer but glossing over important details in overall model structure,nJ4Ro0vLEU
2102,Section 3.1 should be revisited and expanded in depth,nJ4Ro0vLEU
2103,"Additionally, the model figure 1 is hard to decipher.",nJ4Ro0vLEU
2104,"- in terms of ROUGE scores, the continual BERT lags significantly behind standard methods (BERT Sum)",nJ4Ro0vLEU
2105,- insufficient exploration of continual bert's inability to summarize literature - if old literature is the issue then it could be excluded or this impact directly measured.,nJ4Ro0vLEU
2106,- predicting abstracts is perhaps a poor choice for extractive models,nJ4Ro0vLEU
2107,They frequently contain positioning information and words not found elsewhere in the document,nJ4Ro0vLEU
2108,An upper bound for ROUGE scores from extractive methods would be informative.,nJ4Ro0vLEU
2109,- There are some broken citations,nJ4Ro0vLEU
2110,This paper describes the development of a visualization tool that provides an overview of domain-specific named entities extracted from a subset of the COVID-19 Open Research Dataset (CORD-19),NND5KhQGYct
2111,"A pre-trained NER model from the ScispaCy library was used to extract named entities of CORD-19 articles, which are then visualized by the tool",NND5KhQGYct
2112,"In general, the idea of providing a visualization tool for efficiently navigating CORD-19 is interesting",NND5KhQGYct
2113,"However, the author did not provide a way of accessing the tool (e.g",NND5KhQGYct
2114,"via weblink), making an extensive evaluation more difficult",NND5KhQGYct
2115,"Furthermore, the description of the proposed tool is vague.",NND5KhQGYct
2116,"Overall, I think the paper needs to be clearer in describing the tool and its functions, and an online access to the tool would be very helpful for a proper review.",NND5KhQGYct
2117,"In many occurrences, text is not whitespace-separated from the reference (e.g",NND5KhQGYct
2118,"I found multiple sentences without proper punctuation, which makes reading the paper more difficult (e.g",NND5KhQGYct
2119,"In line 120, the term “dataset” is spelled as “data set”.",NND5KhQGYct
2120,"In line 151, the sentence is incomplete.",NND5KhQGYct
2121,"None of the figures (1-8) shown in the paper are mentioned in the text, and a short explanation would be helpful",NND5KhQGYct
2122,"Furthermore, figures 2-8 are very hard to read in the current resolution",NND5KhQGYct
2123,"Also, what do the colors in the plots (blue, yellow, red) refer to?",NND5KhQGYct
2124,A citation at the end of a sentence should be placed before punctuation (e.g,NND5KhQGYct
2125,This study provides an online visualization tool for discovering CORD-19 dataset,NND5KhQGYct
2126,It applies scispaCy to annotate the concepts mentioned in the papers and then applies scattertext for visualization,NND5KhQGYct
2127,My major concern is none of these steps was evaluated,NND5KhQGYct
2128,"The pre-trained models in scispacy were trained using the biomedical datasets, but may not capture COVID-19 specific entities effectively",NND5KhQGYct
2129,"Are there any evaluations on the precision and recall of the models specifically for COVID-19 related entities? Similarly, the identified relations were not evaluated either",NND5KhQGYct
2130,"In addition, the paper does not provide the URL of the tool for evaluation",NND5KhQGYct
2131,"Given the significant amount of NER time, how frequent is the tool updated? Are APIs available?",NND5KhQGYct
2132,"Also, the provided functions are limited",NND5KhQGYct
2133,"For instance, CORD-19 has papers that are not on COVID-19 (e.g., MERS)",NND5KhQGYct
2134,Visualizing the entities and relations on the whole dataset may not accurately represent the characteristics for COVID-19,NND5KhQGYct
2135,Providing more filtering functions would be helpful.,NND5KhQGYct
2136,"For instance, why providing 6 separate figures just showing different percentages of entities? A figure with sub-figures on selected percentages would be sufficient and the remaining figures could be used for demonstrating other functions",NND5KhQGYct
2137,I found this article reports work-in-progress and I think it is still not ready for publication,NND5KhQGYct
2138,"Even though a visualization tool could certainly help medical professionals, no URL is provided to test the system (only screenshots)",NND5KhQGYct
2139,"The author does not discuss its use case (beyond mentioning ""the study of patterns"") nor provides the perspective from a medical professional: How could a medical doctor reuse these ""patterns"" provided with the Scattertext library? How a healthcare professional would know which ""patterns"" to explore and look for with more detail in the literature?",NND5KhQGYct
2140,"Moreover, there are several typographic mistakes and grammar infelicities that seem like something authors dashed off",NND5KhQGYct
2141,Some sentences or paragraphs could be rewritten and condensed for sake of clarity.,NND5KhQGYct
2142,"-> What do authors mean by ""patterns""? Co-occurrence of mentions of diseases and drug entities (which might reveal a therapeutic relation)?",NND5KhQGYct
2143,"named COVID19"" -> This is not correct; please, change to ""SARS-CoV-2""",NND5KhQGYct
2144,"The coronavirus was named ""SARS-CoV-2"", whereas the disease was named ""COVID-19""",NND5KhQGYct
2145,-The paragraphs starting in line 42 through l,NND5KhQGYct
2146,64 seem to revolve around the same idea; it seems more adequate to rewrite them into one more synthetic paragraph.,NND5KhQGYct
2147,"81: The reference to the Scattertext library (Kessler 2017), and the URL link to it, should be provided the first time it is mentioned, not in line 107.",NND5KhQGYct
2148,85: The reference to sciSpacy should be given when this library is mentioned for the first time,NND5KhQGYct
2149,"Moreover, the updated bibliographic reference is:",NND5KhQGYct
2150,    ScispaCy: Fast and Robust Models for Biomedical Natural Language Processing,NND5KhQGYct
2151,"    Mark Neumann, Daniel King, Iz Beltagy, Waleed Ammar",NND5KhQGYct
2152,"of the 18th BioNLP Workshop and Shared Task, 2019, August 1st, Florence, Italy, pp",NND5KhQGYct
2153,-Figures 2-8 are too small to read the entities shown,NND5KhQGYct
2154,"I recommend the author to place them in an Appendix, in a larger size and with higher resolution.",NND5KhQGYct
2155,"The author mention an ""interactive web visualization"", but no URL is provided to test it",NND5KhQGYct
2156,"-Write a white space between ""Dataset"" and the opening bracket in the title.",NND5KhQGYct
2157,There are similar problems throughout all the article: a white space is missing between the last character of some words and the following opening bracket; e.g,NND5KhQGYct
2158,I think this is an issue related to the Latex code.,NND5KhQGYct
2159,"-""Dataset"" is repeated in ""COVID-19 Open Research Dataset (CORD-19) Dataset""",NND5KhQGYct
2160,"-Abstract: ""easy to use"" -> ""easy-to-use""",NND5KhQGYct
2161,-I think the CORD-19 dataset should be cited in the first mention (l,NND5KhQGYct
2162,-Several sentences lack a dot at the end of the sentence: e.g,NND5KhQGYct
2163,"118: ""For this analysis, The custom license"" -> the (lowercase)",NND5KhQGYct
2164,"137: ""Scispacy Named Entity Recognition Model"" -> ""The sciSpacy Named Entity Recognition Model""",NND5KhQGYct
2165,-In general: the author is encouraged to split long sentences into short text fragments,NND5KhQGYct
2166,"For instance, the paragraph starting at l",NND5KhQGYct
2167,137 is made up of only 1 sentence,NND5KhQGYct
2168,This could be fragmented in shorter sentences for the sake of clarity.,NND5KhQGYct
2169,"151: ""...100 tokens were ."" -> something is missing.",NND5KhQGYct
2170,"This paper presents an analysis on tweets posted in Persian/Farsi about COVID-19, including",AWCLvxUgLqx
2171, -- the correlation between tweet discussions and infected cases,AWCLvxUgLqx
2172, -- topic analysis using Latent Dirichlet Allocation,AWCLvxUgLqx
2173, -- tweets categorization into several manually defined categories,AWCLvxUgLqx
2174," -- It is a really interesting reading, providing lots of interesting observations on Iranian public reaction",AWCLvxUgLqx
2175," -- The paper structure looks strange, and it causes difficulty in understanding the paper",AWCLvxUgLqx
2176,Should Section 2 (results) be put after section 3 (methods)? and Section 4 (data collection) become Section 2? Put Appendices after References,AWCLvxUgLqx
2177,Don't feel Appendix B.1 fits the paper.,AWCLvxUgLqx
2178," -- The writing can be improved, especially when describing methods",AWCLvxUgLqx
2179,Add citation and explain in details methods.,AWCLvxUgLqx
2180, -- The experimental setup looks arbitrary,AWCLvxUgLqx
2181,"For example, the explanation in Section 3.1.1 and 3.2 are lack of detail and not convincing.",AWCLvxUgLqx
2182,"- Section 2.2.1: When giving examples about these topics, it would be better to refer to Table 4, explaining why it is the case",AWCLvxUgLqx
2183,"- Table 6, suggest to add English translations",AWCLvxUgLqx
2184,- It seems a paper that should have broder group of readers (ordinary people) rather than only NLP researchers.,AWCLvxUgLqx
2185,The comments I am making are just some examples of the issues I found with the paper – I believe the authors would benefit from collaborating with writing experts from their university,AWCLvxUgLqx
2186,The paper needs to be proofread,AWCLvxUgLqx
2187,"this study is organized as following), missing punctation and long sentences",AWCLvxUgLqx
2188,The structure of the paper is in reverse of usual order in this discipline,AWCLvxUgLqx
2189,"It should be changed to: Introduction, Data, Method, and Analysis and Conclusion.",AWCLvxUgLqx
2190,"There are references to Tables in the paper, but every image is captioned as a Figure",AWCLvxUgLqx
2191,The fact that Twitter is widely used by Iranians needs a reference,AWCLvxUgLqx
2192,It is hard to believe this platform is popular between Iranians given their aversion to government oversight and their private nature,AWCLvxUgLqx
2193,(What percentage of Iranians use Twitter? Compared to Facebook/Instagram/Pinterest?) ,AWCLvxUgLqx
2194,"It is strange to read first “Discussion and Results” before any explanations, and phrases such as “In this round of analysis” are perplexing  - at this point we have no notion of “rounds of analysis” let alone what this round might be.",AWCLvxUgLqx
2195,The section talks about tweets related to COVID-19 and tells us to read section 4 to get an insight into the process,AWCLvxUgLqx
2196,If we read section 4 we find that we must refer to Figure 7 to see what search terms were used – and we find that none of the English translations use the term “COVID” – rather they mostly all use variations of “corona”,AWCLvxUgLqx
2197,Do Iranians not use the COVID-19 terminology? This needs an explanation.,AWCLvxUgLqx
2198,Section 2 brings to our attention the fact that the number of corona-related tweets has steadily gone down after the onset of the disease in Iran,AWCLvxUgLqx
2199," However, there is no analysis done on this important trend, instead an obvious point is made about people being less active on Twitter around the Persian New Year day! This diminished activity is explained as related to travel – is travel the only thing that Iranians do more of that would explain the pattern around Nowruz – but really, why is this significant at all for the study? It could just be quickly mentioned and not in such detail",AWCLvxUgLqx
2200,Figure 2 seems to be redundant as the trend is already in Figure 1 and because of the lack of importance to Nowruz for the study – could the annotation of March 13 be added to Figure 1? ,AWCLvxUgLqx
2201,"Section 2.3, Figure 5 presents a clear tweet distribution over some topics but the discussion before the figure does not clearly explain where the distribution comes from",AWCLvxUgLqx
2202,The discussion seems to imply that the numbers in Fig 5 are based on manual labelling,AWCLvxUgLqx
2203,The reader is left asking herself how many tweets were annotated if manual labelling was used,AWCLvxUgLqx
2204,"Or, if not, then how were these 6 distinct categories derived? We must detour to the suggested detail in the later section 3.2 to understand these are related to a k-means clustering content analysis process",AWCLvxUgLqx
2205,This is just one example of the frustration that occurs because of an incorrect sequence,AWCLvxUgLqx
2206,This is also confusing because this should be explained after the annotation section.,AWCLvxUgLqx
2207,The top 25 topics out of 50 topics are listed and some are analysed here,AWCLvxUgLqx
2208,Looking at the list of topics they seem to be very overlapping,AWCLvxUgLqx
2209,It seems that the number of 50 for topics is too high,AWCLvxUgLqx
2210,"On the other hand, references are made that would require a fine distinction between topics, but these cannot be found in the examples",AWCLvxUgLqx
2211,"For instance, Basij is mentioned as one of the top topics but it is not obvious which topic in Figure 4 it is related to",AWCLvxUgLqx
2212,Should we have seen more of the top words to understand which of the pro or anti regime topics contains this reference? We do not need to keep seeing the word “corona” in every topic – common words would normally be eliminated during topic modelling but can at least be removed from the table so we can see more of the distinctive words.,AWCLvxUgLqx
2213,The choice of 50 topics seems unreasonable and it is not justified,AWCLvxUgLqx
2214,"Looking at the top 25 topics, we could merge some",AWCLvxUgLqx
2215,"Section3.2 Both k-means clustering, and topic modelling seem to be used for the same analysis",AWCLvxUgLqx
2216,I would suggest to stick to just k-means clustering and analyse the taxonomy of Persian corona-related tweets,AWCLvxUgLqx
2217,The k-means clustering is done on 8 categories but annotation is done with 6 labels,AWCLvxUgLqx
2218,Give the number of annotated tweets,AWCLvxUgLqx
2219,If it is only 240 tweets that is not enough for giving a sound analysis,AWCLvxUgLqx
2220,Section 4.1 The keywords used for collecting tweets only based on 8 hashtags which is a very limited scope,AWCLvxUgLqx
2221,It would have been useful to show a few examples of satire tweets.,AWCLvxUgLqx
2222,The mentions of conversations on Whatsapp is completely irrelevant and confusing for the reader,AWCLvxUgLqx
2223,"Whatsapp is a messaging app, not belonging to the social media category",AWCLvxUgLqx
2224,This is a report on the conclusions from a data analysis performed on 530k tweets over a period of one month in Persian language,AWCLvxUgLqx
2225," - as the authors said, it can indeed become a blueprint for how to perform similar analysis in different countries",AWCLvxUgLqx
2226," - it contains several interesting nuggets which are probably distinct of this culture, and are worth comparing with studies performed in other languages (eg: the drop during Persian new year, the high tweets which are about satire)",AWCLvxUgLqx
2227," - there are several points which are unclear (see below), and I believe should be clarified if this is to be accepted",AWCLvxUgLqx
2228, - it contains several unrelated analyses and reads sometimes as a collage of different things,AWCLvxUgLqx
2229,"I would encourage the authors to trim the paper down (eg: focus either on the LDA or kmeans, remove Appendix B)",AWCLvxUgLqx
2230, - the paper would be easier if read in reverse: data-collection comes at the end and lots of material is repeated (first the conclusion (Sect 2) and then again when explained the process (Sect 3) ),AWCLvxUgLqx
2231,"While this might be standard in other disciplines, it is not the case in NLP",AWCLvxUgLqx
2232,I think that by working on the structure the paper could be made clearer and to the point.,AWCLvxUgLqx
2233," - is Fig 2 just the zoom of the red curve of Fig 1? If so, it could be removed",AWCLvxUgLqx
2234," - ""Twitter is one of the widely-used online platforms by Iranians"" could you add a reference to that, detailing, for instance, the market penetration?",AWCLvxUgLqx
2235," - Sect 3.1.2: for what is the document-wide analysis done? If you want a hard-clustering, then why do an LDA and not directly a kmeans like you do afterwards? In general, the LDA analysis seems underexploited",AWCLvxUgLqx
2236,Was it used to obtain the categories of 3.2.1?,AWCLvxUgLqx
2237," - you detail the features for LDA , but not for kmeans",AWCLvxUgLqx
2238, - I think your extrapolation of classes from a random sample of 30 of each category has issues,AWCLvxUgLqx
2239,Depending on the size of the cluster the error might be high (increased by your IAA),AWCLvxUgLqx
2240,"Why not train a classifier with the annotations, maybe adding some weakly-supervision? This would also strengthen the technical aspects of the paper.",AWCLvxUgLqx
2241,"As a conclusion, I propose to reduce the paper lengths substantially by focusing on the main contribution (which for me is the annotated dataset and the clustering), remove duplicate description (which could be easily done by reverting the current order: Sect 4 first, then Sect 3 and finally Sect 2 with the plots) and deciding what to do with the LDA analysis (the appendix might be a good place if it was only used to obtain the categories)",AWCLvxUgLqx
2242,This paper used few shot learning to build a semi-supervised model on unlabeled COVID-19 tweets,OOq31Bnxx5I
2243,"A pre-trained Influenza model was used to facilitate the classification tweets into related to COVID, Self/Others infection, Infection and Vaccine",OOq31Bnxx5I
2244, The paper is well motivated and clearly written,OOq31Bnxx5I
2245,"The test datasets used in the categories of Self/Others infection, Infection and Vaccine were very small",OOq31Bnxx5I
2246,The benefit of semi-supervised learning is to use a small amount of labeled data to classify a large amount of unlabeled data,OOq31Bnxx5I
2247,The comparison between COVID and COVID* using the pre-trained Influenza model in Table 3 and 4 can not be justified based on such small test datasets,OOq31Bnxx5I
2248,There is no baseline method in the paper,OOq31Bnxx5I
2249,Many other semi-supervised methods such as Graph Convolutional Network (GCN) achieved good performance on small training sets,OOq31Bnxx5I
2250,The purposed method needs to be compared with baselines including some traditional machine learning methods.,OOq31Bnxx5I
2251,Some information needs to be clarified:,OOq31Bnxx5I
2252,whether CNN used in Influenza classification is same as the autoencoder used for unlabeled COVID tweets,OOq31Bnxx5I
2253,Please refer to Section 2.3 “Once a second Autoencoder on influenza data has been trained”,OOq31Bnxx5I
2254,Please provide the number of unlabeled COVID-19 tweets trained in autoencoder and labeled Influenza tweets used in classification,OOq31Bnxx5I
2255,The paper proposes an approach to overcoming the lack of annotated data from Twitter related to covid-19,OOq31Bnxx5I
2256,The authors take advantage of the similarities between covid-19 and common flu and employ transfer learning to detect tweets related to covid-19 and classify them into several categories,OOq31Bnxx5I
2257,The technical part of the paper is very well written and the intuition behind various transformations is explained in a clear and simple way,OOq31Bnxx5I
2258,I also appreciated the comments on the extension and application of the approach for future monitoring once a vaccine becomes available.,OOq31Bnxx5I
2259,- The major point of confusion for me is whether the authors trained one model to perform multi-class classification (as claimed in line 141) or four binary models to tackle each problem separately (as it appears in sections 3.1-3.4),OOq31Bnxx5I
2260,"On a related note, it is unclear if the classes considered in the paper are mutually exclusive or if each tweet has multiple labels? A figure/table clarifying this for both coronavirus data and influenza data would be very helpful.",OOq31Bnxx5I
2261,- Lines 237-238: it is unclear what are the 5 categories? Both the introduction section (line 141) and figure 1 mention only 4 categories,OOq31Bnxx5I
2262,I suggest specifying the categories here one more time for clarity.,OOq31Bnxx5I
2263,- Line 239: please provide the size of the final annotated dataset used for few-shot learning.,OOq31Bnxx5I
2264,- Just a suggestion to reiterate in line 339 that the latent representation is denoted by z.,OOq31Bnxx5I
2265,"- Section 2.3: the authors described the process of training 2 encoders, one on Coronavirus data and one on Influenza data",OOq31Bnxx5I
2266,It is unclear which encoder the authors are referring to in line 391,OOq31Bnxx5I
2267,"Moreover, figure 1 creates the impression that W_i denotes the weights of the pre-trained MLP model",OOq31Bnxx5I
2268,To avoid confusion I suggest the authors review the paper and make sure variables are properly introduced in the main text,OOq31Bnxx5I
2269,"- Please confirm that the reported in Table 4 precision, recall, and f1 score values are calculated using the test set.",OOq31Bnxx5I
2270,"- There are a few typos in the text, for example in lines 272, 343, 433, 573",OOq31Bnxx5I
2271,While it doesn’t affect the readability it would be nice to correct those.,OOq31Bnxx5I
2272,This paper proposes a learning algorithm which is semi supervised and can monitor twitter during COVID19,OOq31Bnxx5I
2273,They also evaluate the use of twitter data for surveillance and improve accuracy of their model using transfer learning,OOq31Bnxx5I
2274,The paper shows that high accuracy may be obtained from limited labelled data using few shot learning and can potentially overcome the need to have large datasets which are labelled,OOq31Bnxx5I
2275,Very well written paper with proper descriptions and examples where needed.,OOq31Bnxx5I
2276,Figures and tables are very self explanatory in nature with good notes o them,OOq31Bnxx5I
2277,Processes of dataset building and data annotation has been clearly explained in detail.,OOq31Bnxx5I
2278,The process of classifying data into its labels such as awareness vs infection or self vs other and related vs non related has been explained well and has been analyzed with proper statistical metrics and tests.,OOq31Bnxx5I
2279,The work is very relevant to the current situation and on going research,OOq31Bnxx5I
2280,"A minor comment, but may be a bit more light on to why the specific number of data-points were chosen for classification would be better.",OOq31Bnxx5I
2281,"Although a very well written paper, there are few mistakes in writing and grammar",OOq31Bnxx5I
2282,"Such as ""The accuracy of the influenza classifier is DISCUSS in section 3.4"" in page 5 and a few other minute errors.",OOq31Bnxx5I
2283,This study aimed to improve the CORD-19 dataset by using the tools in SeerSuite to mine data from PDFs,8J1BID37-U1
2284,"Additionally, this study created a search engine, COVIDSeer3, to ease the exploration of this data",8J1BID37-U1
2285,This study clearly stated the problem and the methods used to improve the CORD-19 dataset were clearly described and free from major flaws,8J1BID37-U1
2286,This work reports some experiments of thematic clustering about the COVID-19 pandemics,NO1cfRarN1h
2287,"The authors leveraged data from Bruno Latour's questionnaire, which brought up in public debate some questions about activities to stop or develop after the pandemics",NO1cfRarN1h
2288,The respondents' answers (in French and English) were segmented into short sentences,NO1cfRarN1h
2289,The task consisted in cluster these segments into coherent topics,NO1cfRarN1h
2290,"The experiment reused several sentence embedding models (BERT, Universal Sentence Encoder and Smooth Inverse Frequency embeddings), concatenate them and reduce dimensionality, then use OPTICS clustering (Ankerst et al",NO1cfRarN1h
2291,"The more original contribution is using a logistic regression classifier to re-assign segments from ""noisy clusters"" to ""unambiguous clusters""",NO1cfRarN1h
2292,Segments assigned by the OPTICS method to unambiguous clusters are used to train the model (the authors validated manually the output from the clustering ),NO1cfRarN1h
2293,"Through manual validation of the predicted probabilities (of the ""noisy"" segments to belong to an unambiguous cluster), authors report promising results of topic assignment",NO1cfRarN1h
2294,The authors also tested their methods on data from the SemEval task.,NO1cfRarN1h
2295,I found this work fits the audience of the workshop and could provide an original contribution,NO1cfRarN1h
2296,"Especially, because it seems to work with a small corpus, which is welcomed (given that many tasks lack annotated data) and could work across domains (authors could highligh this fact)",NO1cfRarN1h
2297,"Still, I had some difficulties in following some of the explanations because of structure and the writing style (I did not understand some abbreviations after reading the full article)",NO1cfRarN1h
2298, I wonder whether authors could resubmit to this workshop a paper with a structure and writing clarity that meets the required level.,NO1cfRarN1h
2299,-An original semisupervised method for resolving clustering ambiguities,NO1cfRarN1h
2300,-The method is suitable for small corpora and seems to be domain-independent.,NO1cfRarN1h
2301,-Some parts of the article need to be reestructured,NO1cfRarN1h
2302,5) presents some methods and also the results,NO1cfRarN1h
2303,"8) provides further details about the comparison with Wang & Kuo (2020), which could be moved to sections reporting the evaluation methods or the results",NO1cfRarN1h
2304,The results of evaluating with SemEval should be provided in the Results section.,NO1cfRarN1h
2305,-Several grammar errors and typographic infelicities.,NO1cfRarN1h
2306,"-Authors state that they ""release the anonymized dataset as a publicly available resource"" (l",NO1cfRarN1h
2307,"103); however, no link to any repository is provided.",NO1cfRarN1h
2308,"The statement that the authors' approach is lighter and ""runs on [a] modest software configuration"" (l",NO1cfRarN1h
2309,BERT and other neural models are heavy to load (even though authors do not train BERT or fine-tune on their data),NO1cfRarN1h
2310,"-Table 6: Please, explain that ""Stop"" and ""Dev"" refer to ""Stop answers"" and ""Development answers"" in the questionnaire, respectively",NO1cfRarN1h
2311,"""Dev"" can be mistaken with the ""Development"" set to validate the machine-learning classifier.",NO1cfRarN1h
2312,"-Tables 10-14 (Appendix) and Figures 2-6: Please, provide a note to explain that ""p"" stands for ""probabilities"" obtained with the Logistic Regression model",NO1cfRarN1h
2313,"The way it is presented, ""p"" can be interpreted as ""p-value""",NO1cfRarN1h
2314,"-Figures 2-5: the blue colors corresponding to ""p=1"" and ""0.75<p<1"" do not distinguish very well each bar section",NO1cfRarN1h
2315,I suggest authors use different patterns (vertical or horizontal lines...) for each section in the bars.,NO1cfRarN1h
2316,"16: ""respondents answers"" -> ""respondents' answers""",NO1cfRarN1h
2317,-Several acronyms need to be defined the first time they are used: e.g,NO1cfRarN1h
2318,"207: ""diverse styles :"" -> no space before the "":"" character in English",NO1cfRarN1h
2319,Other contexts to fix throughout the document (e.g,NO1cfRarN1h
2320,"221: ""does not give satisfying"" -> satisfactory",NO1cfRarN1h
2321,-Long sentences (such as lines 248-326) should be split in 2 for the sake of clarity,NO1cfRarN1h
2322,"-Fix grammar errors such as (not exhaustive): ""consist of a Transformer"" (l",NO1cfRarN1h
2323,"397) -> consists; ""the algorithm give"" (l",NO1cfRarN1h
2324,"-Caption of Table 4: ""Other model's performances assessment"" -> ""Evaluation of other models' performance"" ?",NO1cfRarN1h
2325,"593 & Table 8: ""Develop questions"" -> ""Development questions""? More cases throughout the article.",NO1cfRarN1h
2326,This paper addresses topic modelling on a small corpus of 1083 respondant texts to a questionnaire regarding societal changes that could be driven by the recent pandemic,NO1cfRarN1h
2327,"The idea behind the paper is of interest for the NLP community, however the paper seems to have been written in a rush",NO1cfRarN1h
2328,"The methodology is not clear enough, paper organization is flawed and the authors tried to overcome the page limit by adding an annex where they dumped most of the tables and figures, without proper descriptions",NO1cfRarN1h
2329,"This translates in not only not having followed the template, but more so in an increased difficulty for the user to understand those results and their impact",NO1cfRarN1h
2330,"Moreover, Tables 1, 2 and 4 appear in the paper before being referenced and Figure 1 is not even referenced anywhere in the text",NO1cfRarN1h
2331,"Abbreviations are also misused, in some cases they are only written by extension the second or third time they are found in the text (e.g",NO1cfRarN1h
2332,In Table 2 it is not clear which answers are we seeing,NO1cfRarN1h
2333,What are the questions to which the users provided these answers?,NO1cfRarN1h
2334,"The authors claim that the answers in the corpus are generally enumerations ""due to the nature of the proposed task""",NO1cfRarN1h
2335,"However, five out of the nine questions in the questionnaires ask for a description, so I would expect at least the answers to these questions to be descriptive",NO1cfRarN1h
2336,What is the SST benchmark? No description is provided,NO1cfRarN1h
2337,"The most intriguing part about the paper is probably the fact that the authors try to sell it as a topic modeling solution for the  COVID-19 related questionnaire answers, although they end up using only 60 couples of segments out of the pool of the 1083x9 answers texts",NO1cfRarN1h
2338,"The paper presentation is not fluid, I had a hard time following its logic and the issues regarding its organization made it more difficult",NO1cfRarN1h
2339,**Recommendation:** Paper should be conditionally accepted -- revise and resubmit.,8waJft6HpG6
2340,Clear description of methods and data,8waJft6HpG6
2341,Use of open dataset makes work reproducible,8waJft6HpG6
2342,Discussion of relevant research is missing,8waJft6HpG6
2343,Discussion of methods / data overly implementation-specific,8waJft6HpG6
2344,Data / methods discussion is disorganized  ,8waJft6HpG6
2345,The authors use test the implications for using deep learning in a semi-automated content-analysis approach to classifying scientific journal articles,8waJft6HpG6
2346,"They perform four experiments with a single, neural network containing three fully-connected layers",8waJft6HpG6
2347,The experiments consist of the authors varying the inputs and output targets of the neural network,8waJft6HpG6
2348,"They find that across all experiments, the neural network's results are promising.",8waJft6HpG6
2349,The authors should revise section 4 to discuss the what of their data instead of the how,8waJft6HpG6
2350,"The specific format of the data (e.g., JSON or tree-shaped) is immaterial to the analysis they perform",8waJft6HpG6
2351,They should also include a discussion of their methods in this section,8waJft6HpG6
2352,I recommend discussing the neural network architecture and then discussing the four experiments carried out with it,8waJft6HpG6
2353,"The authors should refrain from discussing implementation-specifics (e.g., specific Keras routines used)",8waJft6HpG6
2354,"Though this information is relevant, it is more appropriate for a footnote than the body of the paper",8waJft6HpG6
2355,If the neural network architecture is described in thorough enough detail - the exact implementation should be irrelevant,8waJft6HpG6
2356,"Additionally, the authors miss an opportunity to summarize the research on semi-automated/human-in-the-loop/active learning content analysis",8waJft6HpG6
2357,This is a growing area of interest,8waJft6HpG6
2358,The authors would be well served to conceptualize this interdisciplinary research area and enumerate the machine-learning methods and data types used by previous researchers in this area.,8waJft6HpG6
2359,"Overall, the paper is interesting and applies existing knowledge in a novel way",8waJft6HpG6
2360,The authors could do better to describe their methods and notably miss an opportunity to summarize the research on semi-automated/human-in-the-loop content analysis,8waJft6HpG6
2361,I recommend the paper be accepted conditional upon revisions.,8waJft6HpG6
2362,**Reproducibility:** This paper could be reproduced.,8waJft6HpG6
