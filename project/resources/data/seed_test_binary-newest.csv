,Description,Class Index
0," Unlike the generative distribution sampling of GANs, the method provides an interesting compositional scheme, where the low frequencies are regressed and the high frequencies are obtained by \""copying\"" patches from the training set.",1
1,The conclusion drawn by the authors seems self explanatory and does not require any validation through the presenter work,2
2,default settings?? huh???,2
3,"  \n\nIf convenient, could the authors comment on a similarly motivated paper under review at iclr 2018:\nVARIANCE-BASED GRADIENT COMPRESSION FOR EFFICIENT DISTRIBUTED DEEP LEARNING",1
4,"This paper reads like a womans diary, not like a scientific piece of work",2
5,\n\nMany of the ideas presented are novel.,1
6, Usually it would be defined as $\\mathcal{S} \\rightarrow \\mathcal{P}(\\mathcal{A})$,1
7,Please reject it completely and then block the authors email ID so they cant use the online system in the future.,2
8," Indeed when the network misclassifies an example, its adversarial version is forced to be close to it in embedding space while the adversarial term promotes a different prediction from the clean version (that of the ground truth label).",1
9, Might this also suffer from non-convergence issues like you argue SVAE does?,1
10, The resulting embeddings were evaluated not only on word similarity tasks but also on a bunch of downstream applications such as sentiment analysis. ,1
11," Of course, that involves O(K^2) or O(K^3) computation, which is a weakness.",1
12,  \n\nThe third observation seems less useful to me.,1
13,"""Summary:\nThis paper proposes a new approach to tackle the problem of prediction under\nthe shift in design, which consists of the shift in policy (conditional\ndistribution of treatment given features) and the shift in domain (marginal \ndistribution of features).",1
14,I would rather read a meta-analysis,2
15,"Lots of work, effort, but no real science.",2
16," It would make a lot of sense to use the same loss as the evaluation metric (not to mention the properties of PCA).""",1
17,"And finally, the references are a mess.",2
18,"  The game can be programmed to have an \u201cn\u201d lane highway, where n could reasonable go up to five to represent larger highways.",1
19,"I believe that the authors have done scientific work, but in the current form of the paper it is impossible to judge it.",2
20,  This paper then compare this objective with the MMD distance between the samples A & B.,1
21,The lead author of this study has an apparent history of convincing otherwise well-respected scholars to be unwitting co-authors on his poor excuses for academic papers,2
22,\n\nThe paper is its current form has the following issues:\n1. There is hardly any baseline compared in the paper.,1
23,The current manuscript is deceptive and I do not recommend its publication.,2
24,\n- No comparisons with prior work are provided.,1
25,"Nothing about the paper is objectively concerning, but I am left unconvinced",2
26," The results are also presented in a confusing way, with the current state of the art results separate from the main results of the paper.",1
27,"I urge the authors to not publish this article anywhere, as it will impede the progress of scientific understanding",2
28,The peaceful atmosphere between Christmas and New Year was transiently disrupted by reading this...,2
29,\n\n+ Paper is well written and easy to follow.,1
30,"""The authors argue that the spectral dimensionality reduction techniques are too slow, due to the complexity of computing the eigenvalue decomposition, and that they are not suitable for out-of-sample extension.",1
31,"Unfortunately, for the reader (and it almost seems that for the writers as well), there is no insight or conclusions coming out of their comparison.",2
32," Furthermore, the paper discusses the algorithm using hand-waiving arguments and lacks the rigor that I would consider necessary on an optimization-based contribution.",1
33,"""** post-rebuttal revision **\n\nI thank the authors for running the baseline experiments, especially for running the TwinNet to learn an agreement between two RNNs going forward in time.",1
34,The figure is a mystery to me. Where did all this sound energy go? It defies the basic laws of physics.,2
35, Are the assumptions in Theorem 2 reasonable?,1
36,\n\nSignificance\nThis paper makes incremental improvements and would be of moderate interest to\nthe machine learning community.,1
37,"There is an over-reliance on sophisticated statistics at the expense of good old fashioned, scientific thought",2
38," Especially it borrows the cyclic loss from the image style transfer, which provides a reasonable regularization to the text style transfer model.",1
39,The presentation is of a standard that I would reject from an undergraduate student,2
40,"This paper is so bad I cannot even reject it! 
",2
41,This paper may sink without trace' h/,2
42, Even the definition of external vs. internal environment (section 4) was unclear which is used a few times later.,1
43,It is always rather pleasant to recommend that a paper be rejected.,2
44,Your research paper is not motivated. There is no motivation behind your algorithm. Your results lack motivation,2
45, The paper has the potential of conveying the message of causality into the ICLR community and thereby trigger other ideas in that area.,1
46,"The results are obvious. In fact, so obvious that perhaps no one has bothered to write them down...",2
47,"Can you explain this part a bit further, but without going into detail",2
48,"How does [redacted theory] explain your results? Or really, your underwhelming results?",2
49,"It was hard to bite myself through, but in the back I found some meat.",2
50,The authors criticize the approach of [citation of X] before introducing their own. Seems somewhat hypocritical to me.,2
51,"\n\nThere are also quite a few correctness errors in the paper, and the polish of the plots and language needs work, as outlined below. ",1
52, An important contribution is to show that a well-defined architecture representation could lead to efficient cells with a simple randomized search. ,1
53,"""The paper is interesting,",1
54,This work is not an easy topic. ,2
55,\n\nWeaknesses:\n- Figure 2: the plots are too small.,1
56," found the use of the evolutionary theory problematic. This is a highly contested theory, with major flaws",2
57," The \""parallel ordering\"" terminology also seems to be arbitrary...",1
58,\n\n\nMinor issues - \n* Use one style for introducing and defining terms either use italics or single quotes.,1
59," This way, finer discretization does not increase the dimension of \\x (nor its approximation), but rather improves the resolution.",1
60,\n They do not match up to the Zhang paper (I have tried to find the matching accuracies there).,1
61, It builds on previous works Montufar et al. (2014) and Raghu et al. (2017) and presents improved bounds on the maximum number of linear regions.,1
62,The paper could be considered for acceptance given a rewrite of the paper and change in the title and abstract.,2
63,"  However, while results on convex hull task are good,",1
64,"In the end, I am not sure what is the thesis of the essay (or whether there is one) or how and why the parts are connected",2
65, Some more extra work is needed to derive the lipschitz constant of the loss function from the CNN function.,1
66,"\n\nOverall, this is a very well-written paper that creatively combines a number of interesting ideas to address an important problem.""",1
67,There are far too many typos and grammatical mistakes. I started to correct these but got annoyed.,2
68,Someone has been foraging in theory and has managed to learn how to mangle simple concepts and hide them behind pretentious empty prose,2
69,"While I think there is good reason to have performed this work, it does make for unexciting reading.",2
70,A classic instance of reinvention of the square wheel.,2
71,  It is not clear what implantation of GAN they are using?.,1
72, And an extensive literature of theoretical results.,1
73,"  It would be good to explicitly state that (boldface) s is a vector of scores s_u (or score vectors, in case of multiple edge types) for all u in V.",1
74,"""This paper suggests an RNN reparametrization of the recurrent weights with a skew-symmetric matrix using Cayley transform to keep the recurrent weight matrix orthogonal.",1
75,This paper is to science as astrology is to astrophysics' h/,2
76,"This casual tone is also borne out on the author's website, which is inappropriate if not offensive as a professional introduction.",2
77,". As I understand, MCTS was not used in this experiment.",1
78,I dont see how your approach has potential to shed light on a question that anyone might have.,2
79,"\n\n\n#######################################################\n\nPost-rebuttal review\n---------------------------\n\nGiven the details the authors provided to my review, I decided to adjust my score.",1
80,"  That and other recent work have provided some systematic evaluations of complex-valued networks, and shown their utility in a number of cases. ",1
81,You have two many misprints,2
82,"While an interesting concept, in its current form, the approach taken is fundamentally inadequate and flawed for almost all use cases.",2
83, It is the first to study constructing minimal training sets for NPI given a black-box oracle.,1
84, \n\nThere are many baselines missing.,1
85,\n\nOriginality:\n\npros:\n-The paper while simple sheds some light on important problem with the prior distribution used in GAN.,1
86,The MS is like a group of old wise men sitting around mulling over the terrible state of the world,2
87,The manuscript shall be rejected in its current form if submitted for a journal,2
88," A possible solution is to add a regularization term to the objective function to ensure the sparsity of the factorization.""",1
89,"It looks to be more of a chance for the authors to promote a product using a poorly constructed, non-replicable pilot study",2
90,"But fundamentally, why did you bother?",2
91,The take home message has to be extracted with significant labor from a punishing set of figures with multiple bar graphs,2
92," As I explain further below given the combinatorial form of the result, the usefulness of this particular extension to ReLU network is not very clear.",1
93,"It is at best of little value and, in the worst case, irrelevant and offensive",2
94,"The manuscript is too long for what the authors have to say. However, additional text is required as outlined below.",2
95,"Can you explain this part a bit further, but without going into detail.",2
96," \n\nOn top of this, I do not enjoy the style the paper is written in, the language is convoluted.",1
97,The rest of the Introduction is just as badly done as the first paragraph so I will not continue,2
98,The biggest value of this paper lies in the fact that its pages are bound together.,2
99,Preliminary and intriguing results that should be published elsewhere.,2
100,"If this topic were not dear to my heart, I would perhaps have struggled to follow your logic.",2
101,. It is a term to minimize a risk not a parameter,1
102,"The paper brings to mind the Mark Twain quote: 'I didnt have time to write a short letter, so I wrote a long one instead.'",2
103,Well Written. ,2
104,\n\nIt is rather unclear why changing the learning rate affects the performance of the model and it is would have been interesting to discuss.,1
105, \n\n****** I read the authors reply. Thank you for your answers and for the SVD plots this is  helpful.,1
106,"You know that this table is unreadable – at least one of the authors of this paper must have said this is unreadable, lets put in a series of bar plots with the numbers written on the bar. I agree with that person.",2
107,"The paper is silent on the kinds of issues that occupy yards of library shelf-space, and goes well beyond what is warranted by the data",2
108,"\u201d Let\u2019s consider the top-left subplot of Fig 1, showing a heavily bimodal distribution (modes near -1 and +1.). Is this plot made using data from a single neuron or from  multiple neurons?",1
109," It also showed good online A/B test performance, which indicates that this approach has been tested in real world.",1
110," As a result, it is very hard for me to say anything about whether this particular architecture is interesting or is it just in general that background knowledge from concept net is useful.",1
111," That is because almost all tasks require good representations for all words, not just prepositions.",1
112,\nThe claim that ARM is more robust to partially observable domains is supported by experiments where it outperforms DQN.,1
113,"""The manuscript introduces the sensor transformation attention networks, a generic neural architecture able to learn the attention that must be payed to different input channels (sensors) depending on the relative quality of each sensor with respect to the others.",1
114,I dont think this study would add anything to either theory or practice,2
115,"  The confusion is particularly acute in places where derivatives are taken, because the derivatives continue to be taken as if the weights were untied, but then written as if they happened to be the same.",1
116," Because of different benchmarks, it is not clear whether the performance improvements are due to technical improvements or sub-optimal parameters/training for the baseline methods.",1
117, Any of these references would have made a lot of sense.,1
118,Are we modelling an astronomical object here or an abstraction?,2
119,"  \n\n2. The proposed idea is very well motivated, and the proposed model seems correct.",1
120,I apologize for this but frankly some parts read like a report of a high-school student on a scientific experiment.,2
121,"Most of the work is methodological rather than scientific, making it somewhat boring.",2
122,"Exhaustive pages of statistical and meta-analytic data and results which seem rather redundant are presented, about 60+ pages of minute analyses of each possible particle of data.",2
123, \n\nThere is also a toy example created to show that this approach works well compared to the RNN based approaches.,1
124,The title is the closest Ive seen to manuscript clickbait,2
125,"If this was taken from a successfully defended thesis, as it appears to have been, then he should not have been awarded a PhD",2
126, \nand 2) the distributional discrepancy between the re-weighted source domain and\nthe target domain.,1
127,The title of the submission is misleading and it should be renamed 'A Personal Diary',2
128,"I sent your MS to three referees in the hopes of finding someone who might like it a little.  Sadly, I failed",2
129,"  The architecture consists of an encoder, a mixer, a decoder, and many modality networks to cover different types of input and output pairs for different tasks.",1
130,The abstract is intriguing but confusing,2
131," \nAuthors present two architectures: one based on denseNet, and one based on denseNet + LSTM on output dimensions (i.e. similar to NADE model), and compare it to state of the art on the chest x-ray classification.",1
132,"The authors are perpetuating misguided generalizations in the face of substantial
experimental data to the contrary",2
133, This figure does not seem to be referred to anywhere in the text and the broken caption makes it hard to understand what is happening there.,1
134,"Despite the apparently impeccable arrangement of the essay, with headings and sub-headings, the progression of argument is not always transparent, often hindered by otiose wording. 

",2
135, though it's not clear from the paper that the approach is a substantial improvement over previous work.,1
136,\n - p.2: You use pretrained GloVe vectors that you do not update.,1
137,"""- Good work on developing VAEs for few-shot learning.",1
138,"If published, uneducated and misinformed statements like this would jeopardize the credibility of this journal",2
139,\n- The idea is novel and impactful if its evaluated properly and consistently.,1
140,...It's impossible to judge the claims of the authors although there is real reason to believe that the claims may pan out...,2
141,What is a systematic review? I have never heard of an unsystematic review.,2
142,This is a rather pedestrian treatment of a popular and well-reported topic,2
143,Use of words like performativity (is that a word?),2
144,"  \n2. Unlike one-hidden-layer linear networks, the characterizations of critical points for deep linear networks and deep ReLU networks seem to be hard to be interpreted.",1
145,The authors appear to be blissfully unaware ... [reviewer 6. Out of 7. Seven.,2
146,"The study is poorly conceived, inadequately conducted and the conclusions made by the authors do not necessarily follow from the results",2
147,"These theoretical results have not been verified experimentally. Therefore, they are wrong",2
148,\n\nThe reviewer is favorable in rising the rating towards acceptance if points 1 and 2 will be fixed.,1
149,"In any aspect that this paper is different from XXX et al., (20XX), it shouldnt be",2
150,The authors should at least try to read some of the previous work in the field before attempting to solve our problems.,2
151, This is a very well-accepted method actually used in real-world autonomous cars.,1
152, This would have been useful to study in itself.,1
153, (b) there are serious writing issues.,1
154,I would like to urge the authors to improve the language description to make the manuscript much clear and logic.,2
155, \nThe experimental setting is also unclear.,1
156,"Although it doesnt make for a flashy title (which the authors like more than British tabloids do), there is an alternative interpretation",2
157,\n\nThis is a timely and interesting topic.,1
158, Using DReLU to improve the state-of-art neural network in an uncontrolled setting is important.,1
159," \n\nAlthough I get the high-level goal of the paper, I find Sec. 3.1, which describes the technical approach, nearly incomprehensible.",1
160,"I cannot figure out what point you are making and why you have written this article. This version cannot be saved, so start again with a much clearer vision of what you are trying to say, and the point you are making.",2
161,"This paper is under-referenced, conceptually impoverished, and poorly written.",2
162,"This is nonsense, It is disingenuous to say the least &amp; The authors should stop pretending their method is useful h/",2
163, but the presentation is severely lacking.,1
164,Please use something in parenthesis so your reader doesnt have to take a break from reviewing your work to Google it,2
165,"""The paper considers a problem of adversarial examples applied to the deep neural networks.",1
166, The analyses are interesting and done well.,1
167,Find your inner nerd—it must be a big part of you—bind and gap it and then dump it in the ocean tied to a large rock.,2
168,"While I personally enjoyed this contribution, I cannot escape the sense that this is much ado about very little, to paraphrase Shakespeare.",2
169,Too mathematically inclined.,2
170,"eviewer 2 method acting You will notice that my comments are a bit jumbled, this is somewhat a reflection of the need for improved organisation of the MS in general",2
171,The results are as weak as a wet noodle,2
172, The problem is of significance because in many applications one requires deep networks which uses reduced computation and limited energy.,1
173," --- the new algorithm is 10 times faster and requires only 1/100 resources, and the performance gets worse only slightly.",1
174," Experiments on TREC-QA and SNLI show modest improvement over the word-based structured attention baseline (Parikh et al., 2016).",1
175,The authors should completely revise it after completing the study and by following common scientific standards,2
176,DGA detection concerns the (automatic) distinction of actual and artificially generated domain names.,1
177," They note that the objective can be very different from the desired loss function if the SGD noise matrix is low rank, as evidenced in their experiments.",1
178,"\nTypo: \nIn Session 3 Line 7, there is a missing reference.",1
179,"I would suggest activating the spellchecker on Word, or keeping the cat from walking on your keyboard",2
180, I enjoyed reading the paper which is in general clearly written.,1
181,"None of this work is cited, which I find inexcusable.\u2028\n\n2. ",1
182,"\n- Sec 1: \""abilities not its representation\"" -> comma before \""not\"".",1
183," However, it is not made very clear why this matrix is needed or what the qualitative effect of its addition is.",1
184,"\n* Problem statement in section 3.1 should certainly be improved.[[CNT], [EMP-NEG], [SUG], [MIN]] Authors introduce rather heavy notation which is then used in a confusing way.[[CNT], [PNF-NEG], [CRT], [MIN]] For example, what is the top index in $s_t^{3-p}$ supposed to mean?",1
185,"\n- It would interesting to compare this approach with a conditional training pipeline that sequentially adds branches, keeping the previous branches fixed.",1
186, It proposes many heuristics to use the object feature and attention weights to find the correct count.,1
187,Perpetuating the recognition of this in the face of irrefutable evidence is dilettantish and scientifically unacceptable,2
188,"And finally comes the conclusion, which is the intellectual equivalent of bubblegum.",2
189,"The research questions are vague, which makes them uninteresting",2
190,To put it bluntly: The last thing I want is a reviewer rejecting my papers with reference to an ideological paper like this one,2
191,\n\nCons\n-------\n\nNone,1
192,I find the title and the main premise of the abstract confusing and illogical. [key concept X] has the logic of a Monty Python sketch,2
193," It is unclear what exactly helps, in which case, and why.\u2028\n\n3.",1
194," The \u201cpipeline\u201d is never well defined, only implicitly in p.7 top, and then it is hard to relate the various figures/tables to bottom line results (having the labels wrong does not help that).",1
195,Ive never read anything like it &amp; I do not mean it as a compliment,2
196,I am concerned as it appears that participants in the current study were randomly assigned to one of three experimental conditions,2
197,I would suggest that you do some homework and redirect this work to an actual new and novel and mechanistic work and test it against data,2
198,  This idea is very interesting and tries to marry phrase-based statistical machine translation with neural methods in a principled way.,1
199,\nI do not know which message the paper tries to get across here.,1
200, \n\nQuality: The empirical results (including a video of an actual robotic arm system performing the task) looks good.,1
201," There is a lot of previous work on evaluating similarity in word embeddings (e.g. Hill et al, a lot of the papers in RepEval workshops, etc.); specialization for similarity of word embeddings (e.g. Kiela et al., Mrksic et al., and many others); multi-sense embeddings (e.g. from Navigli's group); and the hubness problem (e.g. Dinu et al.). For the localized centering approach, Hara et al.'s introduced that method. ",1
202,I am personally offended that the authors believed that this study had a reasonable chance of being accepted to a serious journal,2
203,"\n\nWhile this paper is as far as I can tell novel in how it does what it does,",1
204,this may eventually be a cited paper.,2
205,"\n- The main contributions of the paper can be seen as an incremental version of (Franceschi et al, 2017) based on the proposal in (Luketina et al., 2016)",1
206," As is, I don't really see how this motivation has anything to do with getting things out of a KB.",1
207,"\nMoreover, it would be interesting to show if this class-based learning rates changes the convergence of the model or if the early stopping occurs earlier etc...\n\n""",1
208,Often sounds like a precocious high-school student who is trying to show off how clever he is,2
209,I want to vomit; I cant believe this paper was submitted.,2
210,"Reviewer : The conclusions are supported by the results and discussion.
Reviewer : The conclusions are not supported by the result",2
211,"It is rather clear that the paper is incomplete and hastily submitted, as it contains no contribution number. This paper is NOT COMPLETE",2
212,2. [Paper Strengths]: None,2
213, I would argue that there is a lot of evidence for local inhibitory connection in the cortex.,1
214, Presumably this statement needs to be made while also keeping mind the number of importance samples.,1
215," Nevertheless, without going to that extreme, it might be worth adding an extra demo on something bigger than MNIST.",1
216,"The paper is in good shape, though no Sunday morning reading material.",2
217," \n\nBecause of this, the paper needs to be updated and cleaned up before it can be properly reviewed.",1
218,there is no evidence to show this is the first paper to propose the idea,2
219," For instance, the authors could do more to explain Lamport Timestamps than a 1974 citation.",1
220, The advertised new results on the asymptotic behaviour assume a first layer that dominates the size of the network.,1
221,  \n \nShould provide a citation for DRQN,1
222, Much explanation is needed in the author reply in order to clear these questions.,1
223," All the results are more or less direct applications of existing optimization techniques, and not provide fundamental new understandings of the learning REPRESENTATION.""",1
224," Although the ideas are interest and technically sound, and the proposed algorithms are demonstrated to outperform several baselines in various machine learning tasks,",1
225, The experimental results seem solid and seem to support the authors' claims.,1
226,"""This paper suggests a simple yet effective approach for learning with weak supervision.",1
227, The experimental results show that the propped model outperforms tree-lstm using external parsers.,1
228,"\n- The results show only one form of comparison, and the results have confidence intervals that overlap with at least one competing method in all tasks.""",1
229,"From this conclusion, the premise does not follow.",2
230, The authors then compare their approach to previous work on the 8 datasets introduced by Zhang et al. (2015).,1
231,\n\n\nDetailed comments:\n\n- I think in the title/abstract/intro the use of Neural nets is somewhat misleading as neural nets are typically nonlinear.,1
232," When the coreset is empty, VCL turns out to be online variational inference [Broderich et al., 2013; Ghahramani & Attias, 2000].",1
233,"If this was taken from a successfully defended thesis, as it appears to have been, then he should not have been awarded a PhD",2
234,An article like this is just a waste of peer-reviewing resources,2
235,"""****\nI acknowledge the author's comments and improve my score to 7.",1
236,"This sounds nice, but in fact it is vague. There are many instances of this kind of nice-sounding vagueness.",2
237,This study is weak. not innovation h/,2
238,\n - p.7: I was slightly surprised by how small vocabs (3k and 5k words) are said to be optimal for NLI (and similar remarks hold for SQuAD).,1
239,"Unfortunately the paper itself is full of so many fundamental misunderstandings, I don't even know where to begin in criticizing it",2
240," In this work, the authors show that a careful implementation of mixed-precision dynamic fixed point computation can achieve SOTA on 4 large networks on the ImageNET-1K datasets.",1
241,"The text is marred by conceptual messiness, careless reasoning, sloppy phrasing and  inadequate acquaintance with the relevant literature",2
242,\n2) Terms used in the paper are not defined/explained.,1
243,The regression analysis is rubbish. Let's see what happens when you do this properly.,2
244,This is a paper struggling not to die,2
245,The PI is an excellent networker but that he does not have sufficient required scientific expertise and capacity to successfully execute the project,2
246,The derivation is correct but too simple! The paper is therefore not suitable for a general readership.,2
247, I found the formulation of the \\alpha to be non-intuitive and confusing at times.,1
248, Only on CIFAR100 the proposed approach is much better than other approaches.,1
249,"Not now, not ever. - Review of an NSF grant submission. This was the entire review",2
250,"Not sure how to say this diplomatically, but the manuscript is really dull",2
251, \n2. A cycle consistency loss that makes sure the content vector of transferred sentences and style vector of the original sentence should be able to reconstruct the original sentences.,1
252,"author needs to slow down structure at the grammatical level, but more importantly, the process of research, reflection, and argumentation",2
253," The model also does not consider the first mention of the answer span as gold, instead formulating its loss function to incorporate multiple mentions of the answer within the evidence.",1
254,"""The paper is well written, and the authors do an admirable job of motivating their primary contributions throughout the early portions of the paper.",1
255,"\n\n--------------------\n\nadditional review after seeing the author's response: \n\nThe author's response pointed out some of the limitation of Soudry and Carmon, and Xie et al's which I agree.",1
256,This paper is absolutely ridiculous. It shouldn't be published anywhere and the author should not be encouraged to revise,2
257,"\n- The proposed idea (TreeQN) and underlying motivation are almost same as those of VPN [Oh et al.], but there is no in-depth discussion that shows why TreeQN is potentially better than VPN.",1
258," \n\nIt is not clear why the authors have decided to use out-dated 5-layer \""LeNet\""  and NiN (Network in network) architectures instead of more recent and much better performing architectures (and less complex than NiN architectures).",1
259," I am not saying that there is none, but I do not see how the presented experimental results show evidence for this.",1
260,I now turn to my best guess about what the authors might be doing,2
261,\n\nPros:\n-- Efficient model,1
262, But unfortunately doesn\u2019t show any results even qualitative like generated samples for other  work on next frame video prediction.,1
263," Perhaps the heuristics for initializing the connectivity matrices will be insufficient, but could these be improved in further work?\n\n",1
264,insights that rarely amount to very much beyond the bleeding obvious. [..] the problem with jargon is that any idiot can have a go,2
265,\n\nPoints against the paper:\n- Methodological advances are limited / unmotivated choice of model,1
266,"Indeed, the article as a whole shows a lack of sophistication and nuance that is diagnostic of the particular genre of thought pieces",2
267," I also think that the authors should not discuss the general framework and rather focus on \""data teaching\"", which is the only focus of the current paper.",1
268,Didnt like this one ,2
269,In the context here this didn\u2019t seem a particularly relevant addition to the paper. ,1
270,"Mr. Beard is very courageous to give references- if someone did look at another book, I am sure they would stop reading Mr. Beard'-Feynma",2
271,It would be\n  interesting to see what would the method learn if the number of layers was explicitly set to be\n  large and an identity layer was put as one of the option.,1
272,Details of how important these effects are are missing. Ref.75 is entertaining but inadequate in this respect.,2
273,"Let me expand, using an analogy. ",2
274,"\n\nMinors:\nThere are some mixed-up notations: tilde{A_i} => A_i , and rank(A_2) => rank(A)_2 in Proposition 3.""",1
275," Because of this unknown, I could not understand the experiment setup and data formatting!",1
276,"""The authors define a novel method for creating a pair of models, a student and a teacher model, that are co-trained in a manner such that the teacher provides useful examples to the student to communicate a concept that is interpretable to people.",1
277, It seems to perform well in practice as shown in the experimental section.,1
278,Find your inner nerd—it must be a big part of you—bind and gap it and then dump it in the ocean tied to a large rock.,2
279," \n\nThere are several unanswered questions as to how this observation transfers to a semi-supervised or unsupervised setting, and also devise architectures depending on the level of expected noise in the labels.",1
280,"You do not use the empirical data for the analysis, but the empirical data uses you",2
281," Another example, \""are obtained using the GloVe vector, not using PPMI\"" - there are close relationships between what GloVe learns and PPMI, which the authors seem unaware of (see e.g. the GloVe paper and Omer Levy's work).\u2028\n\n4.",1
282,To my mind the paper is similar to the medieval debate concerning angels dancing on pinheads. I do not think the paper should be published,2
283,"Given the way the paper was structured, I felt I had to read most of it.",2
284," For (2), the \""hard\"" functions has a better parameterization, and the gap between 3-layer and 2-layer is proved bigger. ",1
285,"In fact, your hypotheses are not all that complex are they? Nor is Figure 1; nest-ce pas? ,moi",2
286,It seems like you are torturing the data until the model converges.,2
287," However, no detailed information is given in the paper.",1
288,"By the end of the paper, I was left with the impression that the lid had been lifted off a big can of...",2
289,"They have addressed most of the reviewer comments, although their responses to a few of them remind...",2
290,\n****\n\nSummary:\nThe authors propose an experimental framework and metrics for the quantitative evaluation of disentangling representations.,1
291,\nThe paper is NOT well organized and so the technical novelty of the method is unclear.,1
292," There are no theoretical results regarding this question in the paper, and the empirical justification is also lacking.",1
293,"Im really sorry about this reviewer. If youd like, I can get you a new one. - Edito",2
294,This would give a stronger sense of the kind of wins that are possible in this framework,1
295,"I hesitated to suggest this manuscript to be rejected, but I handled to the (naive?) idea that this actual pumpkin can turn into a fair-looking princess.",2
296,\n+ The approach is capable of theoretically handling all linked information to an entity as additional information to the link structure,1
297," This is in my view is how implementations of episodic tasks with a timeout should be done and is implemented this way is classic RL frameworks (e.g., RL glue).",1
298,This paper is desperate. Please reject it completely and then block the author's email ID so they can't use the online system in the future.,2
299," I\nlike the idea of using 3D generation, and particularly, 3D printing, as a means\nof generating adversarial examples -- there is definite novelty in that\nparticular exploration for adversarial examples.",1
300," The ideas are interesting,",1
301,The approach taken is fundamentally inadequate and flawed for almost all use cases,2
302," However, this is not the case for the former (see, e.g., Comon et al., 2008 as cited in this paper).",1
303,The reported mean of 7.7 is misleading because it appears that close to half of your participants are scoring below that mean,2
304,\n\n3. Why comparing to A3C+ which is not necessarily better than A3C in final performance?,1
305,I suggest you consult a competent statistical advisor.,2
306,It is always rather pleasant to recommend that a paper be rejected.,2
307,  Where is this method most applicable and where is it not applicable?,1
308,"A great deal of effort has been expended here, but to what end?",2
309,"\n\nFinally, the experimental part shows nice improvements ",1
310,The authors should refer to the super interesting article on this topic in Wikipedia.,2
311," \n\n2. Sec. 3.3 and 3.4 is a little bit abbreviated from the major focus of the paper, and I guess they are not very important and novel (just educational guess, because I can only guess what the whole algorithm Smoothie is).",1
312,\n\n3. Some details are not clear.,1
313,This work is stuck in the past. The referee would rather talk about the future - some of the senior co-authors were the future once!,2
314,"I know you want to use hormones to study physiological changes, but humans are more than hormones",2
315,I found the entire premise of the work to be utterly theoretically bankrupt,2
316,Table 2 stunningly over-interprets some relatively small signals in the data.,2
317,"Right now, there is zero rationale for the study and zero reason to read the study.",2
318,"Its like you sat around and dreamed up ideas, except theyre just castles in the air",2
319,The results look like a smorgasbord of data,2
320,I am not getting much support for your paper. I hope that privately at least you did not have great confidence in it.,2
321,"""The idea is clearly stated (but lacks some details) and I enjoyed reading the paper.",1
322,"Second, it could benefit from a deeper (maybe theoretical analysis) of some of the questions.",1
323,"While the problem is a very important one for modern society, the topic and lessons are not of broad interest",2
324,\n\nOriginality: The authors demonstrate experimentally that there is a benefit of using non-saturating GANs,1
325,"  Even tough a little bit ad-hoc, it seems promising based on the experiment results.",1
326,"Sprinkled here and there are some things, also taken from his readings, that are more or less correct. But it is all very confused.",2
327,"\n--Very minor: although it is similar to the generator, it would have been nice to see the architecture of the discriminator with example input and output as well.",1
328,\n\nClarifications:\n- See the above mentioned clarification issues in 'major weaknesses'. ,1
329," If that is the case, could the authors describe this a bit further?""",1
330,"it is impossible for the reader to keep track of the hundreds (thousands?) of acronyms in the paper. If there ever is an award for most acronyms in a paper, this one would win it hands down.  h/",2
331,"Like Dr Whos Tardis, the inside of the paper is bigger than the outside. - (H/",2
332,"I would propose skipping the entire first page, which is bewildering and distracting",2
333,"The authors use a log transformation, which is statistical machination, intended to deceive -..",2
334, The paper is missing a clear analysis of NGM's limitations...,1
335,The overall tenor is disturbingly glossy and pretentious given the gravity of the topic,2
336,Perhaps I have just read these papers at monthly intervals and the author had bad luck.,2
337,"""The paper is well written and clear",1
338,People have real issues and I am not at all sure that this one deserves attention.,2
339,"The abstract says absolutely nothing, and I mean this literally and not as a judgement for the content of the paper.",2
340,"Since the manuscript is so lacking in all aspects, I wont bother going through it in detail.",2
341,This is a terrible sentence. It has so many different things in it and not enough punctuation,2
342,"Your footnote is unnecessary, and indeed confusing. Where did you get the word oftentimes from? We are in the 21st century now.",2
343, By the way to me results presented in figure 5 are not enough to claim that the agent trained on random map is implementing a purely reactive wall-following strategy.,1
344," If it wasn\u2019t, then the comparison is unfair, as the results for CP-ALS are drastically underestimated.",1
345,There are FAR too many analyses and results. The reader is swamped.  Its simply not possible to take it all in. It needs to be pruned.,2
346," \n\n- As pointed out by the authors, the idea of this formulation and doubly SGD is not new. ",1
347,\nThis idea however is difficult to be applied to deep learning with a large amount of data.,1
348," The point made in the text between \""Where\"" and \""overseas\"" is perfectly reasonable, but it is a mystery why the base model on the right doesn't learn to associate the common words \""where\"" and \""in\"" both commonly expressing a location.",1
349,"  The idea of using class label to adjust each weight\u2019s learning rate is interesting and somewhat novel,",1
350,\nThere is however a lack of technical novelty or insight in the models themselves.,1
351,Very very sloppy,2
352, \n- how many new data points are finally added into the training data set?,1
353, My impression is hence that the only possible outcome is\n\nrejection.,1
354," Even though LCW performs better than others in this circumstance,",1
355, The UPS optimizer by itself is not new.,1
356, I am curious about the efficiency of the method.,1
357,"I recommend acceptance, provided the editors are willing to stretch the standards for publication a...",2
358,This inclusion criteria is not needed because to be in a master program they would be legal adults. Please remove and adjust everywhere,2
359,Is this really a discovery or just the confirmation of math?,2
360, \n\nTypos / Details: \n- The range of the coefficient of determination is from 0 to 1.,1
361,"Unfortunately, I cannot recommend this paper for publication because its contents violate the laws of physics",2
362,Pleasepleaseplease with sugar on top remove sentences that sound like Hegelian light bulb moments while not meaning anything,2
363,"  To the reviewer, It seems \u201clife-long learning\u201d is the same as \u201conline learning\u201d.[[CNT], [CLA-NEG], [CRT], [MIN]]  However, the whole paper does not define what \u201clife-long learning\u201d is.[[CNT], [CLA-NEG], [CRT], [MIN]]\nThe limited budget scheme is well established in the literature.[[CNT], [CNT], [APC], [MAJ]] \n1. J. Hu, H. Yang, I. King, M. R. Lyu, and A. M.-C. So. Kernelized online imbalanced learning with fixed budgets.",1
364,I did not attempt to understand Figure 2 because there was no motivation given for it,2
365,\n* There are thorough discussion with related works,1
366,The presentation resembles a fishing expedition with claims made beyond the performance of the technology,2
367,The writing and data presentation are so bad that I had to leave work and go home early and then spend time to wonder what life is about.,2
368, In general it was an OK paper and there are many to be improved.\n\n+ Novelty seems minor.,1
369, I would suggest to:\n1. Compare more clearly setups where you fix the hidden size.,1
370,"\n\nAlthough the manuscript has many positive aspects to it,",1
371," Vanilla GAN is know to be hard to train and there has been many variants recently that overcome some of those difficulties and its mode collapse problem. \n""",1
372, And quantify spatial tuning somehow (a natural method would be to use the sparsity measures sometimes applied to neural data to quantify how selective the spatial profile is to one or a few specific locations).,1
373,"   There is some text about a variant of CTC, but it does not explain very clearly what was done or what the motivation was.",1
374,"\nb) suppose that we run an algorithm with fresh samples, then with respect to the randomness of the k-th sample, we have that with prob. 1, W_k is full rank, and the Jacobian of the model is full rank. ",1
375,"\n\nThe problem considered by the paper is interesting,",1
376,"I also do not feel that the lead PI is qualified to undertake this work, [..]  she needs to be academically successful first",2
377,With the appropriate revisions these results could provide a very limited contribution to the field.,2
378,This is a long and tedious manuscript ,2
379," However, the model-free approach does not seem particularly novel in that it is just an extension of that from Tian et al. (2017) plus some additional features.",1
380,"Given the dodgy sampling technique, one could and should wonder how useful it is to include a variable with so little explained variance",2
381," \nFrom these 100 evaluations (with different hyperparameters / architectures), the final performance y_T is collected.",1
382,This whole paper is wildly speculative and needlessly convoluted.,2
383," This is quite a static strategy, I was assuming the authors are going to use some IR method over the web to back up their motivation.",1
384,"eviewer : 'The project can hardly be described as high risk/high gain' 
Reviewer : 'The project is clearly high risk/high gain",2
385," A KB is usually a pretty static entity, and things are added to it at a slow pace.",1
386,"There is no research methodology, no data, no model, no significant analysis and no conclusions which arise from the study",2
387,I now have had a chance to look at this paper. I think it is a bit of a joke.,2
388, (b) To find the value that best matches a key at the decoder stage?,1
389,Not earth shatteringly original but it is hard to be so in this field.,2
390,"Why dont you just send copies of this to the two people in the world who care about it, and forget the publication route?",2
391,"his is the complete review, not an excerpt: Good topic, but i dont get an idea of the results.",2
392,"X and Y are both tools that knotheads can use to move 
science backwards",2
393, More explanations of Figure 2 and the visualization method can be great helpful to understand the advantages of the proposed algorithm.,1
394,Perhaps what I have written is deflating,2
395," which isnt very common in most meta-learning papers today, so it\u2019s encouraging that the method works in that regime.\n",1
396," This method presents a family that can span the entire space, but the efficient parts of this family (which give the promised speedup) only span a tiny fraction of it, as they require only O(log(N)) params to specify an O(N^2) unitary matrix.",1
397,"The question is not very clear, the analysis is not very thorough, and the conclusions are rather trivial or even self-contradictory",2
398,"\n\nAs such, I do not recommend it for acceptance - it needs significant work before it can be accepted at a conference.",1
399,"Sorry for our long silence, due to some perplexity on our side at reading your manuscript.",2
400,The beekeeping example also fails to convince. There is no discussion of bees' actual lived experience.,2
401,This looks like a very early draft,2
402," However,  the authors here argue that spectral normalization is more powerful; it allows for models of higher rank (more non-zero singular values) which implies a more powerful discriminator and eventually more accurate generator.",1
403, The main motivation seems to be that it is easier to optimize.,1
404, It seems as a more natural way to do it.,1
405, Optimisation by back propagation and discretization of the densities to carry out numerical integration are well explained and easy to follow.,1
406,"It is unclear how this would advance the field beyond providing additional, previously unknown information",2
407,I would suggest either activating the spell-checker on Word or finding a way to keep your cat from walking on the keyboard.,2
408,"It is difficult to see the merits of this proposal, and it is doubtful whether the author can contribute anything to this area of research",2
409,This kind of prose simply borders on cruelty against the reader. And the conclusion is the intellectual equivalent of bubblegum.,2
410,"\n\nI think the paper does a fairly good job at doing what it does,",1
411," Studying the relation between predictive coding and deep learning makes sense, but I do not come to the same (strong) conclusions as the author(s) by considering the experimental results - and I do not see evidence for a sophisticated latent representation learned by the network.",1
412,"\n\nOverall, I think the technical contributions of the paper are quite limited, and the experiments are not well enough described for publication.",1
413,\n\nReview:\nThe manuscript describes the proposed algorithm in great detail and the description is easy to follow.,1
414,"If philosophy of science was not taught in the authors doctoral program, (s)he needs to go back and dope slap his/her major professor",2
415,I'm a bonehead so maybe I missed this?,2
416," Then again, the major contribution of this work is not advancing the state-of-the-art on many benchmark tasks,",1
417," \nOverall, I like the paper.",1
418," The approach is evaluated on single word translation, cross-lingual word similarity, and sentence translation retrieval tasks.\",1
419,An alternative to counting sheep.,2
420,The authors have not bothered to learn the first thing about the theories they are hoping to refute with ill-designed experiments and muddled rationale,2
421, so that the recurrent neural networks with attention could capture the learning signal to avoid the repetition issue and the heuristic function in the test time can be removed.,1
422,"If you arent going to make to the effort to understand, then you should just give up",2
423,The theoretical section is unreadable for anyone unfamiliar with the language of relevant French theorists[paper about *German* theorists,2
424," \n\nThis is a well motivated and explained paper, in which a research agenda is clearly defined and evaluated carefully with the results reflected on thoughtfully and with intuition.",1
425,A classic instance of reinvention of the square wheel.,2
426," I liked the fact that the proposed model is very simple, yet very competitive compared to the state-of-the-art.",1
427, Hence I'm not fully convinced that this model indeed works as claimed.,1
428,\nThe latent variables plus a one-hot-encoding representation of the relation is used to reconstruct the input entities.,1
429," For example, have another RNN read the assertions and somehow integrate that.",1
430,\nScheme A consists of training a high precision teacher jointly with a low precision student.,1
431,"I have read this paper several times through, and I have nothing to say in its defense.",2
432,We regret that some of the remarks made by Referee 1 were not edited before being sent to you.,2
433,proposal language is frightfully unclear.,2
434,You have two many misprints,2
435,"My disappointment when finding flawed analyses, conclusions, and terminology [..] was therefore substantial",2
436,"I stopped reading the subsequent data reports carefully, because I no longer had confidence that they would be accurate",2
437,"Sorry for our long silence, due to some perplexity on our side at reading your manuscript.",2
438, Extensive experiments demonstrate the usefulness of the approach.,1
439,"The fact that the question of this paper has never been asked should, on balance, count against the paper",2
440,I doubt that many readers will read anything beyond the abstract if the article remains in its present form,2
441," \n\nTo me, the paper in it\u2019s current form is not written well and does not contain strong enough empirical results, so that I can\u2019t recommend acceptance.",1
442,I now have had a chance to look at this paper. I think it is a bit of a joke.,2
443,  That limits the value.,1
444,.\n\n2. A comparison without dummy parameters would be interesting to investigate the performance differences between the algorithms in a lower-dimensional problem.,1
445,"\nHowever, performance results seem to be competitive and that's the reader may\nbe eager for insights.",1
446," However, the contribution of the paper itself needs to be strengthened in both the theory and empirical sides.",1
447,Based on theoretical considerations I dont see a reason to perform these experiments.,2
448,"The experiments are reasonable, but they fail the fundamental test of good science",2
449,\nHave you tried on other tasks?,1
450,I dont believe in simulations,2
451,Hypothesized is such an ugly word,2
452,This work is antithetical to the spirit of [XX research] and will impede potentially important developments.,2
453,"""Active learning for deep learning is an interesting topic and there is few useful tool available in the literature. It is happy to see such paper in the field.",1
454,It is a collection of good ideas that do not add up to or advance to any meaningful conclusion,2
455,"The turn of phrase is just a vague rhetorical equivocation that is meant to add a semblance of an intellectual air to the text, a rhetorical attempt at being in fashion, but it dissolves only in empty intellectualism.",2
456," Without understanding this first result, it\u2019s difficult to decide to what extent the rest of the paper\u2019s results are to be believed.",1
457, What are the runtimes?,1
458,.\nI raised my score to 7.,1
459," \n\nExperiments don't vary the attack much to understand how robust the method is.""",1
460,"If I never see another piece of writing started with these lines, it will still be too soon.",2
461, However I would encourage authors to rephrase their claim of emergent translation (the title is misleading) as the authors pose this as a supervised problem and the setting has enough constraints to learn a common representation for both languages (bridged by the image) and hence there is no autonomous emergence of translation out of need.,1
462," \n\nAfter rebuttal:\nThe writing of the paper greatly improved, still missing insights (see comments below).",1
463," Many terms are not defined or defined after being introduced (e.g. CIGAR, MF, BQMQ).",1
464,This article reads like the work of a reasonably competent undergraduate.,2
465,The interchangeably use of evaluate and validate is a concern as it is not clear if authors know the difference between these 'verbs' ,2
466," See more detailed points below in Weaknesses.[[CNT], [null], [DIS], [GEN]]\n\n**Strengths**\nI like the high-level motivation of the work, that one needs to understand and establish that language or semantics can help learn better representations for images. ",1
467," As is, I would guess the second is more likely and so I am not convinced the architecture itself is a significant contribution.",1
468,Thats not how science is done.,2
469,"""--------------\nSummary and Evaluation:\n--------------\nThis work present a novel multi-agent reference game designed to train monolingual agents to perform translation between their respective languages -- all without parallel corpora.",1
470,"If the author is comfortable with having his/her name on THIS, then I wont stand in the way of publication.",2
471,I would advise the authors to go back to the drawing board and consider exactly what this paper is to do and do this well,2
472,"It is very lengthy, full of mistakes, irrelevant information, and completely fails to attract...",2
473, While the RWA was an interesting idea,1
474,"""The paper extends the idea of eigenoptions, recently proposed by Machado et al. to domains with stochastic transitions and where state features are learned.",1
475, The numerical experiments show that using CCC strategy leads to an increase in the proportion of efficient equilibrium outcomes.,1
476,"Bad language, weird sentences, half true statements and even nonsense statements continue throughout the draft, I refuse to review more of this draft until these language issues get fixed properly.",2
477,"Given the pedigree of the senior author, I would have expected better",2
478,Not good.,2
479,This manuscript is not publishable in a reasonable sense,2
480,"...to show their similarities or differences, as well as, advantages or disadvantages by your own letters..",2
481,"Im disappointed to say, given the outstanding pedigree of the authors of this paper, that it adds nothing to earlier research.",2
482," Could this submission show some fine-tune experiments?""",1
483,"They include practical examples and code samples, and (in a slightly bizarre move) source code will be made available on acceptance.",2
484,"\n\nAs mentioned in earlier comments, please reword / clarify your use of \""activation function\"".",1
485,"The research team cooked up a great filet mignon. Instead of mushrooms and an exquisite French sauce, we got American ketchup.",2
486," \n- Since there are existing methods to generate images from a textual description (e.g. Zhang ICCV 2017, \""StackGAN\""), Fig. 10 merits a comparison to those.",1
487,here is no point in [..] the statistical overkill in the submission. It simply should not have happened. It should never happen again,2
488,You were either in a rush or you do not care too much about getting your paper accepted,2
489, \n- What is the effect of network hyper-parameters?,1
490," \n\nWhile the experiments are compelling,",1
491, A negative answer to this question will somewhat undermine the significance of the single-hidden-layer result.,1
492,"Alarming errors, even if they could be easily corrected, gave a sense of carelessness that makes me hesitant to recommend it for revisions",2
493, It seems right and valid.,1
494, But there are a few key issues that are not clearly addressed and the experimental results are not convincing.,1
495,"  The current 82.1% accuracy is nice to see,",1
496,The authors are treating what might be called a boutique version within a model that is already considered a boutique model' by many.,2
497," For instance sec 2.1 reviews the history of games and AI, which is besides the key point and does not provide any literary context.",1
498,It is not clear whether important new insights will be gleaned - it cannot be clear until the final product is reviewed,2
499,It was as if they walked in with a blank sheet of paper.,2
500,The most striking—and troubling—feature of this manuscript is that it contains so many exceedingly strange assumptions.,2
501, The invariance introduced here does not seem to be related to any real world phenomenon. ,1
502,What is a systematic review? I have never heard of an unsystematic review.,2
503,Clearly you can tell that I have become distracted by the style of reporting results. I have in fact given up trying to understand it,2
504,  The inclusion of proof summaries in the main text would strengthen this aspect of the paper.,1
505,"The data are weak, based on very small samples, not analyzed properly, and based on measurements  in the wrong medium. I see little value.",2
506," The authors then propose an efficient parallel algorithm for this class of RNNs, which produces speedups over the existing implements of Quasi-RNN, SRU, and LSTM.",1
507,"\n\nI have some concerns about the paper, maybe most notably about the experimental result and the conclusions drawn from them.",1
508,"I am not sure why there is a full section about limitations, this in itself says a lot about the study",2
509,I dont know what the heck the red highlighted text is supposed to mean and left it as is.,2
510,"The study rationale is unclear, the exact research question to be addressed poorly delineated and the overall motivation for the study poorly linked to the literature summary and aims of the study",2
511, \n\nStrengths:\n- The paper is very well written.,1
512,"  First,  a major part of the paper tries to make the case that there is a symmetry breaking property of the proposed model, which I am afraid I simply was not able to follow.",1
513,"I cannot make out signs of independent thinking, work beyond the state of the art, or anything groundbreaking",2
514,The manuscript in the present form is not a review article but is rather a number of research papers stapled together.,2
515,"Unlawful, void and of no effect",2
516," I think there are still some issues, but this work is both valuable and interesting, and it deserves to be published (alongside the Naesseth et al. and Maddison et al. work).",1
517,I fail to see the contribution either to physics or social science,2
518,"This paper is conceptually unclear, and the causal argument/hypotheses are muddled. In short, it is a mess. I stopped reading after page 7",2
519,This strikes me as the worst kind of postmodern legerdemain,2
520," The paper essentially introduces a method to use off-policy data, which is of course important,",1
521,"When the reader is finished struggling through all the methods and results, he/she is left wondering whether it was worth the time.",2
522," In evaluation time, they insert these cells between layers of a network comparable in size to known networks.",1
523,"""This paper focuses on imitation learning with intentions sampled \nfrom a multi-modal distribution.",1
524,"The paper is overlong, very verbose and contains unnecessary repetition.",2
525,Various statements seem to be sweeping and inaccurate generalizations with little robust...,2
526," Also, the experiments takes a fixed 20K iterations for training, and the convergence status (e.g. whether the accumulated gradient has stabilized the policy) is not clear.",1
527, Right now the results are not very convincing.,1
528, The wording here was confusing.,1
529,"presumptuous, ignorant, ill-conceived and downright dangerous",2
530,"""Summary:\nThis paper proposes an approach to learn embeddings in new domains by leveraging the embeddings from other domains in an incremental fashion",1
531, It is shown empirically that the constrained update does not diverge on Baird\u2019s counter example and improves performance in a grid world domain and cart pole over DQN.,1
532,This is depressing! So much work with so little science -..,2
533," My impression is that most papers on NLI use much larger vocabs, no?",1
534,"It was mentioned that participants were recruited. In research, we dont recruit study participants",2
535," To figure out if the GAN is adding anything, it would be nice to see what would happen if you varied individual coordinates in the filter space (\""x-space\"" of the GAN), or varied the magnitude of filters or filter planes.",1
536,"n\nThe paper, however, misses comparison against important work from the literature that is very relevant to their task \u2014 decipherment (Ravi, 2013; Nuhn et al., 2012; Ravi & Knight, 2011) and other approaches like CCA.",1
537, \n\nLemma 1 summarizes properties of the solutions that are expected to have after reaching equilibria.,1
538,"High was my expectation, and so much deeper was my disappointment",2
539," In my sense, the authors do not provide any evidence theoretically or analysis on why the shifted version of ELU (which does not pass the origin) is more favorable.",1
540,"  I noticed the following issues:\n\n1) The learning task is based on error patterns, but it's not clear to me what exactly that means from a software development standpoint.",1
541,I started reading this manuscript with much anticipation but my enthusiasm was short lived.,2
542,"The paper descends into nonsense, never to return, on line 44.",2
543,"\n\nAs is, I cannot recommend acceptance given the current experiments and lack of theoretical results.",1
544,I dont believe in simulations,2
545,"Findings are presented in an anecdotal, descriptive style that I cant interpret.",2
546,Why chase a gene in this ridiculous organism?,2
547,"Table 4 seems unnecessary given figure 8. Indeed, figure 8 also seems unnecessary.",2
548,The supportive tone of this review… took some effort.,2
549,"Cite newer, relevant references, especially those published by X 2012, and X 2008. Best wishes, Dr. X, Associate Editor",2
550,"This paper reads like a womans diary, not like a scientific piece of work",2
551, The application is straightforward and thus technical novelty of this paper is limited.,1
552,Nothing new or ground breaking is discussed in this tutorial,2
553,"I cannot, for the life of me, figure out why this paper was written.",2
554,"The result does improve the state-of-the-art, but it is not strong enough for acceptance",2
555, What is the bases for these parameter choices?,1
556,Why exactly this task? I can think of a zillion other cognitive tasks,2
557,\n\nOverall the paper is well written.,1
558," The given examples seem to exhibit certain kind of mode collapse, i.e. different examples have similar wording from a very limited vocabulary.[[CNT], [EMP-NEG], [CRT], [MIN]] It is possible that the generator just learned to overfit the sentiment classifier, so that the classifier thought the transferred sentences have the desired sentiment, but the transferred sentences may lack variations and hence lacks practical use.",1
559,\n\nPros:\n- Good literature review.,1
560, It would be nice to discuss computational cost as well.,1
561," \n* The block quotes in the introduction may be quite important for points later in the paper, but summarizing the points of these quotes may be a better use of space. The authors more successfully did this in paragraph 2 of the introduction. \n* All long descriptions of the appendix should be carefully revisited and possibly removed due to page length considerations.",1
562,"You will see that Reviewer 2 has slightly missed the point, so please dont pay too much attention to their comments in your revision. -E",2
563,\n\nPros:\n\n1. This paper proposes a simple and intuitive approach for training neural networks.,1
564,"The first and last paragraphs are weak and read in a style unlike the rest of the paper, like poor advertising copy.",2
565,Since you submitted the paper to a scientific journal: where is the science?,2
566," It is well written, the idea is well articulated and presented.",1
567,"This manuscript uses half of the available pages, and fails to explain what has been done, how and...",2
568," In particular, what are the state space and transitions?",1
569,\n+ Improved performance in speech recognition task.,1
570,The length of this review is occasioned by the density of error and misconceived arguments in this manuscript.,2
571,"Moreover, it is unclear whether the effect is sufficiently important to warrant replication.",2
572, I'm not sure what key insights can be taken away from this.,1
573, \n\nPros:\n* Important problem,1
574,"Table 4 seems unnecessary given figure 8. Indeed, figure 8 also seems unnecessary

-R2 has been watching Tidying Up",2
575," I Firstly, the paper introduces a large sketch dataset that future papers can rely on.",1
576,This sentence is so hard to digest it gave me reflux,2
577,"This paper is baffling.[…] In particular, I have not looked at all at section 2 of the paper",2
578,Black-box modeling exercise using a hodge-podge of data tied together with a poorly-defined model,2
579,I showed this paper to my nurses and they agreed there was nothing new reported here.,2
580,The authors need to add a level of puzzlement to their interpretations,2
581,Ive never read anything like it &amp; I do not mean it as a compliment,2
582," It captures local information into so-called blocks using self-attention, and then applies a second level of self-attention over the blocks themselves.",1
583,"  For example, the Cai et al. paper from ICLR 2017 is not considered",1
584,The authors have gained some attention in the community: most of this is due to the wrong reasons,2
585,"For a section on thought, very little seems to have gone into it.",2
586," In the experiments, authors only stated that \u201cwe fit the GPS architecture using UPS optimizer for varying degree of the neighborhood of the graph\u201d, and then the graph is used to train existing models as the input of the graph.",1
587," The early stopping criteria tend to favor suboptimal solution, indeed relying on the Cramer distance is possible improvement.",1
588,This paper introduces tools to answer questions which it does not seem many people are interested in,2
589,The authors should refer to the super interesting article on this topic in Wikipedia.,2
590,This manuscript is a long drive through a countryside. A lot of stuff is irrelevant and pointless.' h/,2
591, The experimental results are very good and give strong support for the proposed normalization.,1
592,"Publishable, but why?",2
593,The figures are dishonest and not all that useful.,2
594,\n- The method lacks details (see Questions above),1
595,n\n- Originality:\nLooking at RNN from an iterative refinement point of view seems novel.,1
596,I gave up pointing out all the mistakes because even the author apparently doesn't consider this manuscript a good scientific presentation,2
597,In order to be able to publish this manuscript it need [sic] to be rewritten in the form of a scientific article,2
598,The authors seem to be reinventing the wheel and a flat tire to go along with it,2
599,"Yes measurements were made, but why, besides a teaching exercise, remains obscure.",2
